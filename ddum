import pandas as pd
import numpy as np
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from xgboost import XGBClassifier
from sklearn.compose import ColumnTransformer
from imblearn.over_sampling import SMOTE

# Load your dataset
df = pd.read_csv('your_dataset.csv')

# Identify the categorical variable with missing values
target_var = 'your_categorical_variable'

# Drop all columns with missing values except the target variable
columns_with_missing_values = df.columns[df.isna().any()].tolist()
columns_with_missing_values.remove(target_var)
df_clean = df.drop(columns=columns_with_missing_values)

# Split the data into training, testing, and target (missing values) sets
df_not_missing = df_clean.dropna(subset=[target_var])
df_missing = df_clean[df_clean[target_var].isna()]

# Further split the not_missing data into training and testing sets
train, test = train_test_split(df_not_missing, test_size=0.2, random_state=42)

# Define the features and target
X_train = train.drop(columns=[target_var])
y_train = train[target_var]
X_test = test.drop(columns=[target_var])
y_test = test[target_var]

# Handle class imbalance using SMOTE
smote = SMOTE(random_state=42)
X_train_res, y_train_res = smote.fit_resample(X_train, y_train)

# Build the preprocessing step
preprocessor = ColumnTransformer(
    transformers=[
        ('cat', OneHotEncoder(handle_unknown='ignore'), X_train.columns)
    ]
)

# Define the models
models = {
    'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42),
    'GradientBoosting': GradientBoostingClassifier(n_estimators=100, random_state=42),
    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)
}

# Train and evaluate each model
for model_name, model in models.items():
    # Build the pipeline
    pipeline = Pipeline([
        ('preprocessor', preprocessor),
        ('classifier', model)
    ])
    
    # Train the classifier on the training set
    pipeline.fit(X_train_res, y_train_res)
    
    # Validate the model on the testing set
    y_pred = pipeline.predict(X_test)
    print(f"Classification report for {model_name}:")
    print(classification_report(y_test, y_pred))
    
    # Impute the missing values in the target dataset
    X_missing = df_missing.drop(columns=[target_var])
    df_missing[target_var] = pipeline.predict(X_missing)
    
    # Print the imputed values for the missing data
    print(f"Imputed missing values using {model_name}:")
    print(df_missing)

# Save the imputed dataset to a CSV file
df_filled = pd.concat([df_not_missing, df_missing])
df_filled.to_csv('filled_dataset.csv', index=False)
print("The dataset with imputed values has been saved to 'filled_dataset.csv'.")
