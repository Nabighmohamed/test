import pandas as pd
import numpy as np
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split

# Assuming final_df is your dataframe
final_df.rename(columns={'total_pnb': 'y_long', 'short_total': 'y_short'}, inplace=True)
data = final_df.copy()
data.dropna(inplace=True)

# Define explanatory variables
X_short = data[['AGE', 'MACMPROF', 'nb_op_annuel', 'CA', 'nb_salaries', 'anc_mois_crea', 'MACMREP', 'MFTCREP', 'k_eq_restant_du']]
y_short = data['y_short']

# Split the data into training and test sets
X_train_short, X_test_short, y_train_short, y_test_short = train_test_split(X_short, y_short, test_size=0.2, random_state=42)

# Define AGBooster parameters
params_agbooster = {
    'eta': 0.01,
    'seed': 1989,
    'subsample': 0.8,
    'booster': 'gbtree',
    'min_child_weight': 10,
    'colsample_bytree': 1
}

# Initialize AGBooster
agbooster_short = agb.AGBooster(
    label_name='y_short',
    feature_names=X_train_short.columns.tolist(),
    params_xgbooster=params_agbooster,
    prefix_sep="_ohe_",
    target_encoding_dict=None  # Adjust if you have target encoding
)

# Select individual features
agbooster_short.select_features(
    data=X_train_short,
    cv_imp=True,
    threshold=5,
    num_boost_round_min=51,
    num_boost_round_max=200,
    num_boost_round_start=200,
    early_stopping_rounds=10,
    eta_start=0.1
)

# Update selected features based on threshold
agbooster_short.update_selected_features(threshold=5)

# Fit AGBooster with univariate GAM
agbooster_short.fit_univariate_gam(
    data=X_train_short,
    num_boost_round_min=51,
    num_boost_round_max=200,
    num_boost_round_start=200,
    early_stopping_rounds=10
)

# Predictions on training and testing datasets
y_pred_short_train = agbooster_short.gam_univariate_model.predict(data=X_train_short)
y_pred_short_test = agbooster_short.gam_univariate_model.predict(data=X_test_short)

# Calculate RMSE for train and test datasets
rmse_gam_univar_train = mean_squared_error(y_train_short, y_pred_short_train, squared=False)
rmse_gam_univar_test = mean_squared_error(y_test_short, y_pred_short_test, squared=False)

print(f'RMSE for y_short on training set: {rmse_gam_univar_train}')
print(f'RMSE for y_short on test set: {rmse_gam_univar_test}')

# Use y_short predictions for y_long model training
data['y_short_pred'] = agbooster_short.gam_univariate_model.predict(data=X_short)
X_long = data[['y_short_pred', 'AGE', 'MACMPROF', 'CA', 'anc_mois_crea', 'MACMREP']]
y_long = data['y_long']

# Split the data into training and test sets for y_long prediction
X_train_long, X_test_long, y_train_long, y_test_long = train_test_split(X_long, y_long, test_size=0.2, random_state=42)

# Initialize AGBooster for y_long
agbooster_long = agb.AGBooster(
    label_name='y_long',
    feature_names=X_train_long.columns.tolist(),
    params_xgbooster=params_agbooster,
    prefix_sep="_ohe_",
    target_encoding_dict=None  # Adjust if you have target encoding
)

# Repeat the process for feature selection and model fitting
agbooster_long.select_features(
    data=X_train_long,
    cv_imp=True,
    threshold=5,
    num_boost_round_min=51,
    num_boost_round_max=200,
    num_boost_round_start=200,
    early_stopping_rounds=10,
    eta_start=0.1
)

agbooster_long.update_selected_features(threshold=5)

agbooster_long.fit_univariate_gam(
    data=X_train_long,
    num_boost_round_min=51,
    num_boost_round_max=200,
    num_boost_round_start=200,
    early_stopping_rounds=10
)

# Predictions on test dataset
y_pred_long_test = agbooster_long.gam_univariate_model.predict(data=X_test_long)

# Calculate RMSE for y_long on test dataset
rmse_gam_univar_long_test = mean_squared_error(y_test_long, y_pred_long_test, squared=False)
print(f'RMSE for y_long on test set: {rmse_gam_univar_long_test}')






import numpy as np
import pandas as pd
import xgboost as xgb
from sklearn.datasets import make_regression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

# Generate synthetic data for regression
X, y = make_regression(n_samples=1000, n_features=20, noise=0.1, random_state=42)

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Convert to DMatrix for XGBoost
dtrain = xgb.DMatrix(X_train, label=y_train)
dtest = xgb.DMatrix(X_test, label=y_test)

# Genetic algorithm parameters
numberOfParents = 8
numberOfParentsMating = 4
numberOfParameters = 7
numberOfGenerations = 5
populationSize = (numberOfParents, numberOfParameters)

# Initialize population
def initialize_population(n_parents):
    population = np.zeros((n_parents, 7))
    for i in range(n_parents):
        population[i, 0] = np.round(np.random.uniform(0.01, 0.3), 2)  # learning_rate
        population[i, 1] = np.random.randint(50, 500)  # n_estimators
        population[i, 2] = np.random.randint(3, 10)  # max_depth
        population[i, 3] = np.round(np.random.uniform(0.5, 10.0), 2)  # min_child_weight
        population[i, 4] = np.round(np.random.uniform(0, 0.5), 2)  # gamma
        population[i, 5] = np.round(np.random.uniform(0.5, 1.0), 2)  # subsample
        population[i, 6] = np.round(np.random.uniform(0.5, 1.0), 2)  # colsample_bytree
    return population

# Fitness function
def fitness_mse(y_true, y_pred):
    return mean_squared_error(y_true, y_pred)

# Train and evaluate a population
def evaluate_population(population, dtrain, dtest):
    fitness = []
    for i in range(population.shape[0]):
        params = {
            'objective': 'reg:squarederror',
            'learning_rate': population[i, 0],
            'n_estimators': int(population[i, 1]),
            'max_depth': int(population[i, 2]),
            'min_child_weight': population[i, 3],
            'gamma': population[i, 4],
            'subsample': population[i, 5],
            'colsample_bytree': population[i, 6],
            'seed': 42
        }
        model = xgb.train(params, dtrain, num_boost_round=int(population[i, 1]))
        preds = model.predict(dtest)
        fitness.append(fitness_mse(y_test, preds))
    return fitness

# Selection of parents
def select_parents(population, fitness, num_parents):
    parents = np.empty((num_parents, population.shape[1]))
    for parent_num in range(num_parents):
        min_fitness_idx = np.argmin(fitness)
        parents[parent_num, :] = population[min_fitness_idx, :]
        fitness[min_fitness_idx] = float('inf')
    return parents

# Crossover
def crossover(parents, offspring_size):
    offspring = np.empty(offspring_size)
    crossover_point = np.uint8(offspring_size[1]/2)

    for k in range(offspring_size[0]):
        parent1_idx = k % parents.shape[0]
        parent2_idx = (k + 1) % parents.shape[0]
        offspring[k, 0:crossover_point] = parents[parent1_idx, 0:crossover_point]
        offspring[k, crossover_point:] = parents[parent2_idx, crossover_point:]

    return offspring

# Mutation
def mutation(offspring_crossover):
    for idx in range(offspring_crossover.shape[0]):
        random_idx = np.random.randint(0, offspring_crossover.shape[1])
        random_value = np.random.uniform(-0.1, 0.1)
        offspring_crossover[idx, random_idx] = offspring_crossover[idx, random_idx] + random_value
        # Ensuring parameter boundaries
        offspring_crossover[idx, 0] = np.clip(offspring_crossover[idx, 0], 0.01, 0.3)
        offspring_crossover[idx, 1] = np.clip(offspring_crossover[idx, 1], 50, 500)
        offspring_crossover[idx, 2] = np.clip(offspring_crossover[idx, 2], 3, 10)
        offspring_crossover[idx, 3] = np.clip(offspring_crossover[idx, 3], 0.5, 10.0)
        offspring_crossover[idx, 4] = np.clip(offspring_crossover[idx, 4], 0, 0.5)
        offspring_crossover[idx, 5] = np.clip(offspring_crossover[idx, 5], 0.5, 1.0)
        offspring_crossover[idx, 6] = np.clip(offspring_crossover[idx, 6], 0.5, 1.0)
    return offspring_crossover

# Genetic Algorithm Execution
population = initialize_population(numberOfParents)
for generation in range(numberOfGenerations):
    print(f"Generation {generation}")
    fitness = evaluate_population(population, dtrain, dtest)
    print(f"Best fitness in generation {generation}: {min(fitness)}")
    parents = select_parents(population, fitness, numberOfParentsMating)
    offspring_crossover = crossover(parents, (populationSize[0] - parents.shape[0], numberOfParameters))
    offspring_mutation = mutation(offspring_crossover)
    population[0:parents.shape[0], :] = parents
    population[parents.shape[0]:, :] = offspring_mutation

# Evaluate the final population
final_fitness = evaluate_population(population, dtrain, dtest)
best_idx = np.argmin(final_fitness)
best_params = population[best_idx]

print("Best parameters found:")
print(f"Learning rate: {best_params[0]}")
print(f"n_estimators: {int(best_params[1])}")
print(f"max_depth: {int(best_params[2])}")
print(f"min_child_weight: {best_params[3]}")
print(f"gamma: {best_params[4]}")
print(f"subsample: {best_params[5]}")
print(f"colsample_bytree: {best_params[6]}")









import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
import statsmodels.api as sm
from statsmodels.genmod.families import Tweedie

# Generate synthetic data
np.random.seed(42)
n_samples = 1000
X = np.random.rand(n_samples, 1) * 10  # Independent variable
y = 3 + 2 * X.flatten() + np.random.gamma(2., 2., n_samples)  # Dependent variable with some noise

# Convert to pandas DataFrame
df = pd.DataFrame({'X': X.flatten(), 'y': y})

# Split the data
X_train, X_test, y_train, y_test = train_test_split(df[['X']], df['y'], test_size=0.2, random_state=42)

# Adding a constant for the intercept
X_train_sm = sm.add_constant(X_train)
X_test_sm = sm.add_constant(X_test)

# Define the Tweedie regression model
tweedie_model = sm.GLM(y_train, X_train_sm, family=Tweedie(var_power=1.5, link_power=0))

# Fit the model
tweedie_results = tweedie_model.fit()

# Print model summary
print(tweedie_results.summary())

# Predict on the test set
y_pred = tweedie_results.predict(X_test_sm)

# Calculate R²
r2 = r2_score(y_test, y_pred)
print(f'R² score: {r2:.4f}')

# Plot Predicted vs. Actual Values
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred, alpha=0.5)
plt.xlabel('Actual Values')
plt.ylabel('Predicted Values')
plt.title('Predicted vs. Actual Values')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], '--r', lw=2)  # Diagonal line
plt.show()





import pandas as pd

# Assuming og_df, df_19, df_20, df_21, df_22, and df_23 are already defined

# List of dataframes to merge with the original dataframe
dfs = [df_19, df_20, df_21, df_22, df_23]

# Loop through each dataframe to merge it with the original dataframe
for i, df in enumerate(dfs, start=19):
    # Rename the pnb_annuel column to pnb_annuel_year (e.g., pnb_annuel_19, pnb_annuel_20)
    df = df.rename(columns={'pnb_annuel': f'pnb_annuel_{i}'})
    
    # Merge the original dataframe with the current dataframe on the 'id' column
    og_df = pd.merge(og_df, df[['id', f'pnb_annuel_{i}']], on='id', how='left')

# Now og_df contains all the pnb_annuel columns from df_19 to df_23









import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.initializers import HeNormal
from tensorflow.keras.losses import MeanSquaredError
from tensorflow.keras.metrics import MeanSquaredError as MSE

# Assuming `df` is your DataFrame and 'target' is the target variable
# df = pd.read_csv('your_data.csv')
# df = ...

# Prepare the data
X = df.drop(columns=['target']).values
y = df['target'].values

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Normalize the features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Create the model
model = Sequential()

# Input layer
model.add(Dense(64, input_dim=X_train.shape[1], activation='relu', kernel_initializer=HeNormal()))

# Hidden layers
model.add(Dense(32, activation='relu', kernel_initializer=HeNormal()))
model.add(Dense(16, activation='relu', kernel_initializer=HeNormal()))

# Output layer for regression
model.add(Dense(1, activation='linear'))

# Compile the model
model.compile(optimizer=Adam(learning_rate=0.001),
              loss=MeanSquaredError(),
              metrics=[MSE()])

# Early stopping to prevent overfitting
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

# Train the model
history = model.fit(X_train, y_train,
                    validation_split=0.2,
                    epochs=100,
                    batch_size=32,
                    callbacks=[early_stopping],
                    verbose=1)

# Evaluate the model
mse = model.evaluate(X_test, y_test, verbose=0)
print(f'Test MSE: {mse:.4f}')






import xgboost as xgb
import numpy as np

# Define the custom loss function using gradients and Hessians derived from R_Q(w)
def custom_loss(y_true, y_pred):
    # Split y_true and y_pred into two halves based on the median of y_true
    n = len(y_true)
    median_y = np.median(y_true)
    
    # Determine indices based on the median
    idx_lower = y_true <= median_y
    idx_upper = y_true > median_y
    
    # Calculate A and B
    A = np.mean((y_true[idx_lower] - y_pred[idx_lower])**2)
    B = np.mean((y_true[idx_upper] - y_pred[idx_upper])**2)
    
    # Calculate R_Q(w)
    RQ_w = np.sqrt((A**2 + B**2) / 2)
    
    # Calculate C and C' based on indices
    C = np.zeros(n)
    C[idx_lower] = A
    C[idx_upper] = B
    
    C_prime = np.zeros(n)
    C_prime[idx_lower] = 4 * (y_pred[idx_lower] - y_true[idx_lower]) / n
    C_prime[idx_upper] = 4 * (y_pred[idx_upper] - y_true[idx_upper]) / n
    
    # Calculate the gradient
    grad = 0.5 * (RQ_w**(-0.5)) * C * C_prime
    
    # Calculate the Hessian
    hess = (-0.25 * (RQ_w**(-1.5)) * C * C_prime) + 0.5 * (RQ_w**(-0.5)) * (C_prime**2 + (4 * C / n))
    
    return grad, hess

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split

# Generate a synthetic dataset
np.random.seed(42)
n_samples = 1000

# Features
X = np.random.normal(size=(n_samples, 5))

# Right-skewed target
y = np.random.exponential(scale=2, size=n_samples)

# Create a DataFrame
data = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(X.shape[1])])
data['target'] = y

# Split the data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(data.drop(columns=['target']), data['target'], test_size=0.2, random_state=42)

# Convert the dataset into DMatrix format for XGBoost
dtrain = xgb.DMatrix(X_train, label=y_train)
dtest = xgb.DMatrix(X_test, label=y_test)

# Set up the parameters for training
params = {
    'max_depth': 3,
    'eta': 0.1
}

# Train the model using the custom loss function
model = xgb.train(params, dtrain, num_boost_round=100, obj=custom_loss)

# Predict on the test set
y_pred = model.predict(dtest)

# Evaluate the model
from sklearn.metrics import mean_squared_error

mse = mean_squared_error(y_test, y_pred)
print(f'Mean Squared Error: {mse:.4f}')









import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import r2_score

def segmented_r2(y, y_pred, segment_range=1000):
    # Sort y and map y_pred accordingly
    sorted_indices = np.argsort(y)
    y_sorted = y[sorted_indices]
    y_pred_sorted = y_pred[sorted_indices]
    
    # Determine the minimum and maximum of y to set up the segments
    min_y = np.min(y_sorted)
    max_y = np.max(y_sorted)
    
    # Define the segments based on the range
    segments = np.arange(min_y, max_y + segment_range, segment_range)
    
    # Calculate R² for each segment
    segment_r2_scores = []
    segment_sizes = []
    
    for i in range(len(segments) - 1):
        start_val = segments[i]
        end_val = segments[i + 1]
        
        # Find indices for the current segment
        mask = (y_sorted >= start_val) & (y_sorted < end_val)
        y_segment = y_sorted[mask]
        y_pred_segment = y_pred_sorted[mask]
        
        if len(y_segment) > 1:  # To avoid computing R² on a single point
            r2 = r2_score(y_segment, y_pred_segment)
            segment_r2_scores.append(r2)
            segment_sizes.append(len(y_segment))
        else:
            segment_r2_scores.append(0)  # If a segment is too small, R² is 0
            segment_sizes.append(1)
    
    # Calculate weighted R²
    weighted_r2 = np.sum(np.array(segment_r2_scores) * np.array(segment_sizes)) / np.sum(segment_sizes)
    
    # Plot R² for each segment
    plt.figure(figsize=(10, 6))
    plt.plot(range(len(segment_r2_scores)), segment_r2_scores, marker='o', linestyle='-', color='b')
    plt.title('Segmented R² Scores')
    plt.xlabel('Segment Index')
    plt.ylabel('R² Score')
    plt.grid(True)
    plt.show()
    
    return weighted_r2, segment_r2_scores

# Example usage
y = np.random.gamma(shape=2.0, scale=2.0, size=5000)
y_pred = y + np.random.normal(0, 1, size=5000)

weighted_r2, segment_r2_scores = segmented_r2(y, y_pred, segment_range=1000)
print('Weighted R²:', weighted_r2)






import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import r2_score

def segmented_r2(y, y_pred, segment_size=1000):
    # Sort y and map y_pred accordingly
    sorted_indices = np.argsort(y)
    y_sorted = y[sorted_indices]
    y_pred_sorted = y_pred[sorted_indices]
    
    # Calculate number of segments
    n_segments = len(y) // segment_size
    if len(y) % segment_size != 0:
        n_segments += 1
    
    # Calculate R² for each segment
    segment_r2_scores = []
    segment_sizes = []
    
    for i in range(n_segments):
        start_index = i * segment_size
        end_index = min((i + 1) * segment_size, len(y))
        y_segment = y_sorted[start_index:end_index]
        y_pred_segment = y_pred_sorted[start_index:end_index]
        
        if len(y_segment) > 1:  # To avoid computing R² on a single point
            r2 = r2_score(y_segment, y_pred_segment)
            segment_r2_scores.append(r2)
            segment_sizes.append(len(y_segment))
        else:
            segment_r2_scores.append(0)  # If a segment is too small, R² is 0
            segment_sizes.append(1)
    
    # Calculate weighted R²
    weighted_r2 = np.sum(np.array(segment_r2_scores) * np.array(segment_sizes)) / np.sum(segment_sizes)
    
    # Plot R² for each segment
    plt.figure(figsize=(10, 6))
    plt.plot(range(n_segments), segment_r2_scores, marker='o', linestyle='-', color='b')
    plt.title('Segmented R² Scores')
    plt.xlabel('Segment Index')
    plt.ylabel('R² Score')
    plt.grid(True)
    plt.show()
    
    return weighted_r2, segment_r2_scores

# Example usage
y = np.random.gamma(shape=2.0, scale=2.0, size=5000)
y_pred = y + np.random.normal(0, 1, size=5000)

weighted_r2, segment_r2_scores = segmented_r2(y, y_pred, segment_size=1000)
print('Weighted R²:', weighted_r2)




import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV
import xgboost as xgb
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt

# Set a random seed for reproducibility
np.random.seed(42)

# Generate synthetic data
n_samples = 1000
X = np.random.rand(n_samples, 10)  # 10 features
y_tweedie = np.random.poisson(1.5, size=n_samples) + np.random.exponential(1.0, size=n_samples)
y_gamma = np.random.gamma(shape=2.0, scale=2.0, size=n_samples)
y_pareto = np.random.pareto(a=3.0, size=n_samples)

# Create a DataFrame for easy handling
data = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(X.shape[1])])
data['y_tweedie'] = y_tweedie
data['y_gamma'] = y_gamma
data['y_pareto'] = y_pareto

# Split the dataset into training and testing sets
X_train, X_test, y_train_tweedie, y_test_tweedie = train_test_split(data.drop(columns=['y_tweedie', 'y_gamma', 'y_pareto']),
                                                                    data['y_tweedie'], test_size=0.2, random_state=42)
_, _, y_train_gamma, y_test_gamma = train_test_split(data.drop(columns=['y_tweedie', 'y_gamma', 'y_pareto']),
                                                     data['y_gamma'], test_size=0.2, random_state=42)
_, _, y_train_pareto, y_test_pareto = train_test_split(data.drop(columns=['y_tweedie', 'y_gamma', 'y_pareto']),
                                                       data['y_pareto'], test_size=0.2, random_state=42)

# Function to plot predictions vs actual
def plot_predictions_vs_actual(y_true, y_pred, title):
    plt.scatter(y_true, y_pred, alpha=0.3)
    plt.xlabel('Actual')
    plt.ylabel('Predicted')
    plt.title(title)
    plt.show()

# Tweedie regression model
model_tweedie = xgb.XGBRegressor(objective='reg:tweedie', tweedie_variance_power=1.5, n_estimators=100, learning_rate=0.1, max_depth=3)
model_tweedie.fit(X_train, y_train_tweedie)
y_pred_tweedie = model_tweedie.predict(X_test)
print('Tweedie MSE:', mean_squared_error(y_test_tweedie, y_pred_tweedie))
plot_predictions_vs_actual(y_test_tweedie, y_pred_tweedie, 'Tweedie Distribution')

# Gamma regression model
model_gamma = xgb.XGBRegressor(objective='reg:gamma', n_estimators=100, learning_rate=0.1, max_depth=3)
model_gamma.fit(X_train, y_train_gamma)
y_pred_gamma = model_gamma.predict(X_test)
print('Gamma MSE:', mean_squared_error(y_test_gamma, y_pred_gamma))
plot_predictions_vs_actual(y_test_gamma, y_pred_gamma, 'Gamma Distribution')

# Custom Pareto regression model (using log link)
def custom_pareto_obj(y_true, y_pred):
    gradient = 1 - np.log(y_pred + 1)
    hessian = -1 / (y_pred + 1)
    return gradient, hessian

model_pareto = xgb.XGBRegressor(objective=custom_pareto_obj, n_estimators=100, learning_rate=0.1, max_depth=3)
model_pareto.fit(X_train, y_train_pareto)
y_pred_pareto = model_pareto.predict(X_test)
print('Pareto MSE:', mean_squared_error(y_test_pareto, y_pred_pareto))
plot_predictions_vs_actual(y_test_pareto, y_pred_pareto, 'Pareto Distribution')

# Hyperparameter tuning for Tweedie
param_grid_tweedie = {
    'learning_rate': [0.01, 0.1, 0.2],
    'max_depth': [3, 4, 5],
    'n_estimators': [50, 100, 150],
    'tweedie_variance_power': [1.1, 1.5, 1.9]
}

grid_search_tweedie = GridSearchCV(estimator=model_tweedie, param_grid=param_grid_tweedie, scoring='neg_mean_squared_error', cv=3)
grid_search_tweedie.fit(X_train, y_train_tweedie)

print("Best Parameters for Tweedie:", grid_search_tweedie.best_params_)
print("Best CV Score for Tweedie:", -grid_search_tweedie.best_score_)

# Refit the tweedie model with the best parameters
best_tweedie_params = grid_search_tweedie.best_params_
model_tweedie = xgb.XGBRegressor(objective='reg:tweedie', **best_tweedie_params)
model_tweedie.fit(X_train, y_train_tweedie)
y_pred_tweedie = model_tweedie.predict(X_test)
print('Tuned Tweedie MSE:', mean_squared_error(y_test_tweedie, y_pred_tweedie))
plot_predictions_vs_actual(y_test_tweedie, y_pred_tweedie, 'Tuned Tweedie Distribution')

# Hyperparameter tuning for Gamma
param_grid_gamma = {
    'learning_rate': [0.01, 0.1, 0.2],
    'max_depth': [3, 4, 5],
    'n_estimators': [50, 100, 150]
}

grid_search_gamma = GridSearchCV(estimator=model_gamma, param_grid=param_grid_gamma, scoring='neg_mean_squared_error', cv=3)
grid_search_gamma.fit(X_train, y_train_gamma)

print("Best Parameters for Gamma:", grid_search_gamma.best_params_)
print("Best CV Score for Gamma:", -grid_search_gamma.best_score_)

# Refit the gamma model with the best parameters
best_gamma_params = grid_search_gamma.best_params_
model_gamma = xgb.XGBRegressor(objective='reg:gamma', **best_gamma_params)
model_gamma.fit(X_train, y_train_gamma)
y_pred_gamma = model_gamma.predict(X_test)
print('Tuned Gamma MSE:', mean_squared_error(y_test_gamma, y_pred_gamma))
plot_predictions_vs_actual(y_test_gamma, y_pred_gamma, 'Tuned Gamma Distribution')






import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV
import xgboost as xgb
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt

# Set a random seed for reproducibility
np.random.seed(42)

# Generate synthetic data
n_samples = 1000
X = np.random.rand(n_samples, 10)  # 10 features
y_tweedie = np.random.poisson(1.5, size=n_samples) + np.random.exponential(1.0, size=n_samples)
y_gamma = np.random.gamma(shape=2.0, scale=2.0, size=n_samples)
y_pareto = np.random.pareto(a=3.0, size=n_samples)

# Create a DataFrame for easy handling
data = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(X.shape[1])])
data['y_tweedie'] = y_tweedie
data['y_gamma'] = y_gamma
data['y_pareto'] = y_pareto

# Split the dataset into training and testing sets
X_train, X_test, y_train_tweedie, y_test_tweedie = train_test_split(data.drop(columns=['y_tweedie', 'y_gamma', 'y_pareto']),
                                                                    data['y_tweedie'], test_size=0.2, random_state=42)
_, _, y_train_gamma, y_test_gamma = train_test_split(data.drop(columns=['y_tweedie', 'y_gamma', 'y_pareto']),
                                                     data['y_gamma'], test_size=0.2, random_state=42)
_, _, y_train_pareto, y_test_pareto = train_test_split(data.drop(columns=['y_tweedie', 'y_gamma', 'y_pareto']),
                                                       data['y_pareto'], test_size=0.2, random_state=42)

# Function to plot predictions vs actual
def plot_predictions_vs_actual(y_true, y_pred, title):
    plt.scatter(y_true, y_pred, alpha=0.3)
    plt.xlabel('Actual')
    plt.ylabel('Predicted')
    plt.title(title)
    plt.show()

# Tweedie regression model
model_tweedie = xgb.XGBRegressor(objective='reg:tweedie', tweedie_variance_power=1.5, n_estimators=100, learning_rate=0.1, max_depth=3)
model_tweedie.fit(X_train, y_train_tweedie)
y_pred_tweedie = model_tweedie.predict(X_test)
print('Tweedie MSE:', mean_squared_error(y_test_tweedie, y_pred_tweedie))
plot_predictions_vs_actual(y_test_tweedie, y_pred_tweedie, 'Tweedie Distribution')

# Gamma regression model
model_gamma = xgb.XGBRegressor(objective='reg:gamma', n_estimators=100, learning_rate=0.1, max_depth=3)
model_gamma.fit(X_train, y_train_gamma)
y_pred_gamma = model_gamma.predict(X_test)
print('Gamma MSE:', mean_squared_error(y_test_gamma, y_pred_gamma))
plot_predictions_vs_actual(y_test_gamma, y_pred_gamma, 'Gamma Distribution')

# Custom Pareto regression model (using log link)
def custom_pareto_obj(y_true, y_pred):
    gradient = 1 - np.log(y_pred + 1)
    hessian = -1 / (y_pred + 1)
    return gradient, hessian

model_pareto = xgb.XGBRegressor(objective=custom_pareto_obj, n_estimators=100, learning_rate=0.1, max_depth=3)
model_pareto.fit(X_train, y_train_pareto)
y_pred_pareto = model_pareto.predict(X_test)
print('Pareto MSE:', mean_squared_error(y_test_pareto, y_pred_pareto))
plot_predictions_vs_actual(y_test_pareto, y_pred_pareto, 'Pareto Distribution')

# Hyperparameter tuning for Tweedie
param_grid_tweedie = {
    'learning_rate': [0.01, 0.1, 0.2],
    'max_depth': [3, 4, 5],
    'n_estimators': [50, 100, 150],
    'tweedie_variance_power': [1.1, 1.5, 1.9]
}

grid_search_tweedie = GridSearchCV(estimator=model_tweedie, param_grid=param_grid_tweedie, scoring='neg_mean_squared_error', cv=3)
grid_search_tweedie.fit(X_train, y_train_tweedie)

print("Best Parameters for Tweedie:", grid_search_tweedie.best_params_)
print("Best CV Score for Tweedie:", -grid_search_tweedie.best_score_)

# Refit the tweedie model with the best parameters
best_tweedie_params = grid_search_tweedie.best_params_
model_tweedie = xgb.XGBRegressor(objective='reg:tweedie', **best_tweedie_params)
model_tweedie.fit(X_train, y_train_tweedie)
y_pred_tweedie = model_tweedie.predict(X_test)
print('Tuned Tweedie MSE:', mean_squared_error(y_test_tweedie, y_pred_tweedie))
plot_predictions_vs_actual(y_test_tweedie, y_pred_tweedie, 'Tuned Tweedie Distribution')

# Hyperparameter tuning for Gamma
param_grid_gamma = {
    'learning_rate': [0.01, 0.1, 0.2],
    'max_depth': [3, 4, 5],
    'n_estimators': [50, 100, 150]
}

grid_search_gamma = GridSearchCV(estimator=model_gamma, param_grid=param_grid_gamma, scoring='neg_mean_squared_error', cv=3)
grid_search_gamma.fit(X_train, y_train_gamma)

print("Best Parameters for Gamma:", grid_search_gamma.best_params_)
print("Best CV Score for Gamma:", -grid_search_gamma.best_score_)

# Refit the gamma model with the best parameters
best_gamma_params = grid_search_gamma.best_params_
model_gamma = xgb.XGBRegressor(objective='reg:gamma', **best_gamma_params)
model_gamma.fit(X_train, y_train_gamma)
y_pred_gamma = model_gamma.predict(X_test)
print('Tuned Gamma MSE:', mean_squared_error(y_test_gamma, y_pred_gamma))
plot_predictions_vs_actual(y_test_gamma, y_pred_gamma, 'Tuned Gamma Distribution')






import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV
import xgboost as xgb
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt

# Set a random seed for reproducibility
np.random.seed(42)

# Generate synthetic data
n_samples = 1000
X = np.random.rand(n_samples, 10)  # 10 features
y_tweedie = np.random.poisson(1.5, size=n_samples) + np.random.exponential(1.0, size=n_samples)
y_gamma = np.random.gamma(shape=2.0, scale=2.0, size=n_samples)
y_pareto = np.random.pareto(a=3.0, size=n_samples)

# Create a DataFrame for easy handling
data = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(X.shape[1])])
data['y_tweedie'] = y_tweedie
data['y_gamma'] = y_gamma
data['y_pareto'] = y_pareto

# Split the dataset into training and testing sets
X_train, X_test, y_train_tweedie, y_test_tweedie = train_test_split(data.drop(columns=['y_tweedie', 'y_gamma', 'y_pareto']),
                                                                    data['y_tweedie'], test_size=0.2, random_state=42)
_, _, y_train_gamma, y_test_gamma = train_test_split(data.drop(columns=['y_tweedie', 'y_gamma', 'y_pareto']),
                                                     data['y_gamma'], test_size=0.2, random_state=42)
_, _, y_train_pareto, y_test_pareto = train_test_split(data.drop(columns=['y_tweedie', 'y_gamma', 'y_pareto']),
                                                       data['y_pareto'], test_size=0.2, random_state=42)

# Function to plot predictions vs actual
def plot_predictions_vs_actual(y_true, y_pred, title):
    plt.scatter(y_true, y_pred, alpha=0.3)
    plt.xlabel('Actual')
    plt.ylabel('Predicted')
    plt.title(title)
    plt.show()

# Tweedie regression model
model_tweedie = xgb.XGBRegressor(objective='reg:tweedie', tweedie_variance_power=1.5, n_estimators=100, learning_rate=0.1, max_depth=3)
model_tweedie.fit(X_train, y_train_tweedie)
y_pred_tweedie = model_tweedie.predict(X_test)
print('Tweedie MSE:', mean_squared_error(y_test_tweedie, y_pred_tweedie))
plot_predictions_vs_actual(y_test_tweedie, y_pred_tweedie, 'Tweedie Distribution')

# Gamma regression model
model_gamma = xgb.XGBRegressor(objective='reg:gamma', n_estimators=100, learning_rate=0.1, max_depth=3)
model_gamma.fit(X_train, y_train_gamma)
y_pred_gamma = model_gamma.predict(X_test)
print('Gamma MSE:', mean_squared_error(y_test_gamma, y_pred_gamma))
plot_predictions_vs_actual(y_test_gamma, y_pred_gamma, 'Gamma Distribution')

# Custom Pareto regression model (using log link)
def custom_pareto_obj(y_true, y_pred):
    gradient = 1 - np.log(y_pred + 1)
    hessian = -1 / (y_pred + 1)
    return gradient, hessian

model_pareto = xgb.XGBRegressor(objective=custom_pareto_obj, n_estimators=100, learning_rate=0.1, max_depth=3)
model_pareto.fit(X_train, y_train_pareto)
y_pred_pareto = model_pareto.predict(X_test)
print('Pareto MSE:', mean_squared_error(y_test_pareto, y_pred_pareto))
plot_predictions_vs_actual(y_test_pareto, y_pred_pareto, 'Pareto Distribution')

# Hyperparameter tuning for Tweedie
param_grid_tweedie = {
    'learning_rate': [0.01, 0.1, 0.2],
    'max_depth': [3, 4, 5],
    'n_estimators': [50, 100, 150],
    'tweedie_variance_power': [1.1, 1.5, 1.9]
}

grid_search_tweedie = GridSearchCV(estimator=model_tweedie, param_grid=param_grid_tweedie, scoring='neg_mean_squared_error', cv=3)
grid_search_tweedie.fit(X_train, y_train_tweedie)

print("Best Parameters for Tweedie:", grid_search_tweedie.best_params_)
print("Best CV Score for Tweedie:", -grid_search_tweedie.best_score_)

# Refit the tweedie model with the best parameters
best_tweedie_params = grid_search_tweedie.best_params_
model_tweedie = xgb.XGBRegressor(objective='reg:tweedie', **best_tweedie_params)
model_tweedie.fit(X_train, y_train_tweedie)
y_pred_tweedie = model_tweedie.predict(X_test)
print('Tuned Tweedie MSE:', mean_squared_error(y_test_tweedie, y_pred_tweedie))
plot_predictions_vs_actual(y_test_tweedie, y_pred_tweedie, 'Tuned Tweedie Distribution')

# Hyperparameter tuning for Gamma
param_grid_gamma = {
    'learning_rate': [0.01, 0.1, 0.2],
    'max_depth': [3, 4, 5],
    'n_estimators': [50, 100, 150]
}

grid_search_gamma = GridSearchCV(estimator=model_gamma, param_grid=param_grid_gamma, scoring='neg_mean_squared_error', cv=3)
grid_search_gamma.fit(X_train, y_train_gamma)

print("Best Parameters for Gamma:", grid_search_gamma.best_params_)
print("Best CV Score for Gamma:", -grid_search_gamma.best_score_)

# Refit the gamma model with the best parameters
best_gamma_params = grid_search_gamma.best_params_
model_gamma = xgb.XGBRegressor(objective='reg:gamma', **best_gamma_params)
model_gamma.fit(X_train, y_train_gamma)
y_pred_gamma = model_gamma.predict(X_test)
print('Tuned Gamma MSE:', mean_squared_error(y_test_gamma, y_pred_gamma))
plot_predictions_vs_actual(y_test_gamma, y_pred_gamma, 'Tuned Gamma Distribution')






import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV
import xgboost as xgb
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt

# Set a random seed for reproducibility
np.random.seed(42)

# Generate synthetic data
n_samples = 1000
X = np.random.rand(n_samples, 10)  # 10 features
y_tweedie = np.random.poisson(1.5, size=n_samples) + np.random.exponential(1.0, size=n_samples)
y_gamma = np.random.gamma(shape=2.0, scale=2.0, size=n_samples)
y_pareto = np.random.pareto(a=3.0, size=n_samples)

# Create a DataFrame for easy handling
data = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(X.shape[1])])
data['y_tweedie'] = y_tweedie
data['y_gamma'] = y_gamma
data['y_pareto'] = y_pareto

# Split the dataset into training and testing sets
X_train, X_test, y_train_tweedie, y_test_tweedie = train_test_split(data.drop(columns=['y_tweedie', 'y_gamma', 'y_pareto']),
                                                                    data['y_tweedie'], test_size=0.2, random_state=42)
_, _, y_train_gamma, y_test_gamma = train_test_split(data.drop(columns=['y_tweedie', 'y_gamma', 'y_pareto']),
                                                     data['y_gamma'], test_size=0.2, random_state=42)
_, _, y_train_pareto, y_test_pareto = train_test_split(data.drop(columns=['y_tweedie', 'y_gamma', 'y_pareto']),
                                                       data['y_pareto'], test_size=0.2, random_state=42)

# Function to plot predictions vs actual
def plot_predictions_vs_actual(y_true, y_pred, title):
    plt.scatter(y_true, y_pred, alpha=0.3)
    plt.xlabel('Actual')
    plt.ylabel('Predicted')
    plt.title(title)
    plt.show()

# Tweedie regression model
model_tweedie = xgb.XGBRegressor(objective='reg:tweedie', tweedie_variance_power=1.5, n_estimators=100, learning_rate=0.1, max_depth=3)
model_tweedie.fit(X_train, y_train_tweedie)
y_pred_tweedie = model_tweedie.predict(X_test)
print('Tweedie MSE:', mean_squared_error(y_test_tweedie, y_pred_tweedie))
plot_predictions_vs_actual(y_test_tweedie, y_pred_tweedie, 'Tweedie Distribution')

# Gamma regression model
model_gamma = xgb.XGBRegressor(objective='reg:gamma', n_estimators=100, learning_rate=0.1, max_depth=3)
model_gamma.fit(X_train, y_train_gamma)
y_pred_gamma = model_gamma.predict(X_test)
print('Gamma MSE:', mean_squared_error(y_test_gamma, y_pred_gamma))
plot_predictions_vs_actual(y_test_gamma, y_pred_gamma, 'Gamma Distribution')

# Custom Pareto regression model (using log link)
def custom_pareto_obj(y_true, y_pred):
    gradient = 1 - np.log(y_pred + 1)
    hessian = -1 / (y_pred + 1)
    return gradient, hessian

model_pareto = xgb.XGBRegressor(objective=custom_pareto_obj, n_estimators=100, learning_rate=0.1, max_depth=3)
model_pareto.fit(X_train, y_train_pareto)
y_pred_pareto = model_pareto.predict(X_test)
print('Pareto MSE:', mean_squared_error(y_test_pareto, y_pred_pareto))
plot_predictions_vs_actual(y_test_pareto, y_pred_pareto, 'Pareto Distribution')

# Hyperparameter tuning for Tweedie
param_grid = {
    'learning_rate': [0.01, 0.1, 0.2],
    'max_depth': [3, 4, 5],
    'n_estimators': [50, 100, 150],
    'tweedie_variance_power': [1.1, 1.5, 1.9]
}

grid_search = GridSearchCV(estimator=model_tweedie, param_grid=param_grid, scoring='neg_mean_squared_error', cv=3)
grid_search.fit(X_train, y_train_tweedie)

print("Best Parameters for Tweedie:", grid_search.best_params_)
print("Best CV Score for Tweedie:", -grid_search.best_score_)

# Refit the tweedie model with the best parameters
best_tweedie_params = grid_search.best_params_
model_tweedie = xgb.XGBRegressor(objective='reg:tweedie', **best_tweedie_params)
model_tweedie.fit(X_train, y_train_tweedie)
y_pred_tweedie = model_tweedie.predict(X_test)
print('Tuned Tweedie MSE:', mean_squared_error(y_test_tweedie, y_pred_tweedie))
plot_predictions_vs_actual(y_test_tweedie, y_pred_tweedie, 'Tuned Tweedie Distribution')






import numpy as np
import matplotlib.pyplot as plt
from statsmodels.genmod.families import Tweedie
from scipy.stats import gaussian_kde

# Sample data for target variable y
# Replace this with your actual data
y = np.random.gamma(shape=2.0, scale=2.0, size=1000)  # Example data

# Plot the actual distribution of the target variable
plt.hist(y, bins=30, density=True, alpha=0.6, color='g', label='Actual Distribution')

# Define a range of variance power values to test
tweedie_powers = [1.1, 1.5, 1.9]  # You can add more values if needed

# Overlay Tweedie distributions with different variance power values
for p in tweedie_powers:
    # Using statsmodels Tweedie distribution family
    tweedie_family = Tweedie(var_power=p)
    mu = np.mean(y)  # Estimate mean from data
    phi = np.var(y) / mu  # Estimate dispersion parameter from data (phi)

    # Generate random samples from the Tweedie distribution
    y_tweedie = tweedie_family.resid_dev(mu, y) * np.sqrt(phi) + mu

    # Estimate density of Tweedie distribution using Kernel Density Estimation (KDE)
    kde = gaussian_kde(y_tweedie)
    x = np.linspace(0, max(y) * 2, 100)
    plt.plot(x, kde(x), label=f'Tweedie p={p}')

# Add labels and legend
plt.xlabel('Value')
plt.ylabel('Density')
plt.title('Comparison of Target Distribution with Tweedie Distributions')
plt.legend()
plt.show()




import numpy as np
import matplotlib.pyplot as plt
from statsmodels.distributions.empirical_distribution import ECDF
from statsmodels.genmod.families import Tweedie

# Sample data for target variable y
# Replace this with your actual data
y = np.random.gamma(shape=2.0, scale=2.0, size=1000)  # Example data

# Plot the actual distribution of the target variable
plt.hist(y, bins=30, density=True, alpha=0.6, color='g', label='Actual Distribution')

# Define a range of variance power values to test
tweedie_powers = [1.1, 1.5, 1.9]  # You can add more values if needed

# Overlay Tweedie distributions with different variance power values
for p in tweedie_powers:
    # Using statsmodels Tweedie distribution family
    tweedie_family = Tweedie(var_power=p)
    mu = np.mean(y)  # Estimate mean from data
    phi = np.var(y) / mu  # Estimate dispersion parameter from data (phi)
    x = np.linspace(0, max(y) * 2, 100)  # Generate x values for the density plot
    
    # Calculate Tweedie probability density function (PDF)
    pdf = tweedie_family.pdf(x, mu=mu, phi=phi)
    
    plt.plot(x, pdf, label=f'Tweedie p={p}')

# Add labels and legend
plt.xlabel('Value')
plt.ylabel('Density')
plt.title('Comparison of Target Distribution with Tweedie Distributions')
plt.legend()
plt.show()




import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

# Assuming X and y are your features and target variables
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Set up XGBoost Regressor
xgb_model = xgb.XGBRegressor(
    objective='reg:tweedie',
    tweedie_variance_power=1.5,  # Adjust as needed
    eta=0.1,
    max_depth=6,
    subsample=0.8,
    colsample_bytree=0.8,
    n_estimators=100
)

# Train the model
xgb_model.fit(X_train, y_train)

# Predict and evaluate
y_pred = xgb_model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
print(f'Mean Squared Error: {mse}')





import xgboost as xgb
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

# Define the custom loss function using gradients and Hessians derived from R_Q(w)
def custom_loss(y_true, y_pred):
    n = len(y_true)
    mid = n // 2
    
    # Calculate A and B
    A = np.mean((y_true[:mid] - y_pred[:mid])**2)
    B = np.mean((y_true[mid:] - y_pred[mid:])**2)
    
    # Calculate R_Q(w)
    RQ_w = np.sqrt((A**2 + B**2) / 2)
    
    # Calculate the gradient
    grad = np.zeros(n)
    grad[:mid] = -2 * (y_true[:mid] - y_pred[:mid]) * A / (n * RQ_w)
    grad[mid:] = -2 * (y_true[mid:] - y_pred[mid:]) * B / (n * RQ_w)
    
    # Calculate the Hessian
    hess = np.zeros(n)
    hess[:mid] = (2 / (n * RQ_w)) - (4 * (y_true[:mid] - y_pred[:mid])**2 * A) / (n**2 * RQ_w**3)
    hess[mid:] = (2 / (n * RQ_w)) - (4 * (y_true[mid:] - y_pred[mid:])**2 * B) / (n**2 * RQ_w**3)
    
    return grad, hess

# Generate right-skewed data
np.random.seed(42)
n_samples = 1000
X = np.random.normal(size=(n_samples, 5))
y = np.random.exponential(scale=2, size=n_samples)
data = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(X.shape[1])])
data['target'] = y

# Split the data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(data.drop(columns=['target']), data['target'], test_size=0.2, random_state=42)

# Set up the parameters for training
params = {
    'max_depth': 3,
    'eta': 0.1
}

# Convert the custom loss function to the format expected by XGBRegressor
def xgb_custom_loss(y_true, y_pred):
    grad, hess = custom_loss(y_true, y_pred)
    return grad, hess

# Train the model using the custom loss function
model = xgb.XGBRegressor(objective=xgb_custom_loss, **params)
model.fit(X_train, y_train)

# Predict on the test set
y_pred = model.predict(X_test)

# Evaluate the model
mse = mean_squared_error(y_test, y_pred)
print(f'Mean Squared Error: {mse:.4f}')






import pandas as pd
import numpy as np
import tensorflow as tf
import tensorflow_probability as tfp
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

# Set the random seed for reproducibility
np.random.seed(42)

# Number of samples
n_samples = 1000

# Generate 5 continuous variables
X = pd.DataFrame({
    'var1': np.random.normal(loc=50, scale=10, size=n_samples),
    'var2': np.random.normal(loc=100, scale=20, size=n_samples),
    'var3': np.random.normal(loc=150, scale=30, size=n_samples),
    'var4': np.random.normal(loc=200, scale=40, size=n_samples),
    'var5': np.random.normal(loc=250, scale=50, size=n_samples),
})

# Generate LTV as the target variable
LTV = 2 * X['var1'] + 0.5 * X['var2'] + 0.3 * X['var3'] + 0.1 * X['var4'] + 0.05 * X['var5'] + np.random.normal(loc=0, scale=10, size=n_samples)

# Combine into a single DataFrame
df = X.copy()
df['LTV'] = LTV

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, LTV, test_size=0.2, random_state=42)

# Define the custom quadratic mean-based loss function
def quadratic_mean_loss(y_true, y_pred):
    """
    Custom quadratic mean-based loss function for a DNN in TensorFlow.

    Parameters:
    y_true (tf.Tensor): True labels.
    y_pred (tf.Tensor): Predicted values from the model.

    Returns:
    tf.Tensor: Calculated quadratic mean-based loss.
    """
    # Calculate the median of y_true
    median = tfp.stats.percentile(y_true, 50.0, interpolation='midpoint')
    
    # Create a mask for values below or equal to the median
    mask = tf.less_equal(y_true, median)
    
    # Split y_true and y_pred based on the median
    y_true_first_half = tf.boolean_mask(y_true, mask)
    y_pred_first_half = tf.boolean_mask(y_pred, mask)
    
    y_true_second_half = tf.boolean_mask(y_true, ~mask)
    y_pred_second_half = tf.boolean_mask(y_pred, ~mask)
    
    # Compute MSE for both halves
    mse_first_half = tf.reduce_mean(tf.square(y_true_first_half - y_pred_first_half))
    mse_second_half = tf.reduce_mean(tf.square(y_true_second_half - y_pred_second_half))
    
    # Compute the quadratic mean of the MSEs
    quadratic_mean = tf.sqrt(0.5 * (tf.square(mse_first_half) + tf.square(mse_second_half)))
    
    return quadratic_mean

# Define the DNN model
model = tf.keras.models.Sequential([
    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dense(1)
])

# Compile the model with the custom loss function
model.compile(optimizer='adam', loss=quadratic_mean_loss)

# Train the model
model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=1)

# Make predictions on the test set
y_pred = model.predict(X_test)

# Plot predicted values vs. true values
plt.figure(figsize=(8, 6))
plt.scatter(y_test, y_pred, alpha=0.5)
plt.xlabel('True Values')
plt.ylabel('Predicted Values')
plt.title('Predicted vs. True Values')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)
plt.show()






import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.model_selection import train_test_split

# Set random seed for reproducibility
np.random.seed(42)
tf.random.set_seed(42)

# Generate synthetic data
n_samples = 1000  # Number of samples
n_features = 10   # Number of features

# Generate random features
X = np.random.normal(size=(n_samples, n_features))

# Simulate the probability of making a purchase (logistic function)
prob_purchase = 1 / (1 + np.exp(-X[:, 0]))  # Probability influenced by the first feature

# Simulate whether a purchase was made or not (binary outcome)
purchase_made = np.random.binomial(1, prob_purchase)

# Simulate the lognormal distributed LTV for customers who made a purchase
lognormal_mean = X[:, 1]  # Mean influenced by the second feature
lognormal_std = np.abs(X[:, 2])  # Std influenced by the third feature, ensure it's positive
ltv_positive = np.exp(np.random.normal(lognormal_mean, lognormal_std))

# Combine the zero LTV for non-purchasers and positive LTV for purchasers
ltv = purchase_made * ltv_positive

# Create a DataFrame
df = pd.DataFrame(X, columns=[f'feature_{i+1}' for i in range(n_features)])
df['purchase_value'] = ltv

# Split the data into features and target
X = df.drop(columns=['purchase_value']).values  # Features
y = df['purchase_value'].values.reshape(-1, 1)  # Target

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Define the custom loss function
def custom_log_loss(y_true, y_pred):
    # Ensure y_pred is greater than 0 to avoid log(0)
    y_pred = tf.clip_by_value(y_pred, 1e-10, tf.reduce_max(y_pred))
    return tf.reduce_mean(tf.square(tf.math.log(y_true) - tf.math.log(y_pred)))

# Define the model architecture
model = tf.keras.Sequential([
    tf.keras.layers.Input(shape=(X_train.shape[1],)),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dense(1)  # Output layer for predicting a single continuous value
])

# Compile the model with the custom log loss function
model.compile(optimizer='adam', loss=custom_log_loss)

# Train the model
model.fit(X_train, y_train, epochs=50, batch_size=128, validation_split=0.2)

# Evaluate the model on the test set
y_pred = model.predict(X_test)

# Display some of the predictions alongside actual values
results = pd.DataFrame({
    'Actual': y_test.flatten(),
    'Predicted': y_pred.flatten()
})

print("Sample of Actual vs Predicted values:")
print(results.head())

# Optionally, evaluate the performance using mean squared error or any other metric
mse = tf.keras.metrics.mean_squared_error(y_test, y_pred).numpy()
print(f"\nMean Squared Error on test set: {mse:.4f}")








import tensorflow as tf
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from zero_inflated_lognormal import zero_inflated_lognormal_loss, zero_inflated_lognormal_pred
from metrics import cumulative_true, gini_from_gain


np.random.seed(42)

# Parameters
n_samples = 1000  # Number of samples
n_features = 10   # Number of features

# Generate random features
X = np.random.normal(size=(n_samples, n_features))

# Simulate the probability of making a purchase (logistic function)
prob_purchase = 1 / (1 + np.exp(-X[:, 0]))  # Probability influenced by the first feature

# Simulate whether a purchase was made or not (binary outcome)
purchase_made = np.random.binomial(1, prob_purchase)

# Simulate the lognormal distributed LTV for customers who made a purchase
lognormal_mean = X[:, 1]  # Mean influenced by the second feature
lognormal_std = np.abs(X[:, 2])  # Std influenced by the third feature, ensure it's positive
ltv_positive = np.exp(np.random.normal(lognormal_mean, lognormal_std))

# Combine the zero LTV for non-purchasers and positive LTV for purchasers
ltv = purchase_made * ltv_positive

# Create a DataFrame
df = pd.DataFrame(X, columns=[f'feature_{i+1}' for i in range(n_features)])
df['purchase_value'] = ltv

# Display the first few rows of the generated data
print(df.head())

# Assuming df is your input DataFrame with features and a 'purchase_value' column as target
X = df.drop(columns=['purchase_value']).values  # Features
y = df['purchase_value'].values.reshape(-1, 1)  # Target, reshape to ensure correct dimensions

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Define the model architecture with Input layer
inputs = tf.keras.Input(shape=(X_train.shape[1],))
x = tf.keras.layers.Dense(64, activation='relu')(inputs)
x = tf.keras.layers.Dense(32, activation='relu')(x)
outputs = tf.keras.layers.Dense(3)(x)  # Output layer with 3 logits for ZILN: p, mean, std

# Define the model
model = tf.keras.Model(inputs, outputs)

# Compile the model with the ZILN loss function
model.compile(optimizer='adam', loss=zero_inflated_lognormal_loss)

# Train the model on the training set
model.fit(X_train, y_train, epochs=50, batch_size=128, validation_split=0.2)

# Evaluate the model on the test set
predictions = model.predict(X_test)
predicted_ltv = zero_inflated_lognormal_pred(predictions)









import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import tensorflow as tf
from tensorflow.keras import layers, Model
import lifetime_value as ltv  # Assuming you have imported your custom package correctly

# Step 1: Generate a random DataFrame with numeric features X1, X2, X3, X4 and target Y
np.random.seed(42)
df = pd.DataFrame({
    'X1': np.random.randn(1000),
    'X2': np.random.randn(1000),
    'X3': np.random.randn(1000),
    'X4': np.random.randn(1000),
    'Y': np.random.randn(1000)
})

df['label'] = df['Y'].values.reshape(-1, 1)  # Ensure label is a column vector
df['calibration_value'] = df['Y']  # This is used for calibration purposes

NUMERIC_FEATURES = ['X1', 'X2', 'X3', 'X4']
CATEGORICAL_FEATURES = []

# Step 2: Define the function to split the data for DNN
def dnn_split(df):
    y0 = df['calibration_value'].values
    df_train, df_eval, y0_train, y0_eval = train_test_split(
        df, y0, test_size=0.2, random_state=123
    )

    def feature_dict(df):
        return {'numeric': df[NUMERIC_FEATURES].values}

    x_train, y_train = feature_dict(df_train), df_train['label'].values.reshape(-1, 1)
    x_eval, y_eval = feature_dict(df_eval), df_eval['label'].values.reshape(-1, 1)

    return x_train, x_eval, y_train, y_eval, y0_eval

# Step 3: Define the DNN model
def dnn_model(output_units):
    numeric_input = tf.keras.layers.Input(shape=(len(NUMERIC_FEATURES),), name='numeric')
    deep_model = tf.keras.Sequential([
        layers.Dense(64, activation='relu'),
        layers.Dense(32, activation='relu'),
        layers.Dense(output_units)  # Output units must be 3 for ZILN
    ])
    return tf.keras.Model(inputs=numeric_input, outputs=deep_model(numeric_input))

# Step 4: Set parameters and compile the model
LOSS = 'ziln'  # Using the Zero-Inflated Lognormal loss
LEARNING_RATE = 0.001
EPOCHS = 100
output_units = 3  # ZILN requires 3 output units

x_train, x_eval, y_train, y_eval, y0_eval = dnn_split(df)
model = dnn_model(output_units)

model.compile(loss=ltv.zero_inflated_lognormal_loss, optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE))

callbacks = [
    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', min_lr=1e-6),
    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)
]

# Step 5: Train the model
history = model.fit(
    x=x_train['numeric'],
    y=y_train,
    batch_size=1024,
    epochs=EPOCHS,
    verbose=2,
    callbacks=callbacks,
    validation_data=(x_eval['numeric'], y_eval)
)

# Step 6: Evaluate and predict
logits = model.predict(x_eval['numeric'], batch_size=1024)
y_pred = ltv.zero_inflated_lognormal_pred(logits).numpy().flatten()

df_pred = pd.DataFrame({
    'y_true': y_eval.flatten(),  # Flatten y_eval to match the shape
    'y_pred': y_pred,
})
print(df_pred.head(10))










import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import tensorflow as tf
from tensorflow.keras import layers, Model
import lifetime_value as ltv  # Assuming you have imported your custom package correctly

# Step 1: Generate a random DataFrame with numeric features X1, X2, X3, X4 and target Y
np.random.seed(42)
df = pd.DataFrame({
    'X1': np.random.randn(1000),
    'X2': np.random.randn(1000),
    'X3': np.random.randn(1000),
    'X4': np.random.randn(1000),
    'Y': np.random.randn(1000)
})

df['label'] = df['Y'].values.reshape(-1, 1)  # Ensure label is a column vector
df['calibration_value'] = df['Y']  # This is used for calibration purposes

NUMERIC_FEATURES = ['X1', 'X2', 'X3', 'X4']
CATEGORICAL_FEATURES = []

# Step 2: Define the function to split the data for DNN
def dnn_split(df):
    y0 = df['calibration_value'].values
    df_train, df_eval, y0_train, y0_eval = train_test_split(
        df, y0, test_size=0.2, random_state=123
    )

    def feature_dict(df):
        return {'numeric': df[NUMERIC_FEATURES].values}

    x_train, y_train = feature_dict(df_train), df_train['label'].values.reshape(-1, 1)
    x_eval, y_eval = feature_dict(df_eval), df_eval['label'].values.reshape(-1, 1)

    return x_train, x_eval, y_train, y_eval, y0_eval

# Step 3: Define the DNN model
def dnn_model(output_units):
    numeric_input = tf.keras.layers.Input(shape=(len(NUMERIC_FEATURES),), name='numeric')
    deep_model = tf.keras.Sequential([
        layers.Dense(64, activation='relu'),
        layers.Dense(32, activation='relu'),
        layers.Dense(output_units)  # Output units must be 3 for ZILN
    ])
    return tf.keras.Model(inputs=numeric_input, outputs=deep_model(numeric_input))

# Step 4: Set parameters and compile the model
LOSS = 'ziln'  # Using the Zero-Inflated Lognormal loss
LEARNING_RATE = 0.001
EPOCHS = 100
output_units = 3  # ZILN requires 3 output units

x_train, x_eval, y_train, y_eval, y0_eval = dnn_split(df)
model = dnn_model(output_units)

model.compile(loss=ltv.zero_inflated_lognormal_loss, optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE))

callbacks = [
    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', min_lr=1e-6),
    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)
]

# Step 5: Train the model
history = model.fit(
    x=x_train['numeric'],
    y=y_train,
    batch_size=1024,
    epochs=EPOCHS,
    verbose=2,
    callbacks=callbacks,
    validation_data=(x_eval['numeric'], y_eval)
)

# Step 6: Evaluate and predict
logits = model.predict(x_eval['numeric'], batch_size=1024)
y_pred = ltv.zero_inflated_lognormal_pred(logits).numpy().flatten()

df_pred = pd.DataFrame({
    'y_true': y_eval.flatten(),  # Flatten y_eval to match the shape
    'y_pred': y_pred,
})
print(df_pred.head(10))

# Step 7: Save the results to a CSV
output_path = "/path/to/your/output/folder/results.csv"
df_pred.to_csv(output_path, index=False)






import tensorflow as tf
import numpy as np
import pandas as pd
from zero_inflated_lognormal import zero_inflated_lognormal_loss, zero_inflated_lognormal_pred
from metrics import cumulative_true, gini_from_gain

# Assuming df is your input DataFrame with features and a 'purchase_value' column as target
X = df.drop(columns=['purchase_value']).values  # Features
y = df['purchase_value'].values.reshape(-1, 1)  # Target, reshape to ensure correct dimensions

# Define the model architecture with Input layer
inputs = tf.keras.Input(shape=(X.shape[1],))
x = tf.keras.layers.Dense(64, activation='relu')(inputs)
x = tf.keras.layers.Dense(32, activation='relu')(x)
outputs = tf.keras.layers.Dense(3)(x)  # Output layer with 3 logits for ZILN: p, mean, std

# Define the model
model = tf.keras.Model(inputs, outputs)

# Compile the model with the ZILN loss function
model.compile(optimizer='adam', loss=zero_inflated_lognormal_loss)

# Train the model
model.fit(X, y, epochs=50, batch_size=128, validation_split=0.2)

# Make predictions
predictions = model.predict(X)
predicted_ltv = zero_inflated_lognormal_pred(predictions)

# Evaluate using metrics
cumulative_true_values = cumulative_true(y, predicted_ltv.numpy())
gini_df = pd.DataFrame({
    'true': cumulative_true_values,
    'predicted': cumulative_true(y, predicted_ltv.numpy())
})
gini_results = gini_from_gain(gini_df)

# Print Gini coefficient results
print(gini_results)



import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import tensorflow as tf
from tensorflow.keras import layers, Model
import lifetime_value as ltv  # Assuming you have imported your custom package correctly

# Step 1: Generate a random DataFrame with numeric features X1, X2, X3, X4 and target Y
np.random.seed(42)
df = pd.DataFrame({
    'X1': np.random.randn(1000),
    'X2': np.random.randn(1000),
    'X3': np.random.randn(1000),
    'X4': np.random.randn(1000),
    'Y': np.random.randn(1000)
})

df['label'] = df['Y'].values.reshape(-1, 1)  # Ensure label is a column vector
df['calibration_value'] = df['Y']  # This is used for calibration purposes

NUMERIC_FEATURES = ['X1', 'X2', 'X3', 'X4']
CATEGORICAL_FEATURES = []

# Step 2: Define the function to split the data for DNN
def dnn_split(df):
    y0 = df['calibration_value'].values
    df_train, df_eval, y0_train, y0_eval = train_test_split(
        df, y0, test_size=0.2, random_state=123
    )

    def feature_dict(df):
        return {'numeric': df[NUMERIC_FEATURES].values}

    x_train, y_train = feature_dict(df_train), df_train['label'].values.reshape(-1, 1)
    x_eval, y_eval = feature_dict(df_eval), df_eval['label'].values.reshape(-1, 1)

    return x_train, x_eval, y_train, y_eval, y0_eval

# Step 3: Define the DNN model
def dnn_model(output_units):
    numeric_input = tf.keras.layers.Input(shape=(len(NUMERIC_FEATURES),), name='numeric')
    deep_model = tf.keras.Sequential([
        layers.Dense(64, activation='relu'),
        layers.Dense(32, activation='relu'),
        layers.Dense(output_units)  # Output units must be 3 for ZILN
    ])
    return tf.keras.Model(inputs=numeric_input, outputs=deep_model(numeric_input))

# Step 4: Set parameters and compile the model
LOSS = 'ziln'  # Using the Zero-Inflated Lognormal loss
LEARNING_RATE = 0.001
EPOCHS = 100
output_units = 3  # ZILN requires 3 output units

x_train, x_eval, y_train, y_eval, y0_eval = dnn_split(df)
model = dnn_model(output_units)

model.compile(loss=ltv.zero_inflated_lognormal_loss, optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE))

callbacks = [
    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', min_lr=1e-6),
    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)
]

# Step 5: Train the model
history = model.fit(
    x=x_train['numeric'],
    y=y_train,
    batch_size=1024,
    epochs=EPOCHS,
    verbose=2,
    callbacks=callbacks,
    validation_data=(x_eval['numeric'], y_eval)
)

# Step 6: Evaluate and predict
logits = model.predict(x_eval['numeric'], batch_size=1024)
y_pred = ltv.zero_inflated_lognormal_pred(logits).numpy().flatten()

df_pred = pd.DataFrame({
    'y_true': y_eval.flatten(),  # Flatten y_eval to match the shape
    'y_pred': y_pred,
})
print(df_pred.head(10))

# Step 7: Save the results to a CSV
output_path = "/path/to/your/output/folder/results.csv"
df_pred.to_csv(output_path, index=False)







import numpy as np
import xgboost as xgb
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt

# Step 1: Generate synthetic data
np.random.seed(42)
X_train = np.random.rand(100, 5)  # 100 samples, 5 features
y_train = np.exp(10 * X_train[:, 0] + 15 * X_train[:, 1]) + np.random.normal(0, 1e3, 100)  # Larger magnitude function

X_test = np.random.rand(20, 5)  # 20 samples, 5 features
y_test = np.exp(10 * X_test[:, 0] + 15 * X_test[:, 1]) + np.random.normal(0, 1e3, 20)

# Ensure all labels are positive (if necessary)
y_train = np.clip(y_train, 1e-6, None)
y_test = np.clip(y_test, 1e-6, None)

# Create DMatrix for XGBoost
dtrain = xgb.DMatrix(X_train, label=y_train)
dtest = xgb.DMatrix(X_test, label=y_test)

# Step 2: Define the custom loss function with L2 regularization
def custom_log_loss_with_regularization(preds, dtrain, reg_lambda=1.0):
    labels = dtrain.get_label()
    eps = 1e-6  # Small value to prevent division by zero and log issues
    
    # Clip preds to avoid log of zero or negative numbers
    preds = np.clip(preds, eps, None)
    
    # Gradient: -(2(log(y) - log(y_pred)) / y_pred + 2 * lambda * y_pred)
    grad = -2 * (np.log(labels) - np.log(preds)) / preds + 2 * reg_lambda * preds
    
    # Hessian: -(2(log(y) + 2log(y_pred) + 2)) / (y_pred^2) + 2 * lambda
    hess = -2 * (np.log(labels) + 2 * np.log(preds) + 2) / (preds ** 2) + 2 * reg_lambda
    
    return grad, hess

# Step 3: Train the model using the custom loss function with L2 regularization
params = {
    'max_depth': 6,
    'eta': 0.1,
    'seed': 42
}

# Train the model using the custom log-based loss function with regularization
model_custom_reg = xgb.train(params, dtrain, num_boost_round=100, obj=lambda preds, dtrain: custom_log_loss_with_regularization(preds, dtrain, reg_lambda=1.0))

# Update the params to use the built-in MSE loss function
params['objective'] = 'reg:squarederror'

# Train the model using the built-in MSE loss function
model_builtin = xgb.train(params, dtrain, num_boost_round=100)

# Make predictions on the test set
preds_custom_reg = model_custom_reg.predict(dtest)
preds_builtin = model_builtin.predict(dtest)

# Calculate the MSE for both models
mse_custom_reg = mean_squared_error(y_test, preds_custom_reg)
mse_builtin = mean_squared_error(y_test, preds_builtin)

print(f"Custom Log-based Loss with Regularization MSE: {mse_custom_reg}")
print(f"Built-in MSE Loss: {mse_builtin}")

# Step 4: Plot the results
plt.figure(figsize=(12, 6))

plt.subplot(1, 2, 1)
plt.scatter(y_test, preds_custom_reg, color='blue', label='Predicted vs True (Custom with Reg)')
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--', label='Ideal')
plt.xlabel('True Values')
plt.ylabel('Predicted Values')
plt.title('Custom Log-based Loss with L2 Regularization')
plt.legend()

plt.subplot(1, 2, 2)
plt.scatter(y_test, preds_builtin, color='green', label='Predicted vs True (Built-in)')
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--', label='Ideal')
plt.xlabel('True Values')
plt.ylabel('Predicted Values')
plt.title('Built-in MSE Loss')
plt.legend()

plt.show()









import numpy as np
import xgboost as xgb
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt

# Step 1: Generate synthetic data
np.random.seed(42)
X_train = np.random.rand(100, 5)  # 100 samples, 5 features
y_train = np.exp(10 * X_train[:, 0] + 15 * X_train[:, 1]) + np.random.normal(0, 1e3, 100)  # Larger magnitude function

X_test = np.random.rand(20, 5)  # 20 samples, 5 features
y_test = np.exp(10 * X_test[:, 0] + 15 * X_test[:, 1]) + np.random.normal(0, 1e3, 20)

# Ensure all labels are positive (if necessary)
y_train = np.clip(y_train, 1e-6, None)
y_test = np.clip(y_test, 1e-6, None)

# Create DMatrix for XGBoost
dtrain = xgb.DMatrix(X_train, label=y_train)
dtest = xgb.DMatrix(X_test, label=y_test)

# Step 2: Define the custom loss function
def custom_log_loss(preds, dtrain):
    labels = dtrain.get_label()
    eps = 1e-6  # Small value to prevent division by zero and log issues
    
    # Clip preds to avoid log of zero or negative numbers
    preds = np.clip(preds, eps, None)
    
    # Gradient: -(2(log(y) - log(y_pred)) / y_pred
    grad = -2 * (np.log(labels) - np.log(preds)) / preds
    
    # Hessian: -(2(log(y) + 2log(y_pred) + 2)) / (y_pred^2)
    hess = -2 * (np.log(labels) + 2 * np.log(preds) + 2) / (preds ** 2)
    
    return grad, hess

# Step 3: Train the model using the custom loss function
params = {
    'max_depth': 6,
    'eta': 0.1,
    'seed': 42
}

# Train the model using the custom log-based loss function
model_custom = xgb.train(params, dtrain, num_boost_round=100, obj=custom_log_loss)

# Update the params to use the built-in MSE loss function
params['objective'] = 'reg:squarederror'

# Train the model using the built-in MSE loss function
model_builtin = xgb.train(params, dtrain, num_boost_round=100)

# Make predictions on the test set
preds_custom = model_custom.predict(dtest)
preds_builtin = model_builtin.predict(dtest)

# Calculate the MSE for both models
mse_custom = mean_squared_error(y_test, preds_custom)
mse_builtin = mean_squared_error(y_test, preds_builtin)

print(f"Custom Log-based Loss MSE: {mse_custom}")
print(f"Built-in MSE Loss: {mse_builtin}")

# Step 4: Plot the results
plt.figure(figsize=(12, 6))

plt.subplot(1, 2, 1)
plt.scatter(y_test, preds_custom, color='blue', label='Predicted vs True (Custom)')
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--', label='Ideal')
plt.xlabel('True Values')
plt.ylabel('Predicted Values')
plt.title('Custom Log-based Loss')
plt.legend()

plt.subplot(1, 2, 2)
plt.scatter(y_test, preds_builtin, color='green', label='Predicted vs True (Built-in)')
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--', label='Ideal')
plt.xlabel('True Values')
plt.ylabel('Predicted Values')
plt.title('Built-in MSE Loss')
plt.legend()

plt.show()




import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import matplotlib.pyplot as plt

# Step 1: Define the original loss function
class OriginalLoss(nn.Module):
    def __init__(self):
        super(OriginalLoss, self).__init__()

    def forward(self, preds, labels):
        eps = 1e-6  # Small value to prevent division by zero
        
        # Ensure preds are positive for log transformation
        preds = torch.clamp(preds, min=eps)
        
        # Compute log-transformed predictions
        log_preds = torch.log(preds)
        
        # Compute mu and sigma from the log-transformed predictions
        mu = torch.mean(log_preds)
        sigma = torch.std(log_preds)
        
        # Compute the loss using the original loss function
        term1 = torch.log(sigma * torch.sqrt(torch.tensor(2.0) * torch.tensor(np.pi)))
        term2 = ((log_preds - mu) ** 2) / (2 * sigma ** 2)
        
        loss = torch.mean(term1 + term2)
        return loss

# Step 2: Define a deep neural network model
class DeepNN(nn.Module):
    def __init__(self, input_dim):
        super(DeepNN, self).__init__()
        self.fc1 = nn.Linear(input_dim, 256)
        self.fc2 = nn.Linear(256, 256)
        self.fc3 = nn.Linear(256, 128)
        self.fc4 = nn.Linear(128, 128)
        self.fc5 = nn.Linear(128, 64)
        self.fc6 = nn.Linear(64, 64)
        self.fc7 = nn.Linear(64, 32)
        self.fc8 = nn.Linear(32, 32)
        self.fc9 = nn.Linear(32, 1)
        self.relu = nn.ReLU()

    def forward(self, x):
        out = self.relu(self.fc1(x))
        out = self.relu(self.fc2(out))
        out = self.relu(self.fc3(out))
        out = self.relu(self.fc4(out))
        out = self.relu(self.fc5(out))
        out = self.relu(self.fc6(out))
        out = self.relu(self.fc7(out))
        out = self.relu(self.fc8(out))
        out = self.fc9(out)
        return out

# Step 3: Generate synthetic data with large numbers
np.random.seed(42)
X_train = np.random.rand(100, 5)  # 100 samples, 5 features
y_train = np.exp(10 * X_train[:, 0] + 15 * X_train[:, 1]) + np.random.normal(0, 1e3, 100)

X_test = np.random.rand(20, 5)  # 20 samples, 5 features
y_test = np.exp(10 * X_test[:, 0] + 15 * X_test[:, 1]) + np.random.normal(0, 1e3, 20)

# Convert to PyTorch tensors
X_train_tensor = torch.tensor(X_train, dtype=torch.float32)
y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)

X_test_tensor = torch.tensor(X_test, dtype=torch.float32)
y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)

# Step 4: Instantiate the deep neural network model, loss function, and optimizer
model = DeepNN(input_dim=5)
criterion = OriginalLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Step 5: Train the deep neural network
num_epochs = 5000
for epoch in range(num_epochs):
    model.train()
    
    # Forward pass
    outputs = model(X_train_tensor)
    loss = criterion(outputs, y_train_tensor)
    
    # Backward pass and optimization
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
    
    if (epoch+1) % 50 == 0:
        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')

# Step 6: Evaluate the model
model.eval()
with torch.no_grad():
    preds = model(X_test_tensor).numpy()
    y_test_numpy = y_test_tensor.numpy()

# Step 7: Plot the results
plt.figure(figsize=(10, 6))
plt.scatter(y_test_numpy, preds, color='blue', label='Predicted vs True')
plt.plot([min(y_test_numpy), max(y_test_numpy)], [min(y_test_numpy), max(y_test_numpy)], color='red', linestyle='--', label='Ideal')
plt.xlabel('True Values')
plt.ylabel('Predicted Values')
plt.title('True vs Predicted Values (Deep NN with Original Loss)')
plt.legend()
plt.show()







import numpy as np
import xgboost as xgb

# Custom objective function using the gradient and hessian with mean and std computed from the data
def custom_objective_with_mu_sigma(preds, dtrain):
    labels = dtrain.get_label()
    eps = 1e-6  # Small value to prevent division by zero
    
    # Compute mu and sigma from the predictions
    log_preds = np.log(preds + eps)
    mu = np.mean(log_preds)
    sigma = np.std(log_preds)
    
    # Calculate the gradient
    grad = (log_preds - mu) / (sigma**2 * labels + eps)
    
    # Calculate the hessian
    hess = (1 - log_preds + mu) / (sigma**2 * (labels ** 2) + eps)
    
    return grad, hess

# Example usage in XGBoost
params = {
    'max_depth': 6,
    'eta': 0.1,
    'seed': 42
}

# Assuming X_train, y_train, X_test, and y_test are already defined
dtrain = xgb.DMatrix(X_train, label=y_train)
dtest = xgb.DMatrix(X_test, label=y_test)

# Train the model using the custom objective function
model = xgb.train(params, dtrain, num_boost_round=100, obj=custom_objective_with_mu_sigma)

# Make predictions and evaluate
preds = model.predict(dtest)








import numpy as np
import xgboost as xgb

# Custom objective function with weighted relative squared error
def weighted_relative_squared_error_objective(preds, dtrain, alpha=1):
    labels = dtrain.get_label()
    eps = 1e-6  # Small value to prevent division by zero
    
    # Weighted gradient and hessian
    weights = labels ** alpha
    grad = -2 * weights * (labels - preds) / (labels ** 2 + eps)
    hess = 2 * weights / (labels ** 2 + eps)
    
    return grad, hess

# Example usage in XGBoost
params = {
    'max_depth': 6,
    'eta': 0.1,
    'seed': 42
}

# Assuming X_train, y_train, X_test, and y_test are already defined
dtrain = xgb.DMatrix(X_train, label=y_train)
dtest = xgb.DMatrix(X_test, label=y_test)

# Train the model using the custom weighted relative squared error objective
model = xgb.train(params, dtrain, num_boost_round=100, obj=weighted_relative_squared_error_objective)

# Make predictions and evaluate
preds = model.predict(dtest)

# Compute the weighted relative squared error on the test set
weighted_relative_squared_error = np.mean((y_test ** alpha) * ((y_test - preds) / (y_test + eps)) ** 2)
print(f"Weighted Relative Squared Error: {weighted_relative_squared_error}")








import numpy as np
import xgboost as xgb

# Custom objective function based on sum((y - y_pred)/y)²
def relative_squared_error_objective(preds, dtrain):
    labels = dtrain.get_label()
    eps = 1e-6  # Small value to prevent division by zero
    
    # Calculate the gradient (first derivative of the loss function)
    grad = -2 * (labels - preds) / (labels**2 + eps)
    
    # Calculate the hessian (second derivative of the loss function)
    hess = 2 / (labels**2 + eps)
    
    return grad, hess

# Example usage in XGBoost
params = {
    'max_depth': 6,
    'eta': 0.1,
    'seed': 42
}

# Assuming X_train, y_train, X_test, and y_test are already defined
dtrain = xgb.DMatrix(X_train, label=y_train)
dtest = xgb.DMatrix(X_test, label=y_test)

# Train the model using the custom relative squared error objective
model = xgb.train(params, dtrain, num_boost_round=100, obj=relative_squared_error_objective)

# Make predictions
preds = model.predict(dtest)

# Evaluate the model
relative_squared_error = np.mean(((y_test - preds) / y_test) ** 2)
print(f"Relative Squared Error: {relative_squared_error}")




import xgboost as xgb
import shap
import numpy as np
import pandas as pd

# Assuming X_train, y_train, X_test, y_test are already defined
# and xgb_model is the trained XGBoost model

# Predict the test set
y_pred = xgb_model.predict(X_test)

# Calculate residuals (errors)
residuals = y_test - y_pred

# Set a threshold to define "bad" predictions (high residuals)
# For example, you can define it as 1.5 times the standard deviation of the residuals
threshold = 1.5 * np.std(residuals)

# Get indices of bad predictions
bad_pred_indices = np.where(np.abs(residuals) > threshold)[0]

# Subset the data for bad predictions
X_test_bad = X_test.iloc[bad_pred_indices]
y_test_bad = y_test.iloc[bad_pred_indices]

# Initialize the SHAP explainer
explainer = shap.TreeExplainer(xgb_model)

# Calculate SHAP values for the bad predictions
shap_values_bad = explainer(X_test_bad)

# Select an instance with the highest residual for the waterfall plot
worst_index = np.argmax(np.abs(residuals[bad_pred_indices]))

# Create a SHAP waterfall plot for this specific instance
shap.waterfall_plot(shap_values_bad[worst_index])






import xgboost as xgb
import shap
import numpy as np
import pandas as pd

# Assuming X_train, y_train, X_test, y_test are already defined
# and xgb_model is the trained XGBoost model

# Predict the test set
y_pred = xgb_model.predict(X_test)

# Calculate residuals (errors)
residuals = y_test - y_pred

# Set a threshold to define "bad" predictions (high residuals)
# For example, you can define it as 1.5 times the standard deviation of the residuals
threshold = 1.5 * np.std(residuals)

# Get indices of bad predictions
bad_pred_indices = np.where(np.abs(residuals) > threshold)[0]

# Subset the data for bad predictions
X_test_bad = X_test.iloc[bad_pred_indices]
y_test_bad = y_test.iloc[bad_pred_indices]

# Initialize the SHAP explainer
explainer = shap.TreeExplainer(xgb_model)

# Calculate SHAP values for the bad predictions
shap_values_bad = explainer.shap_values(X_test_bad)

# Convert SHAP values into a DataFrame for easier analysis
shap_values_df = pd.DataFrame(shap_values_bad, columns=X_test.columns)

# Display the mean absolute SHAP values to understand the most influential features
shap_mean_abs = shap_values_df.abs().mean().sort_values(ascending=False)

# Show the features with the highest mean absolute SHAP values
print("Top features contributing to bad predictions:")
print(shap_mean_abs.head(10))

# Optional: Visualize the SHAP summary plot for bad predictions
shap.summary_plot(shap_values_bad, X_test_bad)

# Optional: Visualize SHAP dependence plot for the most important feature
top_feature = shap_mean_abs.index[0]
shap.dependence_plot(top_feature, shap_values_bad, X_test_bad)











import numpy as np
import xgboost as xgb

# Simplified custom loss function (ZILN-like approximation)
def ziln_objective(preds, dtrain):
    labels = dtrain.get_label()
    eps = 1e-6
    
    # Predict the probability that y > 0 using the sigmoid function
    p = 1 / (1 + np.exp(-preds))
    
    # Gradient (first derivative of the loss)
    grad = np.zeros_like(preds)
    grad[labels == 0] = p[labels == 0]  # For y=0
    grad[labels > 0] = p[labels > 0] - 1  # For y > 0

    # Hessian (second derivative of the loss)
    hess = np.zeros_like(preds)
    hess[labels == 0] = p[labels == 0] * (1 - p[labels == 0])
    hess[labels > 0] = p[labels > 0] * (1 - p[labels > 0])

    return grad, hess

# Example usage in XGBoost
params = {
    'max_depth': 6,
    'eta': 0.1,
    'seed': 42
}

# Create example dataset
dtrain = xgb.DMatrix(X_train, label=y_train)
dtest = xgb.DMatrix(X_test, label=y_test)

# Train the model using the custom objective
model = xgb.train(params, dtrain, num_boost_round=100, obj=ziln_objective)

# Make predictions and evaluate
preds = model.predict(dtest)




import numpy as np

def ziln_loss(preds, labels):
    # To prevent log(0) errors
    eps = 1e-6
    
    # Predict the probability that y > 0 using the sigmoid function
    p = 1 / (1 + np.exp(-preds))
    
    # Split the data into zero and non-zero parts
    zero_mask = labels == 0
    nonzero_mask = labels > 0
    
    # For y = 0, the loss is -log(1 - p)
    loss_zero = -np.log(1 - p[zero_mask] + eps)
    
    # For y > 0, compute the log of the labels
    log_labels = np.log(labels[nonzero_mask] + eps)
    
    # Calculate mu (mean of the log-transformed values) and sigma (standard deviation)
    mu = np.mean(log_labels)
    sigma = np.std(log_labels)
    
    # Loss for non-zero y
    loss_nonzero = (
        -np.log(p[nonzero_mask] + eps) 
        + np.log(sigma * np.sqrt(2 * np.pi) + eps) 
        + ((log_labels - mu) ** 2) / (2 * sigma ** 2 + eps)
    )
    
    # Combine the losses
    total_loss = np.sum(loss_zero) + np.sum(loss_nonzero)
    
    return 'ziln_loss', total_loss

# Example usage with predictions and actual labels
preds = np.array([0.1, 0.9, 2.0, 0.0])  # Example predictions (logits)
labels = np.array([0, 1, 10, 0])        # Example actual values (CLV)
loss_name, loss_value = ziln_loss(preds, labels)
print(f"{loss_name}: {loss_value}")










import numpy as np

def improved_ziln_eval_metric(preds, dtrain):
    labels = dtrain.get_label()
    eps = 1e-6
    
    # Step 1: Calculate the probability p for the Bernoulli part using sigmoid
    p = 1 / (1 + np.exp(-preds))
    
    # Step 2: Separate the data into zero and non-zero cases
    zero_mask = labels == 0
    nonzero_mask = labels > 0
    
    # Step 3: Bernoulli Loss Component
    bernoulli_loss = - np.mean(
        zero_mask * np.log(1 - p + eps) + nonzero_mask * np.log(p + eps)
    )
    
    # Step 4: Lognormal Loss Component for non-zero values
    log_preds = np.log(preds[nonzero_mask] + eps)
    log_labels = np.log(labels[nonzero_mask] + eps)
    
    # Estimate the variance (sigma^2) for lognormal distribution
    variance = np.var(log_labels)
    
    # Lognormal loss function with explicit variance handling
    lognormal_loss = 0.5 * np.mean(
        ((log_labels - log_preds) ** 2) / variance + np.log(variance + eps)
    )
    
    # Combine the Bernoulli and Lognormal losses
    total_loss = bernoulli_loss + lognormal_loss
    
    return 'improved_ziln_eval', total_loss



import xgboost as xgb
import matplotlib.pyplot as plt
import numpy as np
from scipy.stats import spearmanr

# Assuming ziln_eval_metric is a custom function defined elsewhere
def ziln_eval_metric(preds, dtrain):
    labels = dtrain.get_label()
    residuals = preds - labels
    ziln_loss = np.mean(np.log1p(residuals**2))  # Example, actual ZiLn metric may differ
    return 'ziln_loss', ziln_loss

def train_evaluate(df, target_var):
    # Prepare data
    X = df.drop(columns=[target_var])
    y = df[target_var]
    
    # Split data into train and test sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    # Create DMatrix for XGBoost
    dtrain = xgb.DMatrix(X_train, label=y_train)
    dtest = xgb.DMatrix(X_test, label=y_test)
    
    # XGBoost params for standard model
    params = {
        'objective': 'reg:squarederror',
        'eval_metric': 'rmse',
        'max_depth': 6,
        'eta': 0.1,
        'seed': 42
    }
    
    # Train standard XGBoost model
    model_standard = xgb.train(params, dtrain, num_boost_round=100)
    preds_standard = model_standard.predict(dtest)
    
    # Train XGBoost model with custom ZILN metric evaluation
    model_ziln = xgb.train(params, dtrain, num_boost_round=100, feval=ziln_eval_metric)
    preds_ziln = model_ziln.predict(dtest)
    
    # Compute and print ZILN loss
    ziln_loss = ziln_eval_metric(preds_ziln, dtest)[1]
    print(f"\nZiLn Loss: {ziln_loss:.4f}")
    
    # Plot predictions vs actuals
    plt.figure(figsize=(14, 7))
    
    plt.subplot(1, 2, 1)
    plt.scatter(y_test, preds_standard, alpha=0.3)
    plt.title('Standard XGBoost: Predictions vs Actuals (Test Set)')
    plt.xlabel('Actuals')
    plt.ylabel('Predictions')
    
    plt.subplot(1, 2, 2)
    plt.scatter(y_test, preds_ziln, alpha=0.3)
    plt.title('XGBoost with ZILN Metric: Predictions vs Actuals (Test Set)')
    plt.xlabel('Actuals')
    plt.ylabel('Predictions')
    
    plt.show()
    
    # Plot residuals vs actuals
    residuals_ziln = y_test - preds_ziln
    plt.figure(figsize=(7, 7))
    plt.scatter(y_test, residuals_ziln, alpha=0.3)
    plt.axhline(0, color='red', linestyle='--')
    plt.title('Residuals vs Actuals (ZILN Model)')
    plt.xlabel('Actuals')
    plt.ylabel('Residuals')
    plt.show()
    
    # Compute metrics
    def gini(actual, pred):
        all = np.asarray(np.c_[actual, pred, np.arange(len(actual))], dtype=np.float)
        all = all[np.lexsort((all[:, 2], -1 * all[:, 1]))]
        total_losses = all[:, 0].sum()
        gini_sum = all[:, 0].cumsum().sum() / total_losses
        
        gini_sum -= (len(actual) + 1) / 2.
        return gini_sum / len(actual)
    
    def normalized_gini(actual, pred):
        return gini(actual, pred) / gini(actual, actual)
    
    metrics = {
        'Spearman Rank Correlation': spearmanr(y_test, preds_ziln).correlation,
        'Normalized Gini (Standard)': normalized_gini(y_test, preds_standard),
        'Normalized Gini (ZILN)': normalized_gini(y_test, preds_ziln),
        'Decile MAPE (Standard)': np.mean(np.abs((y_test - preds_standard) / y_test)) * 100,
        'Decile MAPE (ZILN)': np.mean(np.abs((y_test - preds_ziln) / y_test)) * 100,
    }
    
    print("\nModel Comparison Metrics:")
    for k, v in metrics.items():
        print(f"{k}: {v:.4f}")

# Example usage with a DataFrame `df` and target variable `target_var`
# df = pd.DataFrame(...)
# train_evaluate(df, 'target_var')









from sklearn.model_selection import train_test_split

def train_evaluate(df, target_var):
    # Prepare data
    X = df.drop(columns=[target_var])
    y = df[target_var]
    
    # Split data into train and test sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    # Create DMatrix for XGBoost
    dtrain = xgb.DMatrix(X_train, label=y_train)
    dtest = xgb.DMatrix(X_test, label=y_test)
    
    # XGBoost params for standard model
    params = {
        'objective': 'reg:squarederror',
        'eval_metric': 'rmse',
        'max_depth': 6,
        'eta': 0.1,
        'seed': 42
    }
    
    # Train standard XGBoost model
    model_standard = xgb.train(params, dtrain, num_boost_round=100)
    preds_standard = model_standard.predict(dtest)
    
    # Train XGBoost model with custom ZILN metric evaluation
    model_ziln = xgb.train(params, dtrain, num_boost_round=100, feval=ziln_eval_metric)
    preds_ziln = model_ziln.predict(dtest)
    
    # Plot predictions vs actuals
    plt.figure(figsize=(14, 7))
    
    plt.subplot(1, 2, 1)
    plt.scatter(y_test, preds_standard, alpha=0.3)
    plt.title('Standard XGBoost: Predictions vs Actuals (Test Set)')
    plt.xlabel('Actuals')
    plt.ylabel('Predictions')
    
    plt.subplot(1, 2, 2)
    plt.scatter(y_test, preds_ziln, alpha=0.3)
    plt.title('XGBoost with ZILN Metric: Predictions vs Actuals (Test Set)')
    plt.xlabel('Actuals')
    plt.ylabel('Predictions')
    
    plt.show()
    
    # Compute metrics
    def gini(actual, pred):
        all = np.asarray(np.c_[actual, pred, np.arange(len(actual))], dtype=np.float)
        all = all[np.lexsort((all[:, 2], -1 * all[:, 1]))]
        total_losses = all[:, 0].sum()
        gini_sum = all[:, 0].cumsum().sum() / total_losses
        
        gini_sum -= (len(actual) + 1) / 2.
        return gini_sum / len(actual)
    
    def normalized_gini(actual, pred):
        return gini(actual, pred) / gini(actual, actual)
    
    metrics = {
        'Spearman Rank Correlation': spearmanr(y_test, preds_ziln).correlation,
        'Normalized Gini (Standard)': normalized_gini(y_test, preds_standard),
        'Normalized Gini (ZILN)': normalized_gini(y_test, preds_ziln),
        'Decile MAPE (Standard)': np.mean(np.abs((y_test - preds_standard) / y_test)) * 100,
        'Decile MAPE (ZILN)': np.mean(np.abs((y_test - preds_ziln) / y_test)) * 100,
    }
    
    print("\nModel Comparison Metrics:")
    for k, v in metrics.items():
        print(f"{k}: {v:.4f}")

# Example usage with a DataFrame `df` and target variable `target_var`
# df = pd.DataFrame(...)
# train_evaluate(df, 'target_var')









import numpy as np
import pandas as pd
import xgboost as xgb
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error
from scipy.stats import spearmanr

# Custom ZILN evaluation metric
def ziln_eval_metric(preds, dtrain):
    labels = dtrain.get_label()
    eps = 1e-6
    p = 1 / (1 + np.exp(-preds))
    nonzero_mask = labels > 0
    log_preds = np.log(preds[nonzero_mask] + eps)
    log_labels = np.log(labels[nonzero_mask] + eps)
    loss = np.mean(- labels * np.log(p + eps) - (1 - labels) * np.log(1 - p + eps))
    loss += 0.5 * np.mean((log_preds - log_labels) ** 2)
    return 'ziln_eval', loss

# Train and evaluate models
def train_evaluate(df, target_var):
    # Prepare data
    X = df.drop(columns=[target_var])
    y = df[target_var]
    
    # Split data into DMatrix
    dtrain = xgb.DMatrix(X, label=y)
    
    # XGBoost params for standard model
    params = {
        'objective': 'reg:squarederror',
        'eval_metric': 'rmse',
        'max_depth': 6,
        'eta': 0.1,
        'seed': 42
    }
    
    # Train standard XGBoost model
    model_standard = xgb.train(params, dtrain, num_boost_round=100)
    preds_standard = model_standard.predict(dtrain)
    
    # Train XGBoost model with custom ZILN metric evaluation
    model_ziln = xgb.train(params, dtrain, num_boost_round=100, feval=ziln_eval_metric)
    preds_ziln = model_ziln.predict(dtrain)
    
    # Plot predictions vs actuals
    plt.figure(figsize=(14, 7))
    
    plt.subplot(1, 2, 1)
    plt.scatter(y, preds_standard, alpha=0.3)
    plt.title('Standard XGBoost: Predictions vs Actuals')
    plt.xlabel('Actuals')
    plt.ylabel('Predictions')
    
    plt.subplot(1, 2, 2)
    plt.scatter(y, preds_ziln, alpha=0.3)
    plt.title('XGBoost with ZILN Metric: Predictions vs Actuals')
    plt.xlabel('Actuals')
    plt.ylabel('Predictions')
    
    plt.show()
    
    # Compute metrics
    def gini(actual, pred):
        all = np.asarray(np.c_[actual, pred, np.arange(len(actual))], dtype=np.float)
        all = all[np.lexsort((all[:, 2], -1 * all[:, 1]))]
        total_losses = all[:, 0].sum()
        gini_sum = all[:, 0].cumsum().sum() / total_losses
        
        gini_sum -= (len(actual) + 1) / 2.
        return gini_sum / len(actual)
    
    def normalized_gini(actual, pred):
        return gini(actual, pred) / gini(actual, actual)
    
    metrics = {
        'Spearman Rank Correlation': spearmanr(y, preds_ziln).correlation,
        'Normalized Gini (Standard)': normalized_gini(y, preds_standard),
        'Normalized Gini (ZILN)': normalized_gini(y, preds_ziln),
        'Decile MAPE (Standard)': np.mean(np.abs((y - preds_standard) / y)) * 100,
        'Decile MAPE (ZILN)': np.mean(np.abs((y - preds_ziln) / y)) * 100,
    }
    
    print("\nModel Comparison Metrics:")
    for k, v in metrics.items():
        print(f"{k}: {v:.4f}")

# Example usage with a DataFrame `df` and target variable `target_var`
# df = pd.DataFrame(...)
# train_evaluate(df, 'target_var')




import numpy as np
import pandas as pd
import xgboost as xgb
import matplotlib.pyplot as plt
from sklearn.metrics import make_scorer, roc_auc_score, mean_squared_error
from scipy.stats import spearmanr

# Define custom ZILN loss function (approximation)
def ziln_loss(preds, dtrain):
    labels = dtrain.get_label()
    eps = 1e-6
    # Bernoulli component (for zero vs non-zero LTV)
    p = 1 / (1 + np.exp(-preds))  # Sigmoid for probability
    bernoulli_loss = - labels * np.log(p + eps) - (1 - labels) * np.log(1 - p + eps)

    # Lognormal component (for non-zero LTV)
    nonzero_mask = labels > 0
    log_preds = np.log(preds[nonzero_mask] + eps)
    log_labels = np.log(labels[nonzero_mask] + eps)
    lognormal_loss = 0.5 * (log_preds - log_labels) ** 2
    
    # Combine losses
    loss = np.mean(bernoulli_loss) + np.mean(lognormal_loss)
    return 'ziln_loss', loss

# Custom evaluation metric (approximation of ZILN)
def ziln_eval_metric(preds, dtrain):
    labels = dtrain.get_label()
    eps = 1e-6
    p = 1 / (1 + np.exp(-preds))
    nonzero_mask = labels > 0
    log_preds = np.log(preds[nonzero_mask] + eps)
    log_labels = np.log(labels[nonzero_mask] + eps)
    loss = np.mean(- labels * np.log(p + eps) - (1 - labels) * np.log(1 - p + eps))
    loss += 0.5 * np.mean((log_preds - log_labels) ** 2)
    return 'ziln_eval', loss

# Train and evaluate models
def train_evaluate(df, target_var):
    # Prepare data
    X = df.drop(columns=[target_var])
    y = df[target_var]
    
    # Split data into DMatrix
    dtrain = xgb.DMatrix(X, label=y)
    
    # XGBoost params for standard model
    params = {
        'objective': 'reg:squarederror',
        'eval_metric': 'rmse',
        'max_depth': 6,
        'eta': 0.1,
        'seed': 42
    }
    
    # Train standard XGBoost model
    model_standard = xgb.train(params, dtrain, num_boost_round=100)
    preds_standard = model_standard.predict(dtrain)
    
    # XGBoost params for ZILN model
    params_ziln = {
        'objective': ziln_loss,
        'eval_metric': ziln_eval_metric,
        'max_depth': 6,
        'eta': 0.1,
        'seed': 42
    }
    
    # Train XGBoost model with custom ZILN loss
    model_ziln = xgb.train(params_ziln, dtrain, num_boost_round=100)
    preds_ziln = model_ziln.predict(dtrain)
    
    # Plot predictions vs actuals
    plt.figure(figsize=(14, 7))
    
    plt.subplot(1, 2, 1)
    plt.scatter(y, preds_standard, alpha=0.3)
    plt.title('Standard XGBoost: Predictions vs Actuals')
    plt.xlabel('Actuals')
    plt.ylabel('Predictions')
    
    plt.subplot(1, 2, 2)
    plt.scatter(y, preds_ziln, alpha=0.3)
    plt.title('XGBoost with ZILN Loss: Predictions vs Actuals')
    plt.xlabel('Actuals')
    plt.ylabel('Predictions')
    
    plt.show()
    
    # Compute metrics
    def gini(actual, pred):
        all = np.asarray(np.c_[actual, pred, np.arange(len(actual))], dtype=np.float)
        all = all[np.lexsort((all[:, 2], -1 * all[:, 1]))]
        total_losses = all[:, 0].sum()
        gini_sum = all[:, 0].cumsum().sum() / total_losses
        
        gini_sum -= (len(actual) + 1) / 2.
        return gini_sum / len(actual)
    
    def normalized_gini(actual, pred):
        return gini(actual, pred) / gini(actual, actual)
    
    metrics = {
        'Spearman Rank Correlation': spearmanr(y, preds_ziln).correlation,
        'Normalized Gini (Standard)': normalized_gini(y, preds_standard),
        'Normalized Gini (ZILN)': normalized_gini(y, preds_ziln),
        'Decile MAPE (Standard)': np.mean(np.abs((y - preds_standard) / y)) * 100,
        'Decile MAPE (ZILN)': np.mean(np.abs((y - preds_ziln) / y)) * 100,
    }
    
    print("\nModel Comparison Metrics:")
    for k, v in metrics.items():
        print(f"{k}: {v:.4f}")

# Example usage with a DataFrame `df` and target variable `target_var`
# df = pd.DataFrame(...)
# train_evaluate(df, 'target_var')







import pandas as pd
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score, mean_squared_error
import numpy as np
import matplotlib.pyplot as plt

def train_xgboost_and_evaluate(df, seg, target):
    # Split the dataframe into two based on the segmentation value
    df1 = df[df[target] <= seg]
    df2 = df[df[target] > seg]
    
    def train_and_evaluate(df_segment):
        # Separate features and target
        X = df_segment.drop(columns=[target])
        y = df_segment[target]

        # Split the data into training and testing sets
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

        # Train an XGBoost model
        model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)
        model.fit(X_train, y_train)

        # Predict and evaluate the model
        y_pred = model.predict(X_test)
        r2 = r2_score(y_test, y_pred)
        rmse = np.sqrt(mean_squared_error(y_test, y_pred))
        
        return r2, rmse, y_test, y_pred

    # Train and evaluate both segments
    r2_1, rmse_1, y_test_1, y_pred_1 = train_and_evaluate(df1)
    r2_2, rmse_2, y_test_2, y_pred_2 = train_and_evaluate(df2)

    # Display R² and RMSE for both segments
    print(f"Segment 1 (y <= {seg}): R² = {r2_1:.4f}, RMSE = {rmse_1:.4f}")
    print(f"Segment 2 (y > {seg}): R² = {r2_2:.4f}, RMSE = {rmse_2:.4f}")
    
    # Plot the predictions vs actuals for a small sample of y_test
    def plot_predictions(y_test, y_pred, segment):
        sorted_indices = np.argsort(y_test)
        y_test_sorted = y_test.iloc[sorted_indices]
        y_pred_sorted = y_pred[sorted_indices]

        plt.figure(figsize=(10, 5))
        plt.plot(y_test_sorted.values, label='Actual Y')
        plt.plot(y_pred_sorted, label='Predicted Y', linestyle='--')
        plt.title(f'Y Test vs Y Predicted for Segment {segment}')
        plt.legend()
        plt.show()
    
    # Plot for segment 1
    plot_predictions(y_test_1, y_pred_1, 1)
    
    # Plot for segment 2
    plot_predictions(y_test_2, y_pred_2, 2)

# Example usage:
# df = pd.DataFrame(...)  # Your dataframe
# train_xgboost_and_evaluate(df, seg=50.0, target='your_target_column')









import numpy as np
import xgboost as xgb
from sklearn.metrics import mean_absolute_error

# Define example data (replace with your actual dataset)
X_train_scaled = np.random.rand(8000, 10)
X_test_scaled = np.random.rand(2000, 10)
y_train = np.random.rand(8000)
y_test = np.random.rand(2000)

# Train a model to predict p (probability of non-zero CLV)
dtrain_p = xgb.DMatrix(X_train_scaled, label=(y_train > 0).astype(int))
dtest_p = xgb.DMatrix(X_test_scaled)

params_p = {
    'objective': 'binary:logistic',  # Binary classification for p
    'max_depth': 6,
    'eta': 0.1,
    'seed': 42
}

xgb_model_p = xgb.train(params_p, dtrain_p, num_boost_round=100)

# Train a model to predict mu (log of CLV for non-zero cases)
non_zero_indices = y_train > 0
dtrain_mu = xgb.DMatrix(X_train_scaled[non_zero_indices], label=np.log(y_train[non_zero_indices]))
dtest_mu = xgb.DMatrix(X_test_scaled)

params_mu = {
    'objective': 'reg:squarederror',  # Regression for mu
    'max_depth': 6,
    'eta': 0.1,
    'seed': 42
}

xgb_model_mu = xgb.train(params_mu, dtrain_mu, num_boost_round=100)

# Train a model to predict sigma (standard deviation of log CLV)
sigma_train = np.full_like(y_train[non_zero_indices], 0.5)  # Example fixed sigma, replace with actual calculation if needed
dtrain_sigma = xgb.DMatrix(X_train_scaled[non_zero_indices], label=sigma_train)
dtest_sigma = xgb.DMatrix(X_test_scaled)

params_sigma = {
    'objective': 'reg:squarederror',  # Regression for sigma
    'max_depth': 6,
    'eta': 0.1,
    'seed': 42
}

xgb_model_sigma = xgb.train(params_sigma, dtrain_sigma, num_boost_round=100)

# Make predictions
p_pred = xgb_model_p.predict(dtest_p)
mu_pred = xgb_model_mu.predict(dtest_mu)
sigma_pred = xgb_model_sigma.predict(dtest_sigma)

# Compute final predicted CLV
expected_clv_pred = p_pred * np.exp(mu_pred + 0.5 * sigma_pred ** 2)
expected_clv_pred = np.nan_to_num(expected_clv_pred, nan=0.0, posinf=0.0, neginf=0.0)

# Evaluate the performance
mae_custom = mean_absolute_error(y_test, expected_clv_pred)

# Print evaluation metrics
print(f"XGBoost with Custom ZILN Loss - MAE: {mae_custom:.2f}")

# You can compare this to a standard XGBoost model as follows:

# Training with Default Loss
params_default = {
    'objective': 'reg:squarederror',  # Standard squared error for comparison
    'max_depth': 6,
    'eta': 0.1,
    'seed': 42
}

dtrain_default = xgb.DMatrix(X_train_scaled, label=y_train)
xgb_model_default = xgb.train(params_default, dtrain_default, num_boost_round=100)

# Predictions with default model
preds_default = xgb_model_default.predict(dtest_p)

# Evaluate default model
mae_default = mean_absolute_error(y_test, preds_default)

print(f"XGBoost with Default Loss - MAE: {mae_default:.2f}")






import numpy as np
import pandas as pd

def generate_simplified_clv_dataset(n_customers=10000, random_seed=42):
    np.random.seed(random_seed)
    
    # Feature: Recency (days since last purchase)
    recency = np.random.exponential(scale=30, size=n_customers)  # Average 30 days
    
    # Feature: Frequency (number of purchases in the last year)
    frequency = np.random.poisson(lam=3, size=n_customers)  # Average 3 purchases
    
    # Feature: Monetary Value (average purchase amount)
    monetary_value = np.random.normal(loc=50, scale=10, size=n_customers)  # Average $50
    
    # Feature: Tenure (days since first purchase)
    tenure = np.random.exponential(scale=365, size=n_customers)  # Average 1 year
    
    # Feature: Age
    age = np.random.normal(loc=35, scale=10, size=n_customers)  # Average age 35
    
    # Feature: Income
    income = np.random.normal(loc=60000, scale=15000, size=n_customers)  # Average $60k
    
    # Generate CLV (target variable)
    recency_scaled = (recency - recency.mean()) / recency.std()
    frequency_scaled = (frequency - frequency.mean()) / frequency.std()
    tenure_scaled = (tenure - tenure.mean()) / tenure.std()
    
    # Logistic function to compute zero probability
    zero_logit = -1.0 + 0.5 * recency_scaled - 0.5 * frequency_scaled - 0.3 * tenure_scaled
    zero_prob = 1 / (1 + np.exp(-zero_logit))
    
    # Determine zero or non-zero CLV
    is_zero = np.random.binomial(1, zero_prob)
    
    # For non-zero CLV, generate from log-normal distribution
    mu = 2 + 0.3 * frequency_scaled + 0.4 * (monetary_value - monetary_value.mean()) / monetary_value.std() + 0.2 * tenure_scaled
    sigma = 0.5  # Standard deviation
    
    clv = np.zeros(n_customers)
    non_zero_indices = np.where(is_zero == 0)[0]
    clv[non_zero_indices] = np.exp(np.random.normal(mu[non_zero_indices], sigma))
    
    # Combine features into a DataFrame
    df = pd.DataFrame({
        'recency': recency,
        'frequency': frequency,
        'monetary_value': monetary_value,
        'tenure': tenure,
        'age': age,
        'income': income,
        'clv': clv
    })
    
    return df

# Generate the dataset
df = generate_simplified_clv_dataset()
print(df.head())


from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# Separate features and target
X = df.drop('clv', axis=1)
y = df['clv']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scaling numerical features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)


import tensorflow as tf
from tensorflow.keras import layers, models

def safe_log(x):
    return tf.math.log(tf.maximum(x, 1e-6))

def ziln_loss(y_true, y_pred):
    p = y_pred[:, 0]
    mu = y_pred[:, 1]
    sigma = y_pred[:, 2]
    is_zero = tf.cast(tf.equal(y_true, 0), tf.float32)
    is_non_zero = 1.0 - is_zero
    epsilon = 1e-6
    ce_loss = -is_zero * safe_log(1.0 - p + epsilon) - is_non_zero * safe_log(p + epsilon)
    ln_loss = is_non_zero * (safe_log(y_true + epsilon) - mu) ** 2 / (2 * (sigma + epsilon) ** 2) + \
              safe_log(sigma + epsilon) + 0.5 * np.log(2 * np.pi)
    total_loss = ce_loss + ln_loss
    return tf.reduce_mean(total_loss)

def build_dnn_ziln_model(input_dim):
    inputs = layers.Input(shape=(input_dim,))
    x = layers.Dense(128, activation='relu')(inputs)
    x = layers.Dense(64, activation='relu')(x)
    p = layers.Dense(1, activation='sigmoid')(x)
    mu = layers.Dense(1)(x)
    sigma = layers.Dense(1, activation='softplus')(x)
    outputs = layers.Concatenate()([p, mu, sigma])
    model = models.Model(inputs=inputs, outputs=outputs)
    model.compile(optimizer='adam', loss=ziln_loss)
    return model

# Build and train the model
input_dim = X_train_scaled.shape[1]
model = build_dnn_ziln_model(input_dim)

# Train the model
history = model.fit(X_train_scaled, y_train.values, epochs=50, batch_size=256, validation_split=0.2)



import xgboost as xgb

# Prepare DMatrix for XGBoost
dtrain = xgb.DMatrix(X_train_scaled, label=y_train)
dtest = xgb.DMatrix(X_test_scaled)

# Define parameters
params = {
    'objective': 'reg:squarederror',
    'eval_metric': 'rmse',
    'max_depth': 6,
    'eta': 0.1,
    'seed': 42
}

# Train the model
xgb_model = xgb.train(params, dtrain, num_boost_round=100)


# DNN Predictions
preds = model.predict(X_test_scaled)
p_pred = preds[:, 0]
mu_pred = preds[:, 1]
sigma_pred = preds[:, 2]

# Expected CLV from DNN
expected_clv_pred = p_pred * np.exp(mu_pred + 0.5 * sigma_pred ** 2)
expected_clv_pred = np.nan_to_num(expected_clv_pred, nan=0.0, posinf=0.0, neginf=0.0)  # Handle potential NaNs or Infs

# XGBoost Predictions
xgb_pred = xgb_model.predict(dtest)



from sklearn.metrics import mean_absolute_error

def gini(y_true, y_pred):
    arr = np.array(np.c_[y_true, y_pred, np.arange(len(y_true))], dtype=np.float64)
    arr = arr[np.lexsort((arr[:,2], -1*arr[:,1]))]
    total_losses = arr[:,0].sum()
    gini_sum = arr[:,0].cumsum().sum() / total_losses
    gini_sum -= (len(y_true) + 1) / 2.
    return gini_sum / len(y_true)

def normalized_gini(y_true, y_pred):
    return gini(y_true, y_pred) / gini(y_true, y_true)

# DNN Evaluation
mae_dnn = mean_absolute_error(y_test, expected_clv_pred)
gini_dnn = normalized_gini(y_test, expected_clv_pred)

# XGBoost Evaluation
mae_xgb = mean_absolute_error(y_test, xgb_pred)
gini_xgb = normalized_gini(y_test, xgb_pred)

print(f"DNN with ZILN Loss - MAE: {mae_dnn:.2f}, Gini: {gini_dnn:.4f}")
print(f"XGBoost - MAE: {mae_xgb:.2f}, Gini: {gini_xgb:.4f}")



import matplotlib.pyplot as plt

def plot_decile_chart(y_true, y_pred, model_name):
    df_plot = pd.DataFrame({'Actual CLV': y_true, 'Predicted CLV': y_pred})
    df_plot['Decile'] = pd.qcut(df_plot['Predicted CLV'], 10, labels=False, duplicates='drop')
    decile_summary = df_plot.groupby('Decile').agg({'Actual CLV': 'mean', 'Predicted CLV': 'mean'}).reset_index()
    plt.figure(figsize=(10,6))
    plt.plot(decile_summary['Decile'], decile_summary['Actual CLV'], label='Actual CLV', marker='o')
    plt.plot(decile_summary['Decile'], decile_summary['Predicted CLV'], label='Predicted CLV', marker='o')
    plt.title(f'Decile Chart - {model_name}')
    plt.xlabel('Decile (0 = Lowest Predicted CLV)')
    plt.ylabel('Mean CLV')
    plt.legend()
    plt.show()

# Plot for DNN
plot_decile_chart(y_test.values, expected_clv_pred, 'DNN with ZILN Loss')

# Plot for XGBoost
plot_decile_chart(y_test.values, xgb_pred, 'XGBoost')





import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras import layers, models
import xgboost as xgb
from sklearn.metrics import mean_absolute_error
import matplotlib.pyplot as plt
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.model_selection import train_test_split

# 1. Generate Synthetic Dataset
def generate_synthetic_data(n_customers=10000, p_zero=0.7, mu=3, sigma=1):
    np.random.seed(42)  # For reproducibility
    
    # Features
    age = np.random.randint(18, 70, size=n_customers)
    income = np.random.normal(50000, 15000, size=n_customers)
    region = np.random.choice(['North', 'South', 'East', 'West'], size=n_customers)
    num_purchases = np.random.randint(1, 20, size=n_customers)
    loyalty_score = np.random.uniform(0, 100, size=n_customers)
    
    # Generate CLV
    clv = np.zeros(n_customers)
    non_zero_mask = np.random.rand(n_customers) > p_zero
    clv[non_zero_mask] = np.exp(np.random.normal(mu, sigma, size=np.sum(non_zero_mask)))
    
    # Create DataFrame
    data = pd.DataFrame({
        'age': age,
        'income': income,
        'region': region,
        'num_purchases': num_purchases,
        'loyalty_score': loyalty_score,
        'clv': clv
    })
    
    return data

data = generate_synthetic_data()

# 2. Preprocessing
# One-Hot Encoding for categorical features
encoder = OneHotEncoder(sparse=False)
encoded_region = encoder.fit_transform(data[['region']])

# Scaling numerical features
scaler = StandardScaler()
scaled_features = scaler.fit_transform(data[['age', 'income', 'num_purchases', 'loyalty_score']])

# Combine preprocessed features
X = np.hstack([scaled_features, encoded_region])
y = data['clv'].values

# Split into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 3. Implement the DNN with ZILN Loss
def safe_log(x):
    return tf.math.log(tf.maximum(x, 1e-6))

def ziln_loss(y_true, y_pred):
    p, mu, sigma = y_pred[:, 0], y_pred[:, 1], y_pred[:, 2]
    is_zero = tf.cast(tf.equal(y_true, 0), tf.float32)
    
    # Cross-entropy loss for zero-inflation
    cross_entropy_loss = is_zero * -tf.math.log(1 - p + 1e-6) + (1 - is_zero) * -tf.math.log(p + 1e-6)
    
    # Lognormal loss for non-zero CLV
    lognormal_loss = (1 - is_zero) * (safe_log(y_true) - mu)**2 / (2 * sigma**2) + safe_log(sigma) + safe_log(y_true) * sigma
    
    return tf.reduce_mean(cross_entropy_loss + lognormal_loss)

def build_dnn_model(input_dim):
    inputs = layers.Input(shape=(input_dim,))
    x = layers.Dense(64, activation='relu', kernel_initializer='he_normal')(inputs)
    x = layers.Dense(32, activation='relu', kernel_initializer='he_normal')(x)
    
    p = layers.Dense(1, activation='sigmoid')(x)
    mu = layers.Dense(1)(x)
    sigma = layers.Dense(1, activation='softplus')(x)
    
    outputs = layers.Concatenate()([p, mu, sigma])
    
    model = models.Model(inputs, outputs)
    model.compile(optimizer='adam', loss=ziln_loss)
    return model

# Build and train the model
input_dim = X_train.shape[1]
model_dnn = build_dnn_model(input_dim)
model_dnn.fit(X_train, y_train, epochs=50, batch_size=256, validation_split=0.2, verbose=1)

# Predict with the DNN model
preds_dnn = model_dnn.predict(X_test)
preds_dnn_clv = preds_dnn[:, 1]  # Use the predicted mean of the lognormal distribution

# Handle NaN values
preds_dnn_clv = np.nan_to_num(preds_dnn_clv, nan=0.0, posinf=0.0, neginf=0.0)

# 4. Implement a Baseline XGBoost Model
dtrain = xgb.DMatrix(X_train, label=y_train)
dtest = xgb.DMatrix(X_test)

params = {
    'objective': 'reg:squarederror',
    'max_depth': 6,
    'eta': 0.1,
    'subsample': 0.8,
    'colsample_bytree': 0.8,
}

model_xgb = xgb.train(params, dtrain, num_boost_round=100)
preds_xgb = model_xgb.predict(dtest)

# 5. Evaluate and Compare the Models
def gini(y_true, y_pred):
    all = np.asarray(np.c_[y_true, y_pred, np.arange(len(y_true))], dtype=np.float64)
    all = all[np.lexsort((all[:, 2], -1 * all[:, 1]))]
    total_losses = all[:, 0].sum()
    gini_sum = all[:, 0].cumsum().sum() / total_losses

    gini_sum -= (len(y_true) + 1) / 2.
    return gini_sum / len(y_true)

def normalized_gini(y_true, y_pred):
    return gini(y_true, y_pred) / gini(y_true, y_true)

# Calculate metrics
gini_dnn = normalized_gini(y_test, preds_dnn_clv)
gini_xgb = normalized_gini(y_test, preds_xgb)

mae_dnn = mean_absolute_error(y_test, preds_dnn_clv)
mae_xgb = mean_absolute_error(y_test, preds_xgb)

# Output results
print(f"DNN with ZILN Loss: Gini = {gini_dnn}, MAE = {mae_dnn}")
print(f"XGBoost: Gini = {gini_xgb}, MAE = {mae_xgb}")

# Optional: Plot Decile Charts for Calibration
def plot_decile_chart(y_true, y_pred, title):
    sorted_idx = np.argsort(y_pred)
    sorted_true = y_true[sorted_idx]
    sorted_pred = y_pred[sorted_idx]
    
    deciles = np.array_split(np.arange(len(y_true)), 10)
    mean_true = [np.mean(sorted_true[decile]) for decile in deciles]
    mean_pred = [np.mean(sorted_pred[decile]) for decile in deciles]
    
    plt.figure(figsize=(10, 6))
    plt.plot(mean_true, label='Actual CLV', marker='o')
    plt.plot(mean_pred, label='Predicted CLV', marker='o')
    plt.title(title)
    plt.xlabel('Decile')
    plt.ylabel('Mean CLV')
    plt.legend()
    plt.show()

plot_decile_chart(y_test, preds_dnn_clv, "DNN with ZILN Loss - Decile Chart")
plot_decile_chart(y_test, preds_xgb, "XGBoost - Decile Chart")







import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, models
import xgboost as xgb
from sklearn.metrics import mean_absolute_error
import matplotlib.pyplot as plt

# 1. Generate Synthetic CLV Distribution
def generate_clv_distribution(n_customers=10000, p_zero=0.7, mu=3, sigma=1):
    # Generate zero-inflation
    clv = np.zeros(n_customers)
    non_zero_mask = np.random.rand(n_customers) > p_zero
    
    # Generate lognormal CLV for non-zero customers
    clv[non_zero_mask] = np.exp(np.random.normal(mu, sigma, size=np.sum(non_zero_mask)))
    return clv

clv = generate_clv_distribution()

# Split into train and test
n_train = int(0.8 * len(clv))
X = np.random.rand(len(clv), 10)  # Dummy features
X_train, X_test = X[:n_train], X[n_train:]
clv_train, clv_test = clv[:n_train], clv[n_train:]

# 2. Implement the DNN with ZILN Loss
def safe_log(x):
    return tf.math.log(tf.maximum(x, 1e-6))

def ziln_loss(y_true, y_pred):
    p, mu, sigma = y_pred[:, 0], y_pred[:, 1], y_pred[:, 2]
    is_zero = tf.cast(tf.equal(y_true, 0), tf.float32)
    
    # Cross-entropy loss for zero-inflation
    cross_entropy_loss = is_zero * -tf.math.log(1 - p + 1e-6) + (1 - is_zero) * -tf.math.log(p + 1e-6)
    
    # Lognormal loss for non-zero CLV
    lognormal_loss = (1 - is_zero) * (safe_log(y_true) - mu)**2 / (2 * sigma**2) + safe_log(sigma) + safe_log(y_true) * sigma
    
    return tf.reduce_mean(cross_entropy_loss + lognormal_loss)

def build_dnn_model(input_dim):
    inputs = layers.Input(shape=(input_dim,))
    x = layers.Dense(64, activation='relu', kernel_initializer='he_normal')(inputs)
    x = layers.Dense(32, activation='relu', kernel_initializer='he_normal')(x)
    
    p = layers.Dense(1, activation='sigmoid')(x)
    mu = layers.Dense(1)(x)
    sigma = layers.Dense(1, activation='softplus')(x)
    
    outputs = layers.Concatenate()([p, mu, sigma])
    
    model = models.Model(inputs, outputs)
    model.compile(optimizer='adam', loss=ziln_loss)
    return model

# Build and train the model
input_dim = X_train.shape[1]
model_dnn = build_dnn_model(input_dim)
model_dnn.fit(X_train, clv_train, epochs=5000, batch_size=256, validation_split=0.2, verbose=1)

# Predict with the DNN model
preds_dnn = model_dnn.predict(X_test)
preds_dnn_clv = preds_dnn[:, 1]  # Use the predicted mean of the lognormal distribution

# Handle NaN values
preds_dnn_clv = np.nan_to_num(preds_dnn_clv, nan=0.0, posinf=0.0, neginf=0.0)

# 3. Implement a Baseline XGBoost Model
dtrain = xgb.DMatrix(X_train, label=clv_train)
dtest = xgb.DMatrix(X_test)

params = {
    'objective': 'reg:squarederror',
    'max_depth': 6,
    'eta': 0.1,
    'subsample': 0.8,
    'colsample_bytree': 0.8,
}

model_xgb = xgb.train(params, dtrain, num_boost_round=100)
preds_xgb = model_xgb.predict(dtest)

# 4. Evaluate and Compare the Models
def gini(y_true, y_pred):
    all = np.asarray(np.c_[y_true, y_pred, np.arange(len(y_true))], dtype=np.float64)
    all = all[np.lexsort((all[:, 2], -1 * all[:, 1]))]
    total_losses = all[:, 0].sum()
    gini_sum = all[:, 0].cumsum().sum() / total_losses

    gini_sum -= (len(y_true) + 1) / 2.
    return gini_sum / len(y_true)

def normalized_gini(y_true, y_pred):
    return gini(y_true, y_pred) / gini(y_true, y_true)

# Calculate metrics
gini_dnn = normalized_gini(clv_test, preds_dnn_clv)
gini_xgb = normalized_gini(clv_test, preds_xgb)

mae_dnn = mean_absolute_error(clv_test, preds_dnn_clv)
mae_xgb = mean_absolute_error(clv_test, preds_xgb)

# Output results
print(f"DNN with ZILN Loss: Gini = {gini_dnn}, MAE = {mae_dnn}")
print(f"XGBoost: Gini = {gini_xgb}, MAE = {mae_xgb}")

# Optional: Plot Decile Charts for Calibration
def plot_decile_chart(y_true, y_pred, title):
    sorted_idx = np.argsort(y_pred)
    sorted_true = y_true[sorted_idx]
    sorted_pred = y_pred[sorted_idx]
    
    deciles = np.array_split(np.arange(len(y_true)), 10)
    mean_true = [np.mean(sorted_true[decile]) for decile in deciles]
    mean_pred = [np.mean(sorted_pred[decile]) for decile in deciles]
    
    plt.figure(figsize=(10, 6))
    plt.plot(mean_true, label='Actual CLV', marker='o')
    plt.plot(mean_pred, label='Predicted CLV', marker='o')
    plt.title(title)
    plt.xlabel('Decile')
    plt.ylabel('Mean CLV')
    plt.legend()
    plt.show()

plot_decile_chart(clv_test, preds_dnn_clv, "DNN with ZILN Loss - Decile Chart")
plot_decile_chart(clv_test, preds_xgb, "XGBoost - Decile Chart")









import xgboost as xgb
import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score, mean_pinball_loss

# Load California Housing dataset
data = fetch_california_housing()
X = data.data
y = data.target

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Define the quantile loss function
def quantile_loss(preds, dtrain, quantile):
    labels = dtrain.get_label()
    errors = labels - preds
    grad = np.where(errors < 0, quantile - 1, quantile)
    hess = np.ones_like(preds)
    return grad, hess

# Set the quantile for median prediction
quantile = 0.5

# Set XGBoost parameters
params = {
    'eta': 0.01,
    'max_depth': 10,
    'n_estimators':1000,
    'objective': 'reg:squarederror',  # Placeholder, we'll use our custom objective
    'eval_metric': 'mae'  # Use mean absolute error for evaluation
}

# Convert data into DMatrix
dtrain = xgb.DMatrix(X_train, label=y_train)

# Train the model using the custom quantile loss function
quantile_model = xgb.train(
    params,
    dtrain,
    num_boost_round=1000,
    obj=lambda preds, dtrain: quantile_loss(preds, dtrain, quantile)
)

# Convert the test set into DMatrix
dtest = xgb.DMatrix(X_test)

# Make predictions
preds = quantile_model.predict(dtest)

# Compute the R² score
r2 = r2_score(y_test, preds)
print(f'R² score: {r2:.4f}')

# Plot the results
plt.figure(figsize=(10, 6))
plt.scatter(y_test, preds, alpha=0.3)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
plt.xlabel('Actual Median House Value')
plt.ylabel('Predicted Median House Value')
plt.title(f'Median Prediction with R²: {r2:.4f}')
plt.show()




https://bwelcome.hr.bnpparibas/fr_FR/externalcareers/ApplicationConfirmation?jobId=12225



https://www.intechopen.com/chapters/61571				
https://link.springer.com/article/10.1057/s41270-023-00234-6				
https://www.intechopen.com/chapters/61571				
https://ar5iv.labs.arxiv.org/html/2208.13358				
https://link.springer.com/chapter/10.1007/978-981-16-3346-1_22				
https://link.springer.com/chapter/10.1007/978-981-16-3346-1_22				
https://link.springer.com/article/10.1057/s41270-023-00234-6				









import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

# Sample data creation (replace this with your actual data loading)
np.random.seed(42)
df_2018 = pd.DataFrame({'id': range(1, 101), 'target': np.random.rand(100) * 100, 'var1': np.random.rand(100) * 100})
df_2019 = pd.DataFrame({'id': range(1, 101), 'target': np.random.rand(100) * 100})
df_2020 = pd.DataFrame({'id': range(1, 101), 'target': np.random.rand(100) * 100})
df_2021 = pd.DataFrame({'id': range(1, 101), 'target': np.random.rand(100) * 100})
df_2022 = pd.DataFrame({'id': range(1, 101), 'target': np.random.rand(100) * 100})
df_2023 = pd.DataFrame({'id': range(1, 101), 'target': np.random.rand(100) * 100})

# Remove outliers based on 'var1' in the 2018 data
Q1 = df_2018['var1'].quantile(0.25)
Q3 = df_2018['var1'].quantile(0.75)
IQR = Q3 - Q1
non_outlier_ids = df_2018[(df_2018['var1'] >= (Q1 - 1.5 * IQR)) & (df_2018['var1'] <= (Q3 + 1.5 * IQR))]['id']

# Create subsets of the other dataframes using the non-outlier IDs
df_2018_no_outliers = df_2018[df_2018['id'].isin(non_outlier_ids)]
df_2019_no_outliers = df_2019[df_2019['id'].isin(non_outlier_ids)]
df_2020_no_outliers = df_2020[df_2020['id'].isin(non_outlier_ids)]
df_2021_no_outliers = df_2021[df_2021['id'].isin(non_outlier_ids)]
df_2022_no_outliers = df_2022[df_2022['id'].isin(non_outlier_ids)]
df_2023_no_outliers = df_2023[df_2023['id'].isin(non_outlier_ids)]

# Combine all DataFrames into a single DataFrame for the non-outliers
combined_df = df_2018_no_outliers[['id', 'target']].rename(columns={'target': 'target_2018'})
combined_df = combined_df.merge(df_2019_no_outliers[['id', 'target']].rename(columns={'target': 'target_2019'}), on='id', how='left')
combined_df = combined_df.merge(df_2020_no_outliers[['id', 'target']].rename(columns={'target': 'target_2020'}), on='id', how='left')
combined_df = combined_df.merge(df_2021_no_outliers[['id', 'target']].rename(columns={'target': 'target_2021'}), on='id', how='left')
combined_df = combined_df.merge(df_2022_no_outliers[['id', 'target']].rename(columns={'target': 'target_2022'}), on='id', how='left')
combined_df = combined_df.merge(df_2023_no_outliers[['id', 'target']].rename(columns={'target': 'target_2023'}), on='id', how='left')

# Calculate mean, median, and sum for each year's target
stats_df = combined_df[['target_2018', 'target_2019', 'target_2020', 'target_2021', 'target_2022', 'target_2023']].agg(['mean', 'median', 'sum']).transpose()
stats_df.index = ['2018', '2019', '2020', '2021', '2022', '2023']

plt.figure(figsize=(12, 8))

# Plot mean, median, and sum of each target variable over the years
plt.subplot(3, 1, 1)
plt.plot(stats_df.index, stats_df['mean'], marker='o')
plt.title('Mean of Target Variables Over Years')
plt.ylabel('Mean')

plt.subplot(3, 1, 2)
plt.plot(stats_df.index, stats_df['median'], marker='o')
plt.title('Median of Target Variables Over Years')
plt.ylabel('Median')

plt.subplot(3, 1, 3)
plt.plot(stats_df.index, stats_df['sum'], marker='o')
plt.title('Sum of Target Variables Over Years')
plt.ylabel('Sum')
plt.xlabel('Year')

plt.tight_layout()
plt.show()

# Plot the trimmed target distribution for each year separately using Seaborn
plt.figure(figsize=(12, 18))
years = ['2018', '2019', '2020', '2021', '2022', '2023']

for i, year in enumerate(years, 1):
    plt.subplot(6, 1, i)
    sns.histplot(combined_df[f'target_{year}'], kde=True, bins=20)
    plt.title(f'Target Distribution for {year}')
    plt.xlabel('Target')
    plt.ylabel('Frequency')

plt.tight_layout()
plt.show()









import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

# Sample data creation (replace this with your actual data loading)
np.random.seed(42)
df_2018 = pd.DataFrame({'id': range(1, 101), 'target': np.random.rand(100) * 100, 'var1': np.random.rand(100) * 100})
df_2019 = pd.DataFrame({'id': range(1, 101), 'target': np.random.rand(100) * 100})
df_2020 = pd.DataFrame({'id': range(1, 101), 'target': np.random.rand(100) * 100})
df_2021 = pd.DataFrame({'id': range(1, 101), 'target': np.random.rand(100) * 100})
df_2022 = pd.DataFrame({'id': range(1, 101), 'target': np.random.rand(100) * 100})
df_2023 = pd.DataFrame({'id': range(1, 101), 'target': np.random.rand(100) * 100})

# Combine all DataFrames into a single DataFrame
combined_df = df_2018.copy()
combined_df = combined_df.rename(columns={'target': 'target_2018'})

# Add target columns for other years
for year, df in zip(range(2019, 2024), [df_2019, df_2020, df_2021, df_2022, df_2023]):
    combined_df = pd.merge(combined_df, df[['id', 'target']].rename(columns={'target': f'target_{year}'}), on='id', how='left')

# Remove outliers based on another variable (e.g., 'var1') in 2018
Q1 = combined_df['var1'].quantile(0.25)
Q3 = combined_df['var1'].quantile(0.75)
IQR = Q3 - Q1
combined_df = combined_df[(combined_df['var1'] >= (Q1 - 1.5 * IQR)) & (combined_df['var1'] <= (Q3 + 1.5 * IQR))]

# Plot mean, median, and sum of each target variable over the years
stats_df = combined_df[['target_2018', 'target_2019', 'target_2020', 'target_2021', 'target_2022', 'target_2023']].agg(['mean', 'median', 'sum']).transpose()
stats_df.index = ['2018', '2019', '2020', '2021', '2022', '2023']

plt.figure(figsize=(12, 18))

# Mean plot
plt.subplot(4, 1, 1)
plt.plot(stats_df.index, stats_df['mean'], marker='o')
plt.title('Mean of Target Variables Over Years')
plt.ylabel('Mean')

# Median plot
plt.subplot(4, 1, 2)
plt.plot(stats_df.index, stats_df['median'], marker='o')
plt.title('Median of Target Variables Over Years')
plt.ylabel('Median')

# Sum plot
plt.subplot(4, 1, 3)
plt.plot(stats_df.index, stats_df['sum'], marker='o')
plt.title('Sum of Target Variables Over Years')
plt.ylabel('Sum')

plt.tight_layout()

# Plot the trimmed target distribution for each year separately using Seaborn
plt.figure(figsize=(12, 18))
years = ['2018', '2019', '2020', '2021', '2022', '2023']

for i, year in enumerate(years, 1):
    plt.subplot(6, 1, i)
    sns.histplot(combined_df[f'target_{year}'], kde=True, bins=20)
    plt.title(f'Target Distribution for {year}')
    plt.xlabel('Target')
    plt.ylabel('Frequency')

plt.tight_layout()
plt.show()







import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

# Sample data creation (replace this with your actual data loading)
np.random.seed(42)
df_2018 = pd.DataFrame({'id': range(1, 101), 'target': np.random.rand(100) * 100, 'var1': np.random.rand(100) * 100})
df_2019 = pd.DataFrame({'id': range(1, 101), 'target': np.random.rand(100) * 100})
df_2020 = pd.DataFrame({'id': range(1, 101), 'target': np.random.rand(100) * 100})
df_2021 = pd.DataFrame({'id': range(1, 101), 'target': np.random.rand(100) * 100})
df_2022 = pd.DataFrame({'id': range(1, 101), 'target': np.random.rand(100) * 100})
df_2023 = pd.DataFrame({'id': range(1, 101), 'target': np.random.rand(100) * 100})

# Combine all DataFrames into a single DataFrame
combined_df = df_2018.copy()
combined_df = combined_df.rename(columns={'target': 'target_2018'})

# Add target columns for other years
for year, df in zip(range(2019, 2024), [df_2019, df_2020, df_2021, df_2022, df_2023]):
    combined_df = pd.merge(combined_df, df[['id', 'target']].rename(columns={'target': f'target_{year}'}), on='id', how='left')

# Remove outliers based on another variable (e.g., 'var1') in 2018
Q1 = combined_df['var1'].quantile(0.25)
Q3 = combined_df['var1'].quantile(0.75)
IQR = Q3 - Q1
combined_df = combined_df[(combined_df['var1'] >= (Q1 - 1.5 * IQR)) & (combined_df['var1'] <= (Q3 + 1.5 * IQR))]

# Plot mean, median, and sum of each target variable over the years
stats_df = combined_df[['target_2018', 'target_2019', 'target_2020', 'target_2021', 'target_2022', 'target_2023']].agg(['mean', 'median', 'sum']).transpose()
stats_df.index = ['2018', '2019', '2020', '2021', '2022', '2023']

plt.figure(figsize=(12, 18))

# Mean plot
plt.subplot(4, 1, 1)
plt.plot(stats_df.index, stats_df['mean'], marker='o')
plt.title('Mean of Target Variables Over Years')
plt.ylabel('Mean')

# Median plot
plt.subplot(4, 1, 2)
plt.plot(stats_df.index, stats_df['median'], marker='o')
plt.title('Median of Target Variables Over Years')
plt.ylabel('Median')

# Sum plot
plt.subplot(4, 1, 3)
plt.plot(stats_df.index, stats_df['sum'], marker='o')
plt.title('Sum of Target Variables Over Years')
plt.ylabel('Sum')

plt.tight_layout()

# Plot the trimmed target distribution for each year separately using Seaborn
plt.figure(figsize=(12, 18))
years = ['2018', '2019', '2020', '2021', '2022', '2023']

for i, year in enumerate(years, 1):
    plt.subplot(6, 1, i)
    sns.histplot(combined_df[f'target_{year}'], kde=True, bins=20)
    plt.title(f'Target Distribution for {year}')
    plt.xlabel('Target')
    plt.ylabel('Frequency')

plt.tight_layout()
plt.show()







import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

# Sample data creation (replace this with your actual data loading)
np.random.seed(42)
df_2018 = pd.DataFrame({'id': range(1, 101), 'target': np.random.rand(100) * 100, 'var1': np.random.rand(100)})
df_2019 = pd.DataFrame({'id': range(1, 101), 'target': np.random.rand(100) * 100})
df_2020 = pd.DataFrame({'id': range(1, 101), 'target': np.random.rand(100) * 100})
df_2021 = pd.DataFrame({'id': range(1, 101), 'target': np.random.rand(100) * 100})
df_2022 = pd.DataFrame({'id': range(1, 101), 'target': np.random.rand(100) * 100})
df_2023 = pd.DataFrame({'id': range(1, 101), 'target': np.random.rand(100) * 100})

# Combine all DataFrames into a single DataFrame
combined_df = df_2018.copy()
combined_df = combined_df.rename(columns={'target': 'target_2018'})

# Add target columns for other years
for year, df in zip(range(2019, 2024), [df_2019, df_2020, df_2021, df_2022, df_2023]):
    combined_df = pd.merge(combined_df, df[['id', 'target']].rename(columns={'target': f'target_{year}'}), on='id', how='left')

# Remove outliers and negative values based on 2018 target
Q1 = combined_df['target_2018'].quantile(0.25)
Q3 = combined_df['target_2018'].quantile(0.75)
IQR = Q3 - Q1
combined_df = combined_df[(combined_df['target_2018'] >= 0) & (combined_df['target_2018'] <= (Q3 + 1.5 * IQR))]

# Plot the trimmed target distribution for each year separately using Seaborn
years = ['2018', '2019', '2020', '2021', '2022', '2023']
plt.figure(figsize=(12, 18))

for i, year in enumerate(years, 1):
    plt.subplot(6, 1, i)
    sns.histplot(combined_df[f'target_{year}'], kde=True, bins=20)
    plt.title(f'Target Distribution for {year}')
    plt.xlabel('Target')
    plt.ylabel('Frequency')

plt.tight_layout()
plt.show()







import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Sample data creation (replace this with your actual data loading)
np.random.seed(42)
df_2018 = pd.DataFrame({'id': range(1, 101), 'target': np.random.rand(100) * 100, 'var1': np.random.rand(100)})
df_2019 = pd.DataFrame({'id': range(1, 101), 'target': np.random.rand(100) * 100})
df_2020 = pd.DataFrame({'id': range(1, 101), 'target': np.random.rand(100) * 100})
df_2021 = pd.DataFrame({'id': range(1, 101), 'target': np.random.rand(100) * 100})
df_2022 = pd.DataFrame({'id': range(1, 101), 'target': np.random.rand(100) * 100})
df_2023 = pd.DataFrame({'id': range(1, 101), 'target': np.random.rand(100) * 100})

# Combine all DataFrames into a single DataFrame
combined_df = df_2018.copy()
combined_df = combined_df.rename(columns={'target': 'target_2018'})

# Add target columns for other years
for year, df in zip(range(2019, 2024), [df_2019, df_2020, df_2021, df_2022, df_2023]):
    combined_df = pd.merge(combined_df, df[['id', 'target']].rename(columns={'target': f'target_{year}'}), on='id', how='left')

# Remove outliers and negative values based on 2018 target
Q1 = combined_df['target_2018'].quantile(0.25)
Q3 = combined_df['target_2018'].quantile(0.75)
IQR = Q3 - Q1
combined_df = combined_df[(combined_df['target_2018'] >= 0) & (combined_df['target_2018'] <= (Q3 + 1.5 * IQR))]

# Plot the trimmed target distribution for each year separately
years = ['2018', '2019', '2020', '2021', '2022', '2023']
plt.figure(figsize=(12, 18))

for i, year in enumerate(years, 1):
    plt.subplot(6, 1, i)
    plt.hist(combined_df[f'target_{year}'], bins=20, edgecolor='k', alpha=0.7)
    plt.title(f'Target Distribution for {year}')
    plt.xlabel('Target')
    plt.ylabel('Frequency')

plt.tight_layout()
plt.show()









import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Sample data creation (replace this with your actual data loading)
np.random.seed(42)
df_2018 = pd.DataFrame({'id': range(1, 101), 'target': np.random.rand(100) * 100, 'var1': np.random.rand(100)})
df_2019 = pd.DataFrame({'id': range(1, 101), 'target': np.random.rand(100) * 100})
df_2020 = pd.DataFrame({'id': range(1, 101), 'target': np.random.rand(100) * 100})
df_2021 = pd.DataFrame({'id': range(1, 101), 'target': np.random.rand(100) * 100})
df_2022 = pd.DataFrame({'id': range(1, 101), 'target': np.random.rand(100) * 100})
df_2023 = pd.DataFrame({'id': range(1, 101), 'target': np.random.rand(100) * 100})

# Combine all DataFrames into a single DataFrame
combined_df = df_2018.copy()
combined_df = combined_df.rename(columns={'target': 'target_2018'})

# Add target columns for other years
for year, df in zip(range(2019, 2024), [df_2019, df_2020, df_2021, df_2022, df_2023]):
    combined_df = pd.merge(combined_df, df[['id', 'target']].rename(columns={'target': f'target_{year}'}), on='id', how='left')

# Remove outliers and negative values based on 2018 target
Q1 = combined_df['target_2018'].quantile(0.25)
Q3 = combined_df['target_2018'].quantile(0.75)
IQR = Q3 - Q1
combined_df = combined_df[(combined_df['target_2018'] >= 0) & (combined_df['target_2018'] <= (Q3 + 1.5 * IQR))]

# Plot mean, median, and sum of each target variable over the years
stats_df = combined_df[['target_2018', 'target_2019', 'target_2020', 'target_2021', 'target_2022', 'target_2023']].agg(['mean', 'median', 'sum']).transpose()
stats_df.index = ['2018', '2019', '2020', '2021', '2022', '2023']

plt.figure(figsize=(12, 8))

# Mean plot
plt.subplot(3, 1, 1)
plt.plot(stats_df.index, stats_df['mean'], marker='o')
plt.title('Mean of Target Variables Over Years')
plt.ylabel('Mean')

# Median plot
plt.subplot(3, 1, 2)
plt.plot(stats_df.index, stats_df['median'], marker='o')
plt.title('Median of Target Variables Over Years')
plt.ylabel('Median')

# Sum plot
plt.subplot(3, 1, 3)
plt.plot(stats_df.index, stats_df['sum'], marker='o')
plt.title('Sum of Target Variables Over Years')
plt.ylabel('Sum')
plt.xlabel('Year')

plt.tight_layout()
plt.show()









import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import r2_score
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor

# Sample data creation (replace this with your actual data loading)
np.random.seed(42)
data = pd.DataFrame({
    'id': range(1, 101),
    'var1': np.random.rand(100),
    'var2': np.random.rand(100),
    'var3': np.random.rand(100),
    'y_short': np.random.rand(100) * 100,
    'y_long': np.random.rand(100) * 1000
})

# Define explanatory variables for the first prediction
X_short = data[['var1', 'var2', 'var3']]
y_short = data['y_short']

# Split the data into training and test sets for y_short prediction
X_train_short, X_test_short, y_train_short, y_test_short = train_test_split(X_short, y_short, test_size=0.2, random_state=42)

# Define parameter grids for Random Forest and Gradient Boosting
param_grid_rf = {
    'n_estimators': [50, 100, 200],
    'max_depth': [None, 10, 20],
    'min_samples_split': [2, 5, 10]
}

param_grid_gb = {
    'n_estimators': [50, 100, 200],
    'learning_rate': [0.01, 0.1, 0.2],
    'max_depth': [3, 5, 7]
}

# Perform Grid Search for Random Forest
rf = RandomForestRegressor(random_state=42)
grid_search_rf = GridSearchCV(rf, param_grid_rf, cv=3, scoring='r2')
grid_search_rf.fit(X_train_short, y_train_short)
best_rf = grid_search_rf.best_estimator_

# Perform Grid Search for Gradient Boosting
gb = GradientBoostingRegressor(random_state=42)
grid_search_gb = GridSearchCV(gb, param_grid_gb, cv=3, scoring='r2')
grid_search_gb.fit(X_train_short, y_train_short)
best_gb = grid_search_gb.best_estimator_

# Predict y_short on the test set using the best models
y_pred_short_rf = best_rf.predict(X_test_short)
y_pred_short_gb = best_gb.predict(X_test_short)

# Evaluate the models for y_short using R²
r2_short_rf = r2_score(y_test_short, y_pred_short_rf)
r2_short_gb = r2_score(y_test_short, y_pred_short_gb)
print(f'Best R² for y_short prediction using Random Forest: {r2_short_rf}')
print(f'Best R² for y_short prediction using Gradient Boosting: {r2_short_gb}')

# Choose the best model for y_short (use Gradient Boosting here)
data['y_short_pred'] = best_gb.predict(X_short)
X_long = data[['y_short_pred', 'var1', 'var2', 'var3']]  # You can add other variables as needed
y_long = data['y_long']

# Split the data into training and test sets for y_long prediction
X_train_long, X_test_long, y_train_long, y_test_long = train_test_split(X_long, y_long, test_size=0.2, random_state=42)

# Perform Grid Search for Random Forest
grid_search_rf_long = GridSearchCV(rf, param_grid_rf, cv=3, scoring='r2')
grid_search_rf_long.fit(X_train_long, y_train_long)
best_rf_long = grid_search_rf_long.best_estimator_

# Perform Grid Search for Gradient Boosting
grid_search_gb_long = GridSearchCV(gb, param_grid_gb, cv=3, scoring='r2')
grid_search_gb_long.fit(X_train_long, y_train_long)
best_gb_long = grid_search_gb_long.best_estimator_

# Predict y_long on the test set using the best models
y_pred_long_rf = best_rf_long.predict(X_test_long)
y_pred_long_gb = best_gb_long.predict(X_test_long)

# Evaluate the models for y_long using R²
r2_long_rf = r2_score(y_test_long, y_pred_long_rf)
r2_long_gb = r2_score(y_test_long, y_pred_long_gb)
print(f'Best R² for y_long prediction using Random Forest: {r2_long_rf}')
print(f'Best R² for y_long prediction using Gradient Boosting: {r2_long_gb}')

# Display the final dataset with predictions
print(data)






import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score

# Sample data creation (replace this with your actual data loading)
np.random.seed(42)
data = pd.DataFrame({
    'id': range(1, 101),
    'var1': np.random.rand(100),
    'var2': np.random.rand(100),
    'var3': np.random.rand(100),
    'y_short': np.random.rand(100) * 100,
    'y_long': np.random.rand(100) * 1000
})

# Define explanatory variables for the first prediction
X_short = data[['var1', 'var2', 'var3']]
y_short = data['y_short']

# Split the data into training and test sets for y_short prediction
X_train_short, X_test_short, y_train_short, y_test_short = train_test_split(X_short, y_short, test_size=0.2, random_state=42)

# Train the XGBoost regressor to predict y_short
model_short = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, random_state=42)
model_short.fit(X_train_short, y_train_short)

# Predict y_short on the test set
y_pred_short = model_short.predict(X_test_short)

# Evaluate the model for y_short using R²
r2_short = r2_score(y_test_short, y_pred_short)
print(f'R² for y_short prediction: {r2_short}')

# Create a new dataset with the predicted y_short and additional explanatory variables for y_long prediction
data['y_short_pred'] = model_short.predict(X_short)
X_long = data[['y_short_pred', 'var1', 'var2', 'var3']]  # You can add other variables as needed
y_long = data['y_long']

# Split the data into training and test sets for y_long prediction
X_train_long, X_test_long, y_train_long, y_test_long = train_test_split(X_long, y_long, test_size=0.2, random_state=42)

# Train the XGBoost regressor to predict y_long
model_long = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, random_state=42)
model_long.fit(X_train_long, y_train_long)

# Predict y_long on the test set
y_pred_long = model_long.predict(X_test_long)

# Evaluate the model for y_long using R²
r2_long = r2_score(y_test_long, y_pred_long)
print(f'R² for y_long prediction: {r2_long}')

# Display the final dataset
print(data)









import pandas as pd

# Sample data (replace these with your actual data loading methods)
df_2018 = pd.DataFrame({'id': [1, 2, 3], 'target': [100, 200, 300], 'var1': [10, 20, 30]})
df_2019 = pd.DataFrame({'id': [1, 3, 4], 'target': [110, 310, 400], 'var1': [15, 25, 35]})
df_2020 = pd.DataFrame({'id': [1, 2, 4], 'target': [120, 220, 420], 'var1': [12, 22, 32]})
df_2021 = pd.DataFrame({'id': [1, 2, 3], 'target': [130, 230, 330], 'var1': [14, 24, 34]})
df_2022 = pd.DataFrame({'id': [2, 3, 4], 'target': [240, 340, 440], 'var1': [18, 28, 38]})
df_2023 = pd.DataFrame({'id': [1, 3, 4], 'target': [150, 350, 450], 'var1': [16, 26, 36]})

# Combine all DataFrames into a single DataFrame for summing targets
dfs = [df_2018, df_2019, df_2020, df_2021, df_2022, df_2023]
combined_targets = pd.concat([df[['id', 'target']] for df in dfs])

# Group by 'id' and sum the target values
summed_targets = combined_targets.groupby('id').sum().reset_index()
summed_targets.rename(columns={'target': 'new_target'}, inplace=True)

# Merge the summed target back into the original 2018 DataFrame
final_df = pd.merge(df_2018, summed_targets, on='id', how='left')

# Fill any missing values in 'new_target' with 0 (if there were IDs not present in 2018)
final_df['new_target'].fillna(0, inplace=True)

# Display the final combined DataFrame
print(final_df)




import pandas as pd

# Assuming df_2018, df_2019, df_2020, df_2021, df_2022, df_2023 are your DataFrames for each year
# Each DataFrame should have columns 'id', 'target', and other variables

# Sample data (replace these with your actual data loading methods)
df_2018 = pd.DataFrame({'id': [1, 2, 3], 'target': [100, 200, 300], 'var1': [10, 20, 30]})
df_2019 = pd.DataFrame({'id': [1, 3, 4], 'target': [110, 310, 400], 'var1': [15, 25, 35]})
df_2020 = pd.DataFrame({'id': [1, 2, 4], 'target': [120, 220, 420], 'var1': [12, 22, 32]})
df_2021 = pd.DataFrame({'id': [1, 2, 3], 'target': [130, 230, 330], 'var1': [14, 24, 34]})
df_2022 = pd.DataFrame({'id': [2, 3, 4], 'target': [240, 340, 440], 'var1': [18, 28, 38]})
df_2023 = pd.DataFrame({'id': [1, 3, 4], 'target': [150, 350, 450], 'var1': [16, 26, 36]})

# Combine all DataFrames
dfs = [df_2018, df_2019, df_2020, df_2021, df_2022, df_2023]

# Initialize the combined DataFrame with the first year's data
combined_df = df_2018[['id', 'var1']].copy()
combined_df['target_2018'] = df_2018['target']

# Add target columns for other years, initializing them to zero
for year, df in zip(range(2019, 2024), dfs[1:]):
    combined_df = pd.merge(combined_df, df[['id', 'target']], on='id', how='left', suffixes=('', f'_{year}'))
    combined_df[f'target_{year}'].fillna(0, inplace=True)

# Sum the target values across all years to create the new target variable
combined_df['new_target'] = combined_df[['target_2018', 'target_2019', 'target_2020', 'target_2021', 'target_2022', 'target_2023']].sum(axis=1)

# Drop the individual target columns if desired
combined_df.drop(columns=['target_2018', 'target_2019', 'target_2020', 'target_2021', 'target_2022', 'target_2023'], inplace=True)

# Display the final combined DataFrame
print(combined_df)





import numpy as np
import matplotlib.pyplot as plt
import xgboost as xgb
from sklearn.datasets import make_regression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
import pandas as pd

# Generate synthetic data for regression
X, y = make_regression(n_samples=100, n_features=1, noise=0.1, random_state=42)

# Create a DataFrame for easier manipulation
df = pd.DataFrame(data=X, columns=['Feature'])
df['Target'] = y

# Sort the DataFrame based on the target
df = df.sort_values(by='Target').reset_index(drop=True)

# Define a threshold to split the data
threshold = df['Target'].median()

# Split the DataFrame into two based on the threshold
df_low = df[df['Target'] <= threshold]
df_high = df[df['Target'] > threshold]

# Split each subset into training and test sets
X_train_low, X_test_low, y_train_low, y_test_low = train_test_split(
    df_low[['Feature']], df_low['Target'], test_size=0.2, random_state=42)
X_train_high, X_test_high, y_train_high, y_test_high = train_test_split(
    df_high[['Feature']], df_high['Target'], test_size=0.2, random_state=42)

# Create and train the XGBoost regressor for each subset
model_low = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, random_state=42)
model_high = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, random_state=42)

model_low.fit(X_train_low, y_train_low)
model_high.fit(X_train_high, y_train_high)

# Predict on the test set for each model
y_pred_low = model_low.predict(X_test_low)
y_pred_high = model_high.predict(X_test_high)

# Calculate residuals for each model
residuals_low = y_test_low - y_pred_low
residuals_high = y_test_high - y_pred_high

# Plot the target values colored by the residuals for the low target model
plt.figure(figsize=(10, 6))
scatter_low = plt.scatter(X_test_low, y_test_low, c=residuals_low, cmap='coolwarm', edgecolor='k', s=100)
plt.colorbar(scatter_low, label='Residuals')
plt.xlabel('Feature')
plt.ylabel('Target')
plt.title('Target Values (Low) Colored by Residuals')
plt.show()

# Plot the target values colored by the residuals for the high target model
plt.figure(figsize=(10, 6))
scatter_high = plt.scatter(X_test_high, y_test_high, c=residuals_high, cmap='coolwarm', edgecolor='k', s=100)
plt.colorbar(scatter_high, label='Residuals')
plt.xlabel('Feature')
plt.ylabel('Target')
plt.title('Target Values (High) Colored by Residuals')
plt.show()






import numpy as np
import matplotlib.pyplot as plt
import xgboost as xgb
from sklearn.datasets import make_regression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

# Generate synthetic data for regression
X, y = make_regression(n_samples=100, n_features=1, noise=0.1, random_state=42)

# Split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create and train the XGBoost regressor
model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Predict on the test set
y_pred = model.predict(X_test)

# Calculate residuals
residuals = y_test - y_pred

# Plot the target values colored by the residuals
plt.figure(figsize=(10, 6))
scatter = plt.scatter(X_test, y_test, c=residuals, cmap='coolwarm', edgecolor='k', s=100)
plt.colorbar(scatter, label='Residuals')
plt.xlabel('Feature')
plt.ylabel('Target')
plt.title('Target Values Colored by Residuals')
plt.show()







\documentclass{article}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{geometry}

\geometry{a4paper, margin=1in}

\title{Mise en Œuvre d'un Modèle de Prédiction de la Valeur Vie Client (CLV) dans une Banque}
\author{NABIGH Mohamed}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
Ce rapport présente un plan détaillé pour implémenter un modèle statistique de prédiction de la Valeur Vie Client (CLV) dans notre banque. Inspiré par les techniques discutées dans l'article "Une approche novatrice pour prédire la valeur vie client dans les entreprises B2B SaaS", cette implémentation vise à améliorer notre capacité à identifier et fidéliser les clients à haute valeur, optimiser les stratégies marketing, et améliorer la rétention des clients.
\end{abstract}

\section{Résumé Exécutif}
Ce rapport présente un plan détaillé pour implémenter un modèle statistique de prédiction de la Valeur Vie Client (CLV) dans notre banque. Inspiré par les techniques discutées dans l'article "Une approche novatrice pour prédire la valeur vie client dans les entreprises B2B SaaS", cette implémentation vise à améliorer notre capacité à identifier et fidéliser les clients à haute valeur, optimiser les stratégies marketing, et améliorer la rétention des clients.

\section{Compréhension de l'Approche de l'Article}
L'article propose un cadre flexible de modélisation statistique spécifiquement conçu pour prédire la CLV dans les entreprises de Software-as-a-Service (SaaS) B2B. Les éléments clés de cette approche incluent :

\begin{enumerate}
    \item \textbf{Structure Modulaire Hiérarchique}:
    \begin{itemize}
        \item \textbf{Prédiction à Court Terme (T')}: Utilise des données récentes pour prédire la CLV sur une période plus courte.
        \item \textbf{Prédiction à Long Terme (T)}: Étend les prédictions à court terme pour couvrir la durée de vie complète du client.
    \end{itemize}
    
    \item \textbf{Modélisation par Ensembles}:
    \begin{itemize}
        \item Combine plusieurs modèles statistiques pour améliorer la précision des prédictions.
        \item Utilise différents modèles pour différents segments de clients basés sur des caractéristiques spécifiques.
    \end{itemize}

    \item \textbf{Ingénierie des Caractéristiques}:
    \begin{itemize}
        \item Crée des caractéristiques significatives à partir de données brutes, telles que des métriques agrégées, des indicateurs de tendance, des caractéristiques décalées et des termes d'interaction.
        \item Met l'accent sur les données récentes pour garantir que les prédictions sont basées sur les informations les plus pertinentes.
    \end{itemize}

    \item \textbf{Évaluation du Modèle}:
    \begin{itemize}
        \item Utilise des métriques telles que RMSE (Root Mean Squared Error), MAE (Mean Absolute Error) et SMAPE (Symmetric Mean Absolute Percentage Error) pour évaluer la performance du modèle.
        \item Effectue une analyse des résidus pour affiner la segmentation et la sélection du modèle.
    \end{itemize}
\end{enumerate}

\section{Étapes et Conditions}

\subsection{Collecte des Données}
\begin{itemize}
    \item Collecter des données clients à partir de diverses sources au sein de la banque, y compris l'historique des transactions, les données démographiques des clients, les produits détenus et les métriques d'engagement.
    \item Assurer la collecte de divers types de données telles que des données catégorielles (par ex., segment de clients), des données entières (par ex., nombre de produits détenus), et des données flottantes (par ex., soldes de comptes).
\end{itemize}

\subsection{Prétraitement des Données}
\begin{itemize}
    \item Nettoyer les données en traitant les valeurs manquantes, en supprimant les doublons et en corrigeant les entrées incohérentes.
    \item Transformer les données en normalisant les caractéristiques numériques et en encodant les variables catégorielles en utilisant des techniques telles que l'encodage one-hot.
\end{itemize}

\subsection{Ingénierie des Caractéristiques}
\begin{itemize}
    \item \textbf{Métriques Agrégées}: Calculer le total des transactions, la valeur moyenne des transactions et la fréquence des transactions.
    \item \textbf{Indicateurs de Tendance}: Calculer les taux de croissance et les changements en pourcentage des soldes et des volumes de transactions.
    \item \textbf{Caractéristiques Décalées}: Créer des caractéristiques représentant les valeurs passées de certaines métriques (par ex., solde du mois précédent, transactions du trimestre précédent).
    \item \textbf{Caractéristiques Cumulatives}: Calculer les métriques cumulatives jusqu'au point d'observation.
    \item \textbf{Termes d'Interaction}: Créer des termes d'interaction entre les caractéristiques pour capturer les effets combinés.
\end{itemize}

\subsection{Entraînement du Modèle}
\begin{itemize}
    \item Diviser les données en ensembles d'entraînement et de test pour évaluer la robustesse du modèle.
    \item Utiliser des modèles de régression pour s'entraîner sur les caractéristiques générées. Les modèles potentiels incluent la régression linéaire, les forêts aléatoires et les machines à vecteurs de support.
    \item Effectuer un ajustement des hyperparamètres pour optimiser la performance du modèle. Les techniques de validation croisée peuvent être utilisées pour cet ajustement.
    \item Évaluer les modèles en utilisant des métriques telles que RMSE, MAE, et SMAPE pour déterminer la précision des prédictions.
    \item Analyser les résidus pour identifier et corriger les erreurs systématiques, améliorant ainsi la précision globale du modèle.
\end{itemize}

\subsection{Déploiement du Modèle}
\begin{itemize}
    \item Intégrer les modèles dans l'infrastructure informatique de la banque pour permettre une utilisation en production.
    \item Automatiser les processus de collecte de données, de prétraitement, d'ingénierie des caractéristiques et de ré-entraînement du modèle pour garantir des prédictions à jour et précises.
    \item Mettre en place des systèmes de surveillance pour suivre la performance du modèle en temps réel et identifier les dégradations de performance potentielles.
\end{itemize}

\subsection{Application Commerciale}
\begin{itemize}
    \item Optimiser les stratégies marketing en utilisant les prédictions de CLV pour cibler les clients à haute valeur avec des offres personnalisées.
    \item Améliorer la rétention des clients en identifiant les clients à risque et en développant des stratégies de rétention ciblées.
    \item Adapter les offres de produits en fonction des prédictions de CLV pour mieux répondre aux besoins des clients.
    \item Mener des analyses de retour sur investissement (ROI) pour guider l'allocation stratégique des ressources et optimiser la performance des campagnes.
\end{itemize}

\section{Projection de l'Approche sur Notre Cas d'Utilisation Spécifique}

\subsection{Prédiction à Court Terme}
Pour le court terme, nous nous concentrerons sur la prédiction de la CLV cumulée sur une période de 2 à 3 ans. Cela nous permettra d'observer l'impact sur notre modèle et d'affiner nos processus d'ingénierie des caractéristiques et de sélection de modèle. Les prédictions à court terme utiliseront des données récentes pour garantir leur pertinence et leur précision.

\subsection{Prédiction à Long Terme}
Pour la prédiction à long terme, nous sélectionnerons des variables facilement prévisibles dans le temps. Celles-ci peuvent inclure des caractéristiques démographiques (par ex., âge, revenu), des comportements historiques (par ex., fréquence des transactions) et des métriques d'engagement (par ex., fréquence des connexions). La prédiction à long terme étendra les prédictions de CLV à court terme pour couvrir toute la durée de vie du client.

\section{Conclusion}
Nous avons commencé à implémenter les techniques de modélisation statistique de l'article, et nous nous attendons à ce qu'elles améliorent considérablement notre capacité à prédire et à tirer parti de la Valeur Vie Client. Cela nous permettra de prendre des décisions plus éclairées, d'optimiser les efforts marketing et d'améliorer la satisfaction et la rétention globales des clients. Le projet impliquera une collecte de données minutieuse, une ingénierie des caractéristiques robuste et des techniques de modélisation avancées pour atteindre ces objectifs.

\end{document}









Rapport de Mise en Œuvre du Modèle de Prédiction de la Valeur Vie Client (CLV) dans une Banque

Résumé Exécutif
Ce rapport présente un plan détaillé pour implémenter un modèle statistique de prédiction de la Valeur Vie Client (CLV) dans notre banque. En nous inspirant des techniques discutées dans l'article "Une approche novatrice pour prédire la valeur vie client dans les entreprises B2B SaaS", cette implémentation vise à améliorer notre capacité à identifier et fidéliser les clients à haute valeur, optimiser les stratégies marketing, et renforcer la rétention des clients.

Compréhension de l'Approche de l'Article
L'article propose un cadre statistique flexible conçu pour prédire la CLV dans les entreprises de Software-as-a-Service (SaaS) B2B. Les éléments clés de cette approche incluent :

Structure Modulaire Hiérarchique:

Prédiction à Court Terme (T'): Utilise des données récentes pour prédire la CLV sur une période plus courte.
Prédiction à Long Terme (T): Étend les prédictions à court terme pour couvrir la durée de vie complète du client.
Ensemble de Modèles:

Combine plusieurs modèles statistiques pour améliorer la précision des prédictions.
Utilise différents modèles pour différents segments de clients en fonction de leurs caractéristiques spécifiques.
Ingénierie des Caractéristiques:

Crée des caractéristiques significatives à partir de données brutes, telles que des métriques agrégées, des indicateurs de tendance, des caractéristiques décalées et des termes d'interaction.
Met l'accent sur les données récentes pour garantir que les prédictions sont basées sur les informations les plus pertinentes.
Évaluation du Modèle:

Utilise des métriques telles que RMSE (Root Mean Squared Error), MAE (Mean Absolute Error), et SMAPE (Symmetric Mean Absolute Percentage Error) pour évaluer la performance du modèle.
Effectue une analyse des résidus pour affiner la segmentation et la sélection du modèle.
Étapes et Conditions
Collecte des Données
Collecter des données clients à partir de diverses sources au sein de la banque, y compris l'historique des transactions, les données démographiques des clients, les produits détenus et les métriques d'engagement.
Assurer la collecte de divers types de données telles que des données catégorielles (par ex., segment de clients), des données entières (par ex., nombre de produits détenus), et des données continues (par ex., soldes de comptes).
Prétraitement des Données
Nettoyer les données en traitant les valeurs manquantes, en supprimant les doublons et en corrigeant les entrées incohérentes.
Transformer les données en normalisant les caractéristiques numériques et en encodant les variables catégorielles en utilisant des techniques telles que l'encodage one-hot.
Ingénierie des Caractéristiques
Métriques Agrégées: Calculer le total des transactions, la valeur moyenne des transactions et la fréquence des transactions.
Indicateurs de Tendance: Calculer les taux de croissance et les changements en pourcentage des soldes et des volumes de transactions.
Caractéristiques Décalées: Créer des caractéristiques représentant les valeurs passées de certaines métriques (par ex., solde du mois précédent, transactions du trimestre précédent).
Caractéristiques Cumulatives: Calculer les métriques cumulatives jusqu'au point d'observation.
Termes d'Interaction: Créer des termes d'interaction entre les caractéristiques pour capturer les effets combinés.
Entraînement du Modèle
Utiliser des modèles statistiques comme la régression linéaire et la régression des moindres carrés pour s'entraîner sur les caractéristiques générées.
Effectuer un ajustement des hyperparamètres pour optimiser la performance du modèle.
Évaluer les modèles en utilisant des métriques telles que RMSE, MAE, et SMAPE.
Déploiement du Modèle
Intégrer les modèles dans l'infrastructure informatique de la banque.
Automatiser les processus de collecte de données, de prétraitement, d'ingénierie des caractéristiques et de ré-entraînement du modèle.
Application Commerciale
Optimiser les stratégies marketing, améliorer la rétention des clients et adapter les offres de produits en fonction des prédictions de CLV.
Mener des analyses de retour sur investissement (ROI) pour guider l'allocation stratégique des ressources.
Projection de l'Approche sur Notre Cas d'Utilisation Spécifique
Prédiction à Court Terme
Pour le court terme, nous nous concentrerons sur la prédiction de la CLV cumulée sur une période de 2 à 3 ans. Cela nous permettra d'observer l'impact sur notre modèle et d'affiner nos processus d'ingénierie des caractéristiques et de sélection de modèle. Les prédictions à court terme utiliseront des données récentes pour garantir leur pertinence et leur précision.

Prédiction à Long Terme
Pour la prédiction à long terme, nous sélectionnerons des variables facilement prévisibles dans le temps. Celles-ci peuvent inclure des caractéristiques démographiques (par ex., âge, revenu), des comportements historiques (par ex., fréquence des transactions) et des métriques d'engagement (par ex., fréquence des connexions). La prédiction à long terme étendra les prédictions de CLV à court terme pour couvrir toute la durée de vie du client.

Conclusion
En implémentant les techniques statistiques de l'article, nous pouvons améliorer considérablement notre capacité à prédire et à tirer parti de la Valeur Vie Client. Cela nous permettra de prendre des décisions plus éclairées, d'optimiser les efforts marketing et d'améliorer la satisfaction et la rétention globales des clients. Le projet impliquera une collecte de données minutieuse, une ingénierie des caractéristiques robuste et des techniques de modélisation avancées pour atteindre ces objectifs.






import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import PolynomialFeatures

# Sample data
data = {
    'feature1': [1, 2, 3, 4, 5],
    'feature2': [5, 4, 3, 2, 1],
    'feature3': [2, 3, 4, 5, 6],
    'target': [10, 20, 30, 40, 50]  # Sample target variable
}

df = pd.DataFrame(data)

# Creating interaction features manually
df['interaction_f1_f2'] = df['feature1'] * df['feature2']
df['interaction_f1_f3'] = df['feature1'] * df['feature3']
df['interaction_f2_f3'] = df['feature2'] * df['feature3']

# Using PolynomialFeatures to generate polynomial combinations
poly = PolynomialFeatures(degree=2, include_bias=False, interaction_only=False)
poly_features = poly.fit_transform(df[['feature1', 'feature2', 'feature3']])

# Converting polynomial features to a DataFrame for better readability
poly_feature_names = poly.get_feature_names_out(['feature1', 'feature2', 'feature3'])
df_poly = pd.DataFrame(poly_features, columns=poly_feature_names)

# Add the target variable to the polynomial dataframe for plotting
df_poly['target'] = df['target']

# Plotting interaction features
plt.figure(figsize=(12, 6))
plt.subplot(1, 3, 1)
plt.scatter(df['interaction_f1_f2'], df['target'])
plt.xlabel('interaction_f1_f2')
plt.ylabel('target')
plt.title('Interaction: feature1 * feature2')

plt.subplot(1, 3, 2)
plt.scatter(df['interaction_f1_f3'], df['target'])
plt.xlabel('interaction_f1_f3')
plt.ylabel('target')
plt.title('Interaction: feature1 * feature3')

plt.subplot(1, 3, 3)
plt.scatter(df['interaction_f2_f3'], df['target'])
plt.xlabel('interaction_f2_f3')
plt.ylabel('target')
plt.title('Interaction: feature2 * feature3')

plt.tight_layout()
plt.show()

# Plotting polynomial features
plt.figure(figsize=(15, 10))
for i, feature_name in enumerate(poly_feature_names):
    plt.subplot(3, 3, i + 1)
    plt.scatter(df_poly[feature_name], df_poly['target'])
    plt.xlabel(feature_name)
    plt.ylabel('target')
    plt.title(f'Polynomial Feature: {feature_name}')

plt.tight_layout()
plt.show()





import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cross_decomposition import PLSRegression
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import r2_score
from xgboost import XGBRegressor
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
import lightgbm as lgb
from mpl_toolkits.mplot3d import Axes3D
import imageio
import os

# Example DataFrame
# df = pd.read_csv('your_data.csv')

# Assuming your target column is named 'target'
target_column = 'target'
features = df.drop(columns=[target_column])
target = df[target_column]

# Apply PLS for dimensionality reduction (n_components=2)
pls = PLSRegression(n_components=2)
pls.fit(features, target)
pls_results = pls.transform(features)

# Create a DataFrame with the PLS results
pls_df = pd.DataFrame(data=pls_results, columns=['PLS1', 'PLS2'])
pls_df[target_column] = target

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(pls_df[['PLS1', 'PLS2']], pls_df[target_column], test_size=0.2, random_state=42)

# Define parameter grids for each model
param_grids = {
    "XGBoost": {
        'n_estimators': [50, 100, 200],
        'max_depth': [3, 6, 9],
        'learning_rate': [0.01, 0.1, 0.2]
    },
    "Random Forest": {
        'n_estimators': [50, 100, 200],
        'max_depth': [None, 10, 20],
        'min_samples_split': [2, 5, 10]
    },
    "Gradient Boosting": {
        'n_estimators': [50, 100, 200],
        'max_depth': [3, 6, 9],
        'learning_rate': [0.01, 0.1, 0.2]
    },
    "LightGBM": {
        'n_estimators': [50, 100, 200],
        'num_leaves': [31, 61, 127],
        'learning_rate': [0.01, 0.1, 0.2]
    }
}

# Initialize models
models = {
    "XGBoost": XGBRegressor(),
    "Random Forest": RandomForestRegressor(),
    "Gradient Boosting": GradientBoostingRegressor(),
    "LightGBM": lgb.LGBMRegressor()
}

# Perform grid search and calculate R² scores
r2_scores = {}
best_params = {}

for name, model in models.items():
    print(f"Training {name}...")
    grid_search = GridSearchCV(model, param_grids[name], cv=3, scoring='r2', n_jobs=-1)
    grid_search.fit(X_train, y_train)
    best_model = grid_search.best_estimator_
    y_pred = best_model.predict(X_test)
    r2_scores[name] = r2_score(y_test, y_pred)
    best_params[name] = grid_search.best_params_
    print(f"Best parameters for {name}: {best_params[name]}")

# Plot the R² scores
plt.figure(figsize=(10, 6))
plt.bar(r2_scores.keys(), r2_scores.values())
plt.xlabel('Model')
plt.ylabel('R² Score')
plt.title('R² Scores of Different Models')
plt.ylim(0, 1)
plt.show()

# Create a rotating 3D plot of PLS1, PLS2, and the target
fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')

angles = range(0, 360, 10)
filenames = []

for angle in angles:
    ax.clear()
    ax.scatter(pls_df['PLS1'], pls_df['PLS2'], pls_df[target_column], c=pls_df[target_column], cmap='viridis')
    ax.set_xlabel('PLS1')
    ax.set_ylabel('PLS2')
    ax.set_zlabel(target_column)
    ax.set_title('3D Plot of PLS1, PLS2, and Target')
    ax.view_init(30, angle)
    filename = f'frame_{angle}.png'
    filenames.append(filename)
    plt.savefig(filename)

# Create a GIF from the saved frames
images = [imageio.imread(filename) for filename in filenames]
imageio.mimsave('rotation.gif', images, duration=0.1)

# Clean up the saved frames
for filename in filenames:
    os.remove(filename)

print("GIF saved as rotation.gif")







import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cross_decomposition import PLSRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score
from xgboost import XGBRegressor
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
import lightgbm as lgb
from mpl_toolkits.mplot3d import Axes3D
import imageio
import os

# Example DataFrame
# df = pd.read_csv('your_data.csv')

# Assuming your target column is named 'target'
target_column = 'target'
features = df.drop(columns=[target_column])
target = df[target_column]

# Apply PLS for dimensionality reduction (n_components=2)
pls = PLSRegression(n_components=2)
pls.fit(features, target)
pls_results = pls.transform(features)

# Create a DataFrame with the PLS results
pls_df = pd.DataFrame(data=pls_results, columns=['PLS1', 'PLS2'])
pls_df[target_column] = target

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(pls_df[['PLS1', 'PLS2']], pls_df[target_column], test_size=0.2, random_state=42)

# Initialize models
models = {
    "XGBoost": XGBRegressor(),
    "Random Forest": RandomForestRegressor(),
    "Gradient Boosting": GradientBoostingRegressor(),
    "LightGBM": lgb.LGBMRegressor()
}

# Train models and calculate R² scores
r2_scores = {}

for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    r2_scores[name] = r2_score(y_test, y_pred)

# Plot the R² scores
plt.figure(figsize=(10, 6))
plt.bar(r2_scores.keys(), r2_scores.values())
plt.xlabel('Model')
plt.ylabel('R² Score')
plt.title('R² Scores of Different Models')
plt.ylim(0, 1)
plt.show()

# Create a rotating 3D plot of PLS1, PLS2, and the target
fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')

angles = range(0, 360, 10)
filenames = []

for angle in angles:
    ax.clear()
    ax.scatter(pls_df['PLS1'], pls_df['PLS2'], pls_df[target_column], c=pls_df[target_column], cmap='viridis')
    ax.set_xlabel('PLS1')
    ax.set_ylabel('PLS2')
    ax.set_zlabel(target_column)
    ax.set_title('3D Plot of PLS1, PLS2, and Target')
    ax.view_init(30, angle)
    filename = f'frame_{angle}.png'
    filenames.append(filename)
    plt.savefig(filename)

# Create a GIF from the saved frames
images = [imageio.imread(filename) for filename in filenames]
imageio.mimsave('rotation.gif', images, duration=0.1)

# Clean up the saved frames
for filename in filenames:
    os.remove(filename)

print("GIF saved as rotation.gif")





import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cross_decomposition import PLSRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score
from xgboost import XGBRegressor
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
import lightgbm as lgb
from mpl_toolkits.mplot3d import Axes3D
import imageio

# Example DataFrame
# df = pd.read_csv('your_data.csv')

# Assuming your target column is named 'target'
target_column = 'target'
features = df.drop(columns=[target_column])
target = df[target_column]

# Apply PLS for dimensionality reduction (n_components=2)
pls = PLSRegression(n_components=2)
pls.fit(features, target)
pls_results = pls.transform(features)

# Create a DataFrame with the PLS results
pls_df = pd.DataFrame(data=pls_results, columns=['PLS1', 'PLS2'])
pls_df[target_column] = target

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(pls_df[['PLS1', 'PLS2']], pls_df[target_column], test_size=0.2, random_state=42)

# Initialize models
models = {
    "XGBoost": XGBRegressor(),
    "Random Forest": RandomForestRegressor(),
    "Gradient Boosting": GradientBoostingRegressor(),
    "LightGBM": lgb.LGBMRegressor()
}

# Train models and calculate R² scores
r2_scores = {}

for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    r2_scores[name] = r2_score(y_test, y_pred)

# Plot the R² scores
plt.figure(figsize=(10, 6))
plt.bar(r2_scores.keys(), r2_scores.values())
plt.xlabel('Model')
plt.ylabel('R² Score')
plt.title('R² Scores of Different Models')
plt.ylim(0, 1)
plt.show()

# Create a rotating 3D plot of PLS1, PLS2, and the target
fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')
ax.scatter(pls_df['PLS1'], pls_df['PLS2'], pls_df[target_column], c=pls_df[target_column], cmap='viridis')
ax.set_xlabel('PLS1')
ax.set_ylabel('PLS2')
ax.set_zlabel(target_column)
ax.set_title('3D Plot of PLS1, PLS2, and Target')

# Save frames for the GIF
angles = range(0, 360, 10)
filenames = []

for angle in angles:
    ax.view_init(30, angle)
    filename = f'frame_{angle}.png'
    filenames.append(filename)
    plt.savefig(filename)
    plt.clf()

# Create a GIF from the saved frames
images = [imageio.imread(filename) for filename in filenames]
imageio.mimsave('rotation.gif', images, duration=0.1)

# Clean up the saved frames
for filename in filenames:
    os.remove(filename)

print("GIF saved as rotation.gif")








import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cross_decomposition import PLSRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score
from xgboost import XGBRegressor
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
import lightgbm as lgb

# Example DataFrame
# df = pd.read_csv('your_data.csv')

# Assuming your target column is named 'target'
target_column = 'target'
features = df.drop(columns=[target_column])
target = df[target_column]

# Apply PLS for dimensionality reduction (n_components=2)
pls = PLSRegression(n_components=2)
pls.fit(features, target)
pls_results = pls.transform(features)

# Create a DataFrame with the PLS results
pls_df = pd.DataFrame(data=pls_results, columns=['PLS1', 'PLS2'])
pls_df[target_column] = target

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(pls_df[['PLS1', 'PLS2']], pls_df[target_column], test_size=0.2, random_state=42)

# Initialize models
models = {
    "XGBoost": XGBRegressor(),
    "Random Forest": RandomForestRegressor(),
    "Gradient Boosting": GradientBoostingRegressor(),
    "LightGBM": lgb.LGBMRegressor()
}

# Train models and calculate R² scores
r2_scores = {}

for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    r2_scores[name] = r2_score(y_test, y_pred)

# Plot the R² scores
plt.figure(figsize=(10, 6))
plt.bar(r2_scores.keys(), r2_scores.values())
plt.xlabel('Model')
plt.ylabel('R² Score')
plt.title('R² Scores of Different Models')
plt.ylim(0, 1)
plt.show()





import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cross_decomposition import PLSRegression
from sklearn.preprocessing import LabelEncoder

# Example DataFrame
# df = pd.read_csv('your_data.csv')

# Assuming your target column is named 'target'
target_column = 'target'
features = df.drop(columns=[target_column])
target = df[target_column]

# Apply PLS for dimensionality reduction (n_components=2)
# Note: Typically PLS is used for regression, but here we're using it for dimension reduction
pls = PLSRegression(n_components=2)
pls.fit(features, target)
pls_results = pls.transform(features)

# Create a DataFrame with the PLS results
pls_df = pd.DataFrame(data=pls_results, columns=['PLS1', 'PLS2'])

# Function to plot scatter with color based on a given column
def plot_scatter(data, color_column):
    plt.figure(figsize=(10, 6))
    if pd.api.types.is_numeric_dtype(data[color_column]):
        scatter = plt.scatter(data['PLS1'], data['PLS2'], c=data[color_column], cmap='viridis')
        plt.colorbar(scatter)
    else:
        label_encoder = LabelEncoder()
        data['encoded'] = label_encoder.fit_transform(data[color_column])
        scatter = plt.scatter(data['PLS1'], data['PLS2'], c=data['encoded'], cmap='viridis')
        plt.legend(handles=scatter.legend_elements()[0], labels=label_encoder.classes_)
    plt.xlabel('PLS1')
    plt.ylabel('PLS2')
    plt.title(f'PLS plot colored by {color_column}')
    plt.show()

# Plot the PLS results colored by each original variable
for column in df.columns:
    if column != target_column:
        plot_scatter(pd.concat([pls_df, df[column]], axis=1), column)




import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cross_decomposition import PLSRegression
from sklearn.preprocessing import LabelEncoder

# Example DataFrame
# df = pd.read_csv('your_data.csv')

# Assuming your target column is named 'target'
target_column = 'target'
features = df.drop(columns=[target_column])
target = df[target_column]

# Apply PLS for dimensionality reduction (n_components=2)
pls = PLSRegression(n_components=2)
pls.fit(features, np.zeros((features.shape[0], 1)))  # Dummy Y
pls_results = pls.transform(features)

# Create a DataFrame with the PLS results
pls_df = pd.DataFrame(data=pls_results, columns=['PLS1', 'PLS2'])

# Function to plot scatter with color based on a given column
def plot_scatter(data, color_column):
    plt.figure(figsize=(10, 6))
    if pd.api.types.is_numeric_dtype(data[color_column]):
        scatter = plt.scatter(data['PLS1'], data['PLS2'], c=data[color_column], cmap='viridis')
        plt.colorbar(scatter)
    else:
        label_encoder = LabelEncoder()
        data['encoded'] = label_encoder.fit_transform(data[color_column])
        scatter = plt.scatter(data['PLS1'], data['PLS2'], c=data['encoded'], cmap='viridis')
        plt.legend(handles=scatter.legend_elements()[0], labels=label_encoder.classes_)
    plt.xlabel('PLS1')
    plt.ylabel('PLS2')
    plt.title(f'PLS plot colored by {color_column}')
    plt.show()

# Plot the PLS results colored by each original variable
for column in df.columns:
    if column != target_column:
        plot_scatter(pd.concat([pls_df, df[column]], axis=1), column)





import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.manifold import Isomap
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.cross_decomposition import PLSRegression

# Example DataFrame
# df = pd.read_csv('your_data.csv')

# Assuming your target column is named 'target'
target_column = 'target'
features = df.drop(columns=[target_column])
target = df[target_column]

# Standardize the features
scaler = StandardScaler()
features_standardized = scaler.fit_transform(features)

# Apply PLS for dimensionality reduction (n_components=2)
pls = PLSRegression(n_components=2)
pls.fit(features_standardized, np.zeros((features_standardized.shape[0], 1)))  # Dummy Y
pls_results = pls.transform(features_standardized)

# Create a DataFrame with the PLS results
pls_df = pd.DataFrame(data=pls_results, columns=['PLS1', 'PLS2'])

# Function to plot scatter with color based on a given column
def plot_scatter(data, color_column):
    plt.figure(figsize=(10, 6))
    if pd.api.types.is_numeric_dtype(data[color_column]):
        scatter = plt.scatter(data['PLS1'], data['PLS2'], c=data[color_column], cmap='viridis')
        plt.colorbar(scatter)
    else:
        label_encoder = LabelEncoder()
        data['encoded'] = label_encoder.fit_transform(data[color_column])
        scatter = plt.scatter(data['PLS1'], data['PLS2'], c=data['encoded'], cmap='viridis')
        plt.legend(handles=scatter.legend_elements()[0], labels=label_encoder.classes_)
    plt.xlabel('PLS1')
    plt.ylabel('PLS2')
    plt.title(f'PLS plot colored by {color_column}')
    plt.show()

# Plot the PLS results colored by each original variable
for column in df.columns:
    if column != target_column:
        plot_scatter(pd.concat([pls_df, df[column]], axis=1), column)





import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.manifold import Isomap
from sklearn.preprocessing import StandardScaler, LabelEncoder

# Example DataFrame
# df = pd.read_csv('your_data.csv')

# Assuming your target column is named 'target'
target_column = 'target'
features = df.drop(columns=[target_column])
target = df[target_column]

# Standardize the features
scaler = StandardScaler()
features_standardized = scaler.fit_transform(features)

# Apply Isomap
isomap = Isomap(n_components=2)
isomap_results = isomap.fit_transform(features_standardized)

# Create a DataFrame with the Isomap results
isomap_df = pd.DataFrame(data=isomap_results, columns=['ISOMAP1', 'ISOMAP2'])

# Function to plot scatter with color based on a given column
def plot_scatter(data, color_column):
    plt.figure(figsize=(10, 6))
    if pd.api.types.is_numeric_dtype(data[color_column]):
        scatter = plt.scatter(data['ISOMAP1'], data['ISOMAP2'], c=data[color_column], cmap='viridis')
        plt.colorbar(scatter)
    else:
        label_encoder = LabelEncoder()
        data['encoded'] = label_encoder.fit_transform(data[color_column])
        scatter = plt.scatter(data['ISOMAP1'], data['ISOMAP2'], c=data['encoded'], cmap='viridis')
        plt.legend(handles=scatter.legend_elements()[0], labels=label_encoder.classes_)
    plt.xlabel('ISOMAP1')
    plt.ylabel('ISOMAP2')
    plt.title(f'Isomap plot colored by {color_column}')
    plt.show()

# Plot the Isomap results colored by each original variable
for column in df.columns:
    if column != target_column:
        plot_scatter(pd.concat([isomap_df, df[column]], axis=1), column)




import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.manifold import Isomap
from sklearn.preprocessing import LabelEncoder

# Example DataFrame
# df = pd.read_csv('your_data.csv')

# Assuming your target column is named 'target'
target_column = 'target'
features = df.drop(columns=[target_column])
target = df[target_column]

# Apply Isomap
isomap = Isomap(n_components=2)
isomap_results = isomap.fit_transform(features)

# Create a DataFrame with the Isomap results
isomap_df = pd.DataFrame(data=isomap_results, columns=['ISOMAP1', 'ISOMAP2'])

# Function to plot scatter with color based on a given column
def plot_scatter(data, color_column):
    plt.figure(figsize=(10, 6))
    if pd.api.types.is_numeric_dtype(data[color_column]):
        scatter = plt.scatter(data['ISOMAP1'], data['ISOMAP2'], c=data[color_column], cmap='viridis')
        plt.colorbar(scatter)
    else:
        label_encoder = LabelEncoder()
        data['encoded'] = label_encoder.fit_transform(data[color_column])
        scatter = plt.scatter(data['ISOMAP1'], data['ISOMAP2'], c=data['encoded'], cmap='viridis')
        plt.legend(handles=scatter.legend_elements()[0], labels=label_encoder.classes_)
    plt.xlabel('ISOMAP1')
    plt.ylabel('ISOMAP2')
    plt.title(f'Isomap plot colored by {color_column}')
    plt.show()

# Plot the Isomap results colored by each original variable
for column in df.columns:
    if column != target_column:
        plot_scatter(pd.concat([isomap_df, df[column]], axis=1), column)






import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.manifold import TSNE
from sklearn.preprocessing import LabelEncoder

# Example DataFrame
# df = pd.read_csv('your_data.csv')

# Assuming your target column is named 'target'
target_column = 'target'
features = df.drop(columns=[target_column])
target = df[target_column]

# Apply t-SNE
tsne = TSNE(n_components=2, random_state=42)
tsne_results = tsne.fit_transform(features)

# Create a DataFrame with the t-SNE results
tsne_df = pd.DataFrame(data=tsne_results, columns=['TSNE1', 'TSNE2'])
tsne_df[target_column] = target.values

# Encode target labels for coloring
label_encoder = LabelEncoder()
tsne_df['target_encoded'] = label_encoder.fit_transform(tsne_df[target_column])

# Plot the t-SNE results
plt.figure(figsize=(10, 6))
scatter = plt.scatter(tsne_df['TSNE1'], tsne_df['TSNE2'], c=tsne_df['target_encoded'], cmap='viridis')
plt.legend(handles=scatter.legend_elements()[0], labels=label_encoder.classes_)
plt.xlabel('TSNE1')
plt.ylabel('TSNE2')
plt.title('t-SNE plot')
plt.show()






# Generating a more complex example dataset
np.random.seed(0)
x_complex = np.linspace(-10, 10, 200)
y_complex = np.piecewise(x_complex,
                         [x_complex < -5, (x_complex >= -5) & (x_complex < 5), x_complex >= 5],
                         [lambda x: 2 * x + 1,
                          lambda x: -3 * x + 10,
                          lambda x: 0.5 * x - 5]) + np.random.normal(0, 1, x_complex.size)
from scipy.stats import spearmanr

# Greedy method for segmentation using Spearman correlation
def greedy_segmentation_spearman(x, y, max_segments):
    n = len(x)
    best_correlation = -np.inf
    best_segmentation = None
    best_models = []

    for num_segs in range(1, max_segments + 1):
        for split_points in combinations(range(1, n), num_segs):
            splits = [0] + list(split_points) + [n]
            total_correlation = 0
            models = []
            
            for i in range(len(splits) - 1):
                x_seg = x[splits[i]:splits[i+1]].reshape(-1, 1)
                y_seg = y[splits[i]:splits[i+1]]
                model = LinearRegression().fit(x_seg, y_seg)
                y_pred = model.predict(x_seg)
                corr, _ = spearmanr(y_seg, y_pred)
                total_correlation += corr
                models.append(model)
            
            if total_correlation > best_correlation:
                best_correlation = total_correlation
                best_segmentation = splits
                best_models = models
                
    return best_correlation, best_segmentation, best_models

# Finding optimal segmentation with Spearman correlation
best_corr, best_segmentation_spearman, best_models_spearman = greedy_segmentation_spearman(x_complex, y_complex, max_segments=3)

# Plotting the data and the best segmentation
plt.figure(figsize=(10, 6))
plt.scatter(x_complex, y_complex, color='blue', alpha=0.5, label='Data')
colors = ['red', 'green', 'orange']

for i in range(len(best_segmentation_spearman) - 1):
    start, end = best_segmentation_spearman[i], best_segmentation_spearman[i+1]
    x_seg = x_complex[start:end]
    y_seg = y_complex[start:end]
    y_pred = best_models_spearman[i].predict(x_seg.reshape(-1, 1))
    plt.plot(x_seg, y_pred, color=colors[i], linestyle='--', label=f'Segment {i+1}')

plt.xlabel('x')
plt.ylabel('y')
plt.title('Optimal Segmentation with Spearman Correlation')
plt.legend()
plt.grid(True)
plt.show()

best_corr, best_segmentation_spearman







import numpy as np
import pandas as pd
from sklearn.metrics import r2_score
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from xgboost import XGBRegressor

# Function to compute R² evolution with increasing observations
def r2_evolution(df, target):
    # Sort the DataFrame by the target variable
    df_sorted = df.sort_values(by=target)
    
    r2_scores = []
    observation_counts = []
    
    # Start with the first 1000 observations and increment by 500
    for i in range(1000, len(df_sorted), 500):
        subset = df_sorted.iloc[:i]
        X = subset.drop(columns=[target])
        y = subset[target]
        
        # Split the data into training and testing sets
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        
        # Train an XGBoost model
        model = XGBRegressor()
        model.fit(X_train, y_train)
        
        # Predict and calculate R² score
        y_pred = model.predict(X_test)
        r2 = r2_score(y_test, y_pred)
        
        r2_scores.append(r2)
        observation_counts.append(i)
    
    # Plotting the R² evolution
    plt.figure(figsize=(10, 6))
    plt.plot(observation_counts, r2_scores, marker='o', linestyle='-', color='b')
    plt.title('R² Evolution with Increasing Observations')
    plt.xlabel('Number of Observations')
    plt.ylabel('R² Score')
    plt.grid(True)
    plt.show()

# Example usage
# r2_evolution(df, 'target_column_name')




import numpy as np
import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split

# Assuming df is your DataFrame and 'target' is your target variable
def r2_evolution(df, target):
    # Sort the DataFrame by the target variable
    df_sorted = df.sort_values(by=target)
    
    r2_scores = []
    observation_counts = []
    
    # Start with the first 1000 observations and increment by 500
    for i in range(1000, len(df_sorted), 500):
        subset = df_sorted.iloc[:i]
        X = subset.drop(columns=[target])
        y = subset[target]
        
        # Split the data into training and testing sets
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        
        # Train a linear regression model
        model = LinearRegression()
        model.fit(X_train, y_train)
        
        # Predict and calculate R² score
        y_pred = model.predict(X_test)
        r2 = r2_score(y_test, y_pred)
        
        r2_scores.append(r2)
        observation_counts.append(i)
    
    # Plotting the R² evolution
    plt.figure(figsize=(10, 6))
    plt.plot(observation_counts, r2_scores, marker='o', linestyle='-', color='b')
    plt.title('R² Evolution with Increasing Observations')
    plt.xlabel('Number of Observations')
    plt.ylabel('R² Score')
    plt.grid(True)
    plt.show()

# Example usage
# r2_evolution(df, 'target_column_name')



import pandas as pd
from sklearn.linear_model import LinearRegression, HuberRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVR
from xgboost import XGBRegressor
from lightgbm import LGBMRegressor
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt

# Load your datasets
df_2018 = pd.read_csv('data_2018.csv')  # Replace with your actual data source
df_2019 = pd.read_csv('data_2019.csv')  # Replace with your actual data source

# Assume there's a common column named 'id' to merge on. If not, this can be omitted.
common_column = 'id'

# Define models to be used
models = {
    'Linear Regression': LinearRegression(),
    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),
    'Support Vector Regressor': SVR(),
    'Huber Regressor': HuberRegressor(),
    'XGBoost': XGBRegressor(objective='reg:squarederror', random_state=42),
    'LightGBM': LGBMRegressor(random_state=42)
}

# Prepare a DataFrame to store results
results = pd.DataFrame(columns=['Variable', 'Model', 'MSE', 'R²', 'Adjusted R²'])

# Function to calculate adjusted R²
def adjusted_r2(r2, n, k):
    return 1 - (1 - r2) * (n - 1) / (n - k - 1)

# Iterate over each column and predict 2019 values based on 2018 data
for column in df_2018.columns:
    # Skip the common_column or non-numeric columns if any
    if column == common_column or not pd.api.types.is_numeric_dtype(df_2018[column]):
        continue

    # Merge datasets based on the common column
    merged_data = pd.merge(df_2018[[common_column, column]], df_2019[[common_column, column]],
                           on=common_column, suffixes=('_2018', '_2019'))

    # Drop rows where the 2019 column has NaN values
    merged_data.dropna(subset=[column + '_2019'], inplace=True)

    X = merged_data[column + '_2018'].values.reshape(-1, 1)
    y = merged_data[column + '_2019'].values
    n = len(y)
    k = 1  # number of independent variables

    for model_name, model in models.items():
        # Fit the model
        model.fit(X, y)
        predictions = model.predict(X)
        mse = mean_squared_error(y, predictions)
        r2 = r2_score(y, predictions)
        adj_r2 = adjusted_r2(r2, n, k)

        # Store the results
        results = pd.concat([results, pd.DataFrame({
            'Variable': [column],
            'Model': [model_name],
            'MSE': [mse],
            'R²': [r2],
            'Adjusted R²': [adj_r2]
        })], ignore_index=True)

# Display results
print(results)

# Plotting results
fig, axs = plt.subplots(1, 3, figsize=(18, 6))
models_list = results['Model'].unique()

for i, metric in enumerate(['MSE', 'R²', 'Adjusted R²']):
    for model_name in models_list:
        data = results[results['Model'] == model_name]
        axs[i].plot(data['Variable'], data[metric], marker='o', label=model_name)
    axs[i].set_title(metric)
    axs[i].set_xlabel('Variable')
    axs[i].set_ylabel(metric)
    axs[i].legend()

plt.tight_layout()
plt.show()





import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt

# Load your datasets
df_2018 = pd.read_csv('data_2018.csv')  # Replace with your actual data source
df_2019 = pd.read_csv('data_2019.csv')  # Replace with your actual data source

# Assume there's a common column named 'id' to merge on. If not, this can be omitted.
common_column = 'id'

# Define models to be used
models = {
    'Linear Regression': LinearRegression(),
    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),
    'Support Vector Regressor': SVR()
}

# Prepare a DataFrame to store results
results = pd.DataFrame(columns=['Variable', 'Model', 'MSE', 'R²', 'Adjusted R²'])

# Function to calculate adjusted R²
def adjusted_r2(r2, n, k):
    return 1 - (1 - r2) * (n - 1) / (n - k - 1)

# Iterate over each column and predict 2019 values based on 2018 data
for column in df_2018.columns:
    # Skip the common_column or non-numeric columns if any
    if column == common_column or not pd.api.types.is_numeric_dtype(df_2018[column]):
        continue

    # Merge datasets based on the common column
    merged_data = pd.merge(df_2018[[common_column, column]], df_2019[[common_column, column]],
                           on=common_column, suffixes=('_2018', '_2019'))

    # Drop rows where the 2019 column has NaN values
    merged_data.dropna(subset=[column + '_2019'], inplace=True)

    X = merged_data[column + '_2018'].values.reshape(-1, 1)
    y = merged_data[column + '_2019'].values
    n = len(y)
    k = 1  # number of independent variables

    for model_name, model in models.items():
        # Fit the model
        model.fit(X, y)
        predictions = model.predict(X)
        mse = mean_squared_error(y, predictions)
        r2 = r2_score(y, predictions)
        adj_r2 = adjusted_r2(r2, n, k)

        # Store the results
        results = pd.concat([results, pd.DataFrame({
            'Variable': [column],
            'Model': [model_name],
            'MSE': [mse],
            'R²': [r2],
            'Adjusted R²': [adj_r2]
        })], ignore_index=True)

# Display results
print(results)

# Plotting results
fig, axs = plt.subplots(1, 3, figsize=(18, 6))
models_list = results['Model'].unique()

for i, metric in enumerate(['MSE', 'R²', 'Adjusted R²']):
    for model_name in models_list:
        data = results[results['Model'] == model_name]
        axs[i].plot(data['Variable'], data[metric], marker='o', label=model_name)
    axs[i].set_title(metric)
    axs[i].set_xlabel('Variable')
    axs[i].set_ylabel(metric)
    axs[i].legend()

plt.tight_layout()
plt.show()








import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error

# Load your datasets
df_2018 = pd.read_csv('data_2018.csv')  # Replace with your actual data source
df_2019 = pd.read_csv('data_2019.csv')  # Replace with your actual data source

# Assume there's a common column named 'id' to merge on. If not, this can be omitted.
common_column = 'id'

# Define models to be used
models = {
    'Linear Regression': LinearRegression(),
    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),
    'Support Vector Regressor': SVR()
}

# Prepare a DataFrame to store results
results = pd.DataFrame(columns=['Variable', 'Model', 'MSE'])

# Iterate over each column and predict 2019 values based on 2018 data
for column in df_2018.columns:
    # Skip the common_column or non-numeric columns if any
    if column == common_column or not pd.api.types.is_numeric_dtype(df_2018[column]):
        continue

    # Merge datasets based on the common column
    merged_data = pd.merge(df_2018[[common_column, column]], df_2019[[common_column, column]],
                           on=common_column, suffixes=('_2018', '_2019'))

    # Drop rows where the 2019 column has NaN values
    merged_data.dropna(subset=[column + '_2019'], inplace=True)

    X = merged_data[column + '_2018'].values.reshape(-1, 1)
    y = merged_data[column + '_2019'].values

    for model_name, model in models.items():
        # Fit the model
        model.fit(X, y)
        predictions = model.predict(X)
        mse = mean_squared_error(y, predictions)

        # Store the results
        results = pd.concat([results, pd.DataFrame({
            'Variable': [column],
            'Model': [model_name],
            'MSE': [mse]
        })], ignore_index=True)

# Display results
print(results)





import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error

# Load your datasets
df_2018 = pd.read_csv('data_2018.csv')  # Replace with your actual data source
df_2019 = pd.read_csv('data_2019.csv')  # Replace with your actual data source

# Assume there's a common column named 'id' to merge on. If not, this can be omitted.
common_column = 'id'

# Define models to be used
models = {
    'Linear Regression': LinearRegression(),
    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),
    'Support Vector Regressor': SVR()
}

# Prepare a DataFrame to store results
results = pd.DataFrame(columns=['Variable', 'Model', 'MSE'])

# Iterate over each column and predict 2019 values based on 2018 data
for column in df_2018.columns:
    # Skip the common_column or non-numeric columns if any
    if column == common_column or not pd.api.types.is_numeric_dtype(df_2018[column]):
        continue

    # Merge datasets based on the common column
    merged_data = pd.merge(df_2018[[common_column, column]], df_2019[[common_column, column]],
                           on=common_column, suffixes=('_2018', '_2019'))

    # Drop rows where the 2019 column has NaN values
    merged_data.dropna(subset=[column + '_2019'], inplace=True)

    X = merged_data[column + '_2018'].values.reshape(-1, 1)
    y = merged_data[column + '_2019'].values

    for model_name, model in models.items():
        # Fit the model
        model.fit(X, y)
        predictions = model.predict(X)
        mse = mean_squared_error(y, predictions)

        # Store the results
        results = results.append({
            'Variable': column,
            'Model': model_name,
            'MSE': mse
        }, ignore_index=True)

# Display results
print(results)







import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error

# Load your datasets
df_2018 = pd.read_csv('data_2018.csv')  # Replace with your actual data source
df_2019 = pd.read_csv('data_2019.csv')  # Replace with your actual data source

# Ensure the datasets are sorted and aligned if necessary
# df_2018 = df_2018.sort_values(by='common_column').reset_index(drop=True)  # If needed
# df_2019 = df_2019.sort_values(by='common_column').reset_index(drop=True)  # If needed

# Define models to be used
models = {
    'Linear Regression': LinearRegression(),
    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),
    'Support Vector Regressor': SVR()
}

# Prepare a DataFrame to store results
results = pd.DataFrame(columns=['Variable', 'Model', 'MSE'])

# Iterate over each column and predict 2019 values based on 2018 data
for column in df_2018.columns:
    # Skip non-numeric or unwanted columns if any
    if not pd.api.types.is_numeric_dtype(df_2018[column]):
        continue

    X = df_2018[column].values.reshape(-1, 1)
    y = df_2019[column].values

    for model_name, model in models.items():
        # Fit the model
        model.fit(X, y)
        predictions = model.predict(X)
        mse = mean_squared_error(y, predictions)

        # Store the results
        results = results.append({
            'Variable': column,
            'Model': model_name,
            'MSE': mse
        }, ignore_index=True)

# Display results
print(results)








import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline

# Load your datasets
df_2018 = pd.read_csv('data_2018.csv')  # Replace with your actual data source
df_2019 = pd.read_csv('data_2019.csv')  # Replace with your actual data source

# Ensure the datasets are sorted and aligned
df_2018 = df_2018.sort_values(by='common_column').reset_index(drop=True)  # Replace 'common_column' with a key column if needed
df_2019 = df_2019.sort_values(by='common_column').reset_index(drop=True)  # Replace 'common_column' with a key column if needed

# Define models to be used
models = {
    'Linear Regression': LinearRegression(),
    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),
}

# Iterate over each column and predict 2019 values based on 2018 data
results = []

for column in df_2018.columns:
    if column == 'common_column':  # Skip key columns or non-predictive columns
        continue

    X = df_2018.drop(columns=[column, 'common_column'])
    y = df_2018[column]
    X_test = df_2019.drop(columns=[column, 'common_column'])
    y_test = df_2019[column]

    column_results = {'Column': column}
    
    for model_name, model in models.items():
        # Use a pipeline to include scaling if necessary
        pipeline = make_pipeline(StandardScaler(), model)
        pipeline.fit(X, y)
        predictions = pipeline.predict(X_test)
        mse = mean_squared_error(y_test, predictions)
        column_results[model_name + ' MSE'] = mse

    results.append(column_results)

# Convert results to DataFrame and display
results_df = pd.DataFrame(results)
print(results_df)





import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib.animation import FuncAnimation
from itertools import combinations
import seaborn as sns

# Sample data for demonstration
Y = np.random.rand(100) * 10  # Random float numbers between 0 and 10
Y.sort()
min_number_per_seg = 5
N = 4  # Number of segments
step_size = 2  # Step size for selecting segmentation points

# Create a DataFrame with the sample data
df = pd.DataFrame({'value': Y})

def is_valid_segmentation(segments, min_count):
    # Count numbers in each segment
    segment_counts = [np.sum((Y >= segments[i]) & (Y < segments[i+1])) for i in range(len(segments) - 1)]
    segment_counts.append(np.sum(Y >= segments[-1]))  # For the last segment
    return all(count >= min_count for count in segment_counts)

# Create a list of valid segmentations and store in DataFrame
valid_segments = []
segmentation_results = pd.DataFrame({'value': Y})

# Apply step size by filtering Y
filtered_Y = Y[::step_size]  # Taking every step_size-th element

for idx, split_points in enumerate(combinations(filtered_Y, N-1)):  # We need N-1 split points for N segments
    if is_valid_segmentation(split_points, min_number_per_seg):
        valid_segments.append(split_points)
        # Create a new column for each valid segmentation
        segmentation_results[f'segment_{idx}'] = np.digitize(Y, bins=split_points, right=False)

# If no valid segments, exit early
if not valid_segments:
    print("No valid segmentations found. Exiting.")
    exit()

# Set up the plot
fig, ax = plt.subplots()
sns.set(style="whitegrid")

# Initialize the plot elements
def init():
    ax.clear()
    ax.set_xlim(np.min(Y), np.max(Y))
    ax.set_ylim(0, 20)  # Adjust ylim based on data
    return []

# Animation function
def animate(i):
    ax.clear()
    segments = valid_segments[i]
    df['segment'] = np.digitize(df['value'], bins=segments, right=False)
    
    # Plot each segment as a histogram using Seaborn
    sns.histplot(df, x='value', hue='segment', element="step", palette='tab10', ax=ax)
    
    ax.set_title(f'Valid Segmentation {i+1}')
    return []

# Create the animation
ani = FuncAnimation(fig, animate, init_func=init, frames=len(valid_segments), interval=200, blit=False)

# Save the animation as a GIF file
ani.save('segmented_histogram_animation.gif', writer='pillow')

plt.show()

# Save the segmentation results DataFrame to a CSV file
segmentation_results.to_csv('segmentation_results.csv', index=False)






import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay, f1_score
from xgboost import XGBClassifier
from deap import base, creator, tools, algorithms

# Generate a synthetic dataset
np.random.seed(0)
data = pd.DataFrame(np.random.randn(1000, 10), columns=[f'feature_{i}' for i in range(10)])
data['target'] = np.random.randint(0, 2, 1000)  # Binary target variable

# Split the data into features and target
X = data.drop(columns='target')
y = data['target']

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# Define the fitness function to maximize F1 score
def fitness_function(individual):
    n_estimators, max_depth, learning_rate = individual
    n_estimators = int(n_estimators)
    max_depth = int(max_depth)
    learning_rate = float(learning_rate)
    
    # Ensure hyperparameters are within valid ranges
    if n_estimators < 1 or max_depth < 1 or learning_rate <= 0 or learning_rate > 1:
        return -1.0,  # Invalid fitness score for invalid parameter ranges

    model = XGBClassifier(
        n_estimators=n_estimators,
        max_depth=max_depth,
        learning_rate=learning_rate,
        use_label_encoder=False,
        eval_metric='logloss',
        random_state=0
    )
    
    # Evaluate the model using cross-validation with F1 score
    try:
        scores = cross_val_score(model, X_train, y_train, cv=3, scoring='f1')
        return scores.mean(),
    except Exception as e:
        # Handle cases where the model fails to train
        return -1.0,  # Invalid fitness score

# Define the GA components
creator.create("FitnessMax", base.Fitness, weights=(1.0,))
creator.create("Individual", list, fitness=creator.FitnessMax)

toolbox = base.Toolbox()
toolbox.register("attr_int", np.random.randint, 50, 200)  # Range for n_estimators
toolbox.register("attr_int2", np.random.randint, 1, 10)   # Range for max_depth
toolbox.register("attr_float", np.random.uniform, 0.01, 1.0)  # Range for learning_rate
toolbox.register("individual", tools.initCycle, creator.Individual,
                 (toolbox.attr_int, toolbox.attr_int2, toolbox.attr_float), n=1)
toolbox.register("population", tools.initRepeat, list, toolbox.individual)

toolbox.register("evaluate", fitness_function)
toolbox.register("mate", tools.cxBlend, alpha=0.5)

# Correct mutation function to ensure valid values
def mutate_individual(individual, low, up, indpb):
    size = len(individual)
    for i in range(size):
        if np.random.rand() < indpb:
            if i == 2:  # learning_rate
                individual[i] = np.clip(np.random.uniform(0.01, 1.0), low[i], up[i])
            else:
                individual[i] = np.clip(int(np.random.randint(low[i], up[i])), low[i], up[i])
    return individual,

toolbox.register("mutate", mutate_individual, low=[50, 1, 0.01], up=[200, 10, 1.0], indpb=0.2)
toolbox.register("select", tools.selTournament, tournsize=3)

# Run the Genetic Algorithm
population = toolbox.population(n=20)  # Small population for simplicity
NGEN = 10
CXPB, MUTPB = 0.5, 0.2
f1_scores = []

for gen in range(NGEN):
    offspring = algorithms.varAnd(population, toolbox, CXPB, MUTPB)
    invalid_ind = [ind for ind in offspring if not ind.fitness.valid]
    fitnesses = map(toolbox.evaluate, invalid_ind)
    for ind, fit in zip(invalid_ind, fitnesses):
        ind.fitness.values = fit
    
    population = toolbox.select(offspring, k=len(population))
    
    # Record the best F1 score for this generation
    best_f1 = tools.selBest(population, k=1)[0].fitness.values[0]
    f1_scores.append(best_f1)

# Extract the best individual
best_individual = tools.selBest(population, k=1)[0]
best_params = [int(best_individual[0]), int(best_individual[1]), best_individual[2]]
print("Best hyperparameters found:", best_params)

# Train the final model with the best hyperparameters
xgb = XGBClassifier(
    n_estimators=best_params[0],
    max_depth=best_params[1],
    learning_rate=best_params[2],
    use_label_encoder=False,
    eval_metric='logloss',
    random_state=0
)
xgb.fit(X_train, y_train)

# Predict the target values for the test set
y_pred = xgb.predict(X_test)

# Compute the confusion matrix
cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot(cmap=plt.cm.Blues)
plt.title("Confusion Matrix")
plt.show()

# Generate and print the classification report
report = classification_report(y_test, y_pred)
print("Classification Report:")
print(report)

# Plot the evolution of the F1 score through generations
plt.plot(range(1, NGEN+1), f1_scores, marker='o')
plt.xlabel('Generation')
plt.ylabel('F1 Score')
plt.title('Evolution of F1 Score through Generations')
plt.show()





import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay, f1_score
from xgboost import XGBClassifier
from deap import base, creator, tools, algorithms

# Generate a synthetic dataset
np.random.seed(0)
data = pd.DataFrame(np.random.randn(1000, 10), columns=[f'feature_{i}' for i in range(10)])
data['target'] = np.random.randint(0, 2, 1000)  # Binary target variable

# Split the data into features and target
X = data.drop(columns='target')
y = data['target']

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# Define the fitness function to maximize F1 score
def fitness_function(individual):
    n_estimators, max_depth, learning_rate = individual
    n_estimators = int(n_estimators)
    max_depth = int(max_depth)
    learning_rate = float(learning_rate)
    
    # Ensure hyperparameters are within valid ranges
    if n_estimators < 1 or max_depth < 1 or learning_rate <= 0 or learning_rate > 1:
        return -1.0,  # Invalid fitness score for invalid parameter ranges

    model = XGBClassifier(
        n_estimators=n_estimators,
        max_depth=max_depth,
        learning_rate=learning_rate,
        use_label_encoder=False,
        eval_metric='logloss',
        random_state=0
    )
    
    # Evaluate the model using cross-validation with F1 score
    try:
        scores = cross_val_score(model, X_train, y_train, cv=3, scoring='f1')
        return scores.mean(),
    except Exception as e:
        # Handle cases where the model fails to train
        return -1.0,  # Invalid fitness score

# Define the GA components
creator.create("FitnessMax", base.Fitness, weights=(1.0,))
creator.create("Individual", list, fitness=creator.FitnessMax)

toolbox = base.Toolbox()
toolbox.register("attr_int", np.random.randint, 50, 200)  # Range for n_estimators
toolbox.register("attr_int2", np.random.randint, 1, 10)   # Range for max_depth
toolbox.register("attr_float", np.random.uniform, 0.01, 1.0)  # Range for learning_rate
toolbox.register("individual", tools.initCycle, creator.Individual,
                 (toolbox.attr_int, toolbox.attr_int2, toolbox.attr_float), n=1)
toolbox.register("population", tools.initRepeat, list, toolbox.individual)

toolbox.register("evaluate", fitness_function)
toolbox.register("mate", tools.cxBlend, alpha=0.5)
toolbox.register("mutate", tools.mutPolynomialBounded, low=[50, 1, 0.01], up=[200, 10, 1.0], eta=0.1, indpb=0.2)
toolbox.register("select", tools.selTournament, tournsize=3)

# Run the Genetic Algorithm
population = toolbox.population(n=20)  # Small population for simplicity
NGEN = 10
CXPB, MUTPB = 0.5, 0.2
f1_scores = []

for gen in range(NGEN):
    offspring = algorithms.varAnd(population, toolbox, CXPB, MUTPB)
    invalid_ind = [ind for ind in offspring if not ind.fitness.valid]
    fitnesses = map(toolbox.evaluate, invalid_ind)
    for ind, fit in zip(invalid_ind, fitnesses):
        ind.fitness.values = fit
    
    population = toolbox.select(offspring, k=len(population))
    
    # Record the best F1 score for this generation
    best_f1 = tools.selBest(population, k=1)[0].fitness.values[0]
    f1_scores.append(best_f1)

# Extract the best individual
best_individual = tools.selBest(population, k=1)[0]
best_params = [int(best_individual[0]), int(best_individual[1]), best_individual[2]]
print("Best hyperparameters found:", best_params)

# Train the final model with the best hyperparameters
xgb = XGBClassifier(
    n_estimators=best_params[0],
    max_depth=best_params[1],
    learning_rate=best_params[2],
    use_label_encoder=False,
    eval_metric='logloss',
    random_state=0
)
xgb.fit(X_train, y_train)

# Predict the target values for the test set
y_pred = xgb.predict(X_test)

# Compute the confusion matrix
cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot(cmap=plt.cm.Blues)
plt.title("Confusion Matrix")
plt.show()

# Generate and print the classification report
report = classification_report(y_test, y_pred)
print("Classification Report:")
print(report)

# Plot the evolution of the F1 score through generations
plt.plot(range(1, NGEN+1), f1_scores, marker='o')
plt.xlabel('Generation')
plt.ylabel('F1 Score')
plt.title('Evolution of F1 Score through Generations')
plt.show()





import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib.animation import FuncAnimation
from itertools import combinations
import seaborn as sns

# Sample data for demonstration
Y = np.random.rand(100) * 10  # Random float numbers between 0 and 10
Y.sort()
min_number_per_seg = 25
N = 4  # Number of segments

# Create a DataFrame with the sample data
df = pd.DataFrame({'value': Y})

def is_valid_segmentation(segments, min_count):
    # Count numbers in each segment
    segment_counts = [np.sum((Y >= segments[i]) & (Y < segments[i+1])) for i in range(len(segments) - 1)]
    segment_counts.append(np.sum(Y >= segments[-1]))  # For the last segment
    return all(count >= min_count for count in segment_counts)

# Create a list of valid segmentations and store in DataFrame
valid_segments = []
segmentation_results = pd.DataFrame({'value': Y})

for idx, split_points in enumerate(combinations(Y, N-1)):  # We need N-1 split points for N segments
    if is_valid_segmentation(split_points, min_number_per_seg):
        valid_segments.append(split_points)
        # Create a new column for each valid segmentation
        segmentation_results[f'segment_{idx}'] = np.digitize(Y, bins=split_points, right=False)

# If no valid segments, exit early
if not valid_segments:
    print("No valid segmentations found. Exiting.")
    exit()

# Set up the plot
fig, ax = plt.subplots()
sns.set(style="whitegrid")

# Initialize the plot elements
def init():
    ax.clear()
    ax.set_xlim(np.min(Y), np.max(Y))
    ax.set_ylim(0, 20)  # Adjust ylim based on data
    return []

# Animation function
def animate(i):
    ax.clear()
    segments = valid_segments[i]
    df['segment'] = np.digitize(df['value'], bins=segments, right=False)
    
    # Plot each segment as a histogram using Seaborn
    sns.histplot(df, x='value', hue='segment', element="step", palette='tab10', ax=ax)
    
    ax.set_title(f'Valid Segmentation {i+1}')
    return []

# Create the animation
ani = FuncAnimation(fig, animate, init_func=init, frames=len(valid_segments), interval=200, blit=False)

# Save the animation as a GIF file
ani.save('segmented_histogram_animation.gif', writer='pillow')

plt.show()

# Save the segmentation results DataFrame to a CSV file
segmentation_results.to_csv('segmentation_results.csv', index=False)





import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay
from xgboost import XGBClassifier
from deap import base, creator, tools, algorithms

# Load your dataset
np.random.seed(0)
data = pd.DataFrame(np.random.randn(1000, 10), columns=[f'feature_{i}' for i in range(10)])
data['target'] = np.random.randint(0, 2, 1000)  # Binary target variable

# Split the data into features and target
X = data.drop(columns='target')
y = data['target']

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# Define the fitness function
def fitness_function(individual):
    n_estimators, max_depth, learning_rate = individual
    n_estimators = int(n_estimators)
    max_depth = int(max_depth)
    learning_rate = float(learning_rate)
    
    model = XGBClassifier(
        n_estimators=n_estimators,
        max_depth=max_depth,
        learning_rate=learning_rate,
        use_label_encoder=False,
        eval_metric='logloss',
        random_state=0
    )
    
    # Evaluate the model using cross-validation
    scores = cross_val_score(model, X_train, y_train, cv=3, scoring='accuracy')
    return scores.mean(),

# Define the GA components
creator.create("FitnessMax", base.Fitness, weights=(1.0,))
creator.create("Individual", list, fitness=creator.FitnessMax)

toolbox = base.Toolbox()
toolbox.register("attr_int", np.random.randint, 50, 200)  # Range for n_estimators
toolbox.register("attr_int2", np.random.randint, 1, 10)   # Range for max_depth
toolbox.register("attr_float", np.random.uniform, 0.01, 0.3)  # Range for learning_rate
toolbox.register("individual", tools.initCycle, creator.Individual,
                 (toolbox.attr_int, toolbox.attr_int2, toolbox.attr_float), n=1)
toolbox.register("population", tools.initRepeat, list, toolbox.individual)

toolbox.register("evaluate", fitness_function)
toolbox.register("mate", tools.cxBlend, alpha=0.5)
toolbox.register("mutate", tools.mutPolynomialBounded, low=[50, 1, 0.01], up=[200, 10, 0.3], eta=0.1, indpb=0.2)
toolbox.register("select", tools.selTournament, tournsize=3)

# Run the Genetic Algorithm
population = toolbox.population(n=10)  # Smaller population for simplicity
NGEN = 5
CXPB, MUTPB = 0.5, 0.2

for gen in range(NGEN):
    offspring = algorithms.varAnd(population, toolbox, CXPB, MUTPB)
    invalid_ind = [ind for ind in offspring if not ind.fitness.valid]
    fitnesses = map(toolbox.evaluate, invalid_ind)
    for ind, fit in zip(invalid_ind, fitnesses):
        ind.fitness.values = fit
    
    population = toolbox.select(offspring, k=len(population))

# Extract the best individual
best_individual = tools.selBest(population, k=1)[0]
best_params = [int(best_individual[0]), int(best_individual[1]), best_individual[2]]
print("Best hyperparameters found:", best_params)

# Train the final model with the best hyperparameters
xgb = XGBClassifier(
    n_estimators=best_params[0],
    max_depth=best_params[1],
    learning_rate=best_params[2],
    use_label_encoder=False,
    eval_metric='logloss',
    random_state=0
)
xgb.fit(X_train, y_train)

# Predict the target values for the test set
y_pred = xgb.predict(X_test)

# Compute the confusion matrix
cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot(cmap=plt.cm.Blues)
plt.title("Confusion Matrix")
plt.show()

# Generate and print the classification report
report = classification_report(y_test, y_pred)
print("Classification Report:")
print(report)

# Plot feature importance
plt.figure(figsize=(10, 6))
plt.barh(range(len(xgb.feature_importances_)), xgb.feature_importances_)
plt.yticks(range(len(X.columns)), X.columns)
plt.xlabel("Feature Importance")
plt.ylabel("Feature")
plt.title("Feature Importance in XGBClassifier")
plt.show()




import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay, accuracy_score
from xgboost import XGBClassifier
from deap import base, creator, tools, algorithms

# Load your dataset
np.random.seed(0)
data = pd.DataFrame(np.random.randn(1000, 10), columns=[f'feature_{i}' for i in range(10)])
data['target'] = np.random.randint(0, 2, 1000)  # Binary target variable

# Split the data into features and target
X = data.drop(columns='target')
y = data['target']

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# Define the fitness function
def fitness_function(params):
    n_estimators, max_depth, learning_rate, subsample, colsample_bytree = params
    n_estimators = int(n_estimators)
    max_depth = int(max_depth)
    
    model = XGBClassifier(
        n_estimators=n_estimators,
        max_depth=max_depth,
        learning_rate=learning_rate,
        subsample=subsample,
        colsample_bytree=colsample_bytree,
        use_label_encoder=False,
        eval_metric='logloss',
        random_state=0
    )
    
    # Evaluate the model using cross-validation
    scores = cross_val_score(model, X_train, y_train, cv=3, scoring='accuracy')
    return scores.mean(),

# Define the GA components
creator.create("FitnessMax", base.Fitness, weights=(1.0,))
creator.create("Individual", list, fitness=creator.FitnessMax)

toolbox = base.Toolbox()
toolbox.register("attr_float", np.random.rand)
toolbox.register("individual", tools.initRepeat, creator.Individual, toolbox.attr_float, n=5)
toolbox.register("population", tools.initRepeat, list, toolbox.individual)

toolbox.register("evaluate", fitness_function)
toolbox.register("mate", tools.cxBlend, alpha=0.5)
toolbox.register("mutate", tools.mutPolynomialBounded, low=0, up=1, eta=0.1, indpb=0.2)
toolbox.register("select", tools.selTournament, tournsize=3)

# Run the Genetic Algorithm
population = toolbox.population(n=50)
NGEN = 20
CXPB, MUTPB = 0.5, 0.2

for gen in range(NGEN):
    offspring = algorithms.varAnd(population, toolbox, CXPB, MUTPB)
    invalid_ind = [ind for ind in offspring if not ind.fitness.valid]
    fitnesses = map(toolbox.evaluate, invalid_ind)
    for ind, fit in zip(invalid_ind, fitnesses):
        ind.fitness.values = fit
    
    population = toolbox.select(offspring, k=len(population))

# Extract the best individual
best_individual = tools.selBest(population, k=1)[0]
best_params = [int(best_individual[0]), int(best_individual[1]), best_individual[2], best_individual[3], best_individual[4]]
print("Best hyperparameters found:", best_params)

# Train the final model with the best hyperparameters
xgb = XGBClassifier(
    n_estimators=best_params[0],
    max_depth=best_params[1],
    learning_rate=best_params[2],
    subsample=best_params[3],
    colsample_bytree=best_params[4],
    use_label_encoder=False,
    eval_metric='logloss',
    random_state=0
)
xgb.fit(X_train, y_train)

# Predict the target values for the test set
y_pred = xgb.predict(X_test)

# Compute the confusion matrix
cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot(cmap=plt.cm.Blues)
plt.title("Confusion Matrix")
plt.show()

# Generate and print the classification report
report = classification_report(y_test, y_pred)
print("Classification Report:")
print(report)

# Plot feature importance
plt.figure(figsize=(10, 6))
plt.barh(range(len(xgb.feature_importances_)), xgb.feature_importances_)
plt.yticks(range(len(X.columns)), X.columns)
plt.xlabel("Feature Importance")
plt.ylabel("Feature")
plt.title("Feature Importance in XGBClassifier")
plt.show()






import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeRegressor
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split
from xgboost import XGBClassifier
from deap import base, creator, tools, algorithms
import random

# Generate a synthetic dataset for the example
np.random.seed(0)
data = pd.DataFrame(np.random.randn(100, 5), columns=[f'feature_{i}' for i in range(5)])
data['target'] = np.random.randn(100)

# Desired number of clusters and range for min_samples_split
num_clusters = 10

# Define the fitness function
def fitness_function(individual):
    min_samples_split = int(individual[0])
    
    # Initialize list to store weighted F1 scores for each feature
    weighted_f1_scores = []

    # Iterate over each feature to segment it using the target variable
    for feature_index in range(data.shape[1] - 1):  # Exclude the target column
        feature_name = data.columns[feature_index]
        X_feature = data[[feature_name]].values.reshape(-1, 1)
        y = data['target'].values.reshape(-1, 1)

        # Segment the feature using the target variable
        dt = DecisionTreeRegressor(min_samples_split=min_samples_split, max_leaf_nodes=num_clusters, random_state=0)
        dt.fit(y, X_feature)
        predicted_X = dt.predict(y)

        # Convert the continuous segment predictions into discrete labels
        label_encoder = LabelEncoder()
        segment_labels = label_encoder.fit_transform(predicted_X)

        # Split the data into training and testing sets
        X_train, X_test, y_train, y_test = train_test_split(
            data.drop(columns='target'), segment_labels, test_size=0.3, random_state=0
        )

        # Use all features (excluding the target variable) to predict these segments
        xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')
        xgb.fit(X_train, y_train)

        # Predict the segments on the test set
        predicted_segments = xgb.predict(X_test)

        # Generate a classification report
        report = classification_report(y_test, predicted_segments, output_dict=True)
        weighted_f1_scores.append(report['weighted avg']['f1-score'])

    # Return the average weighted F1 score as the fitness score (negated to minimize)
    return -np.mean(weighted_f1_scores),

# Define the GA settings
creator.create("FitnessMin", base.Fitness, weights=(-1.0,))
creator.create("Individual", list, fitness=creator.FitnessMin)
toolbox = base.Toolbox()
toolbox.register("attr_int", random.randint, 2, 20)
toolbox.register("individual", tools.initRepeat, creator.Individual, toolbox.attr_int, n=1)
toolbox.register("population", tools.initRepeat, list, toolbox.individual)

toolbox.register("evaluate", fitness_function)
toolbox.register("mate", tools.cxBlend, alpha=0.5)
toolbox.register("mutate", tools.mutPolynomialBounded, low=2, up=20, eta=0.1, indpb=0.2)
toolbox.register("select", tools.selTournament, tournsize=3)

# Run the Genetic Algorithm
population = toolbox.population(n=10)
NGEN = 20
CXPB, MUTPB = 0.5, 0.2

for gen in range(NGEN):
    offspring = algorithms.varAnd(population, toolbox, CXPB, MUTPB)
    invalid_ind = [ind for ind in offspring if not ind.fitness.valid]
    fitnesses = map(toolbox.evaluate, invalid_ind)
    for ind, fit in zip(invalid_ind, fitnesses):
        ind.fitness.values = fit
    population = toolbox.select(offspring, k=len(population))

# Extract and print the best solution
best_individual = tools.selBest(population, k=1)[0]
best_min_samples_split = int(best_individual[0])
print("Best min_samples_split is:", best_min_samples_split)





import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib.animation import FuncAnimation
from itertools import combinations
import seaborn as sns

# Sample data for demonstration
Y = np.random.rand(100) * 10  # Random float numbers between 0 and 10
Y.sort()
min_number_per_seg = 5
N = 4  # Number of segments

# Create a DataFrame with the sample data
df = pd.DataFrame({'value': Y})

def is_valid_segmentation(segments, min_count):
    # Count numbers in each segment
    segment_counts = [np.sum((Y >= segments[i]) & (Y < segments[i+1])) for i in range(len(segments) - 1)]
    segment_counts.append(np.sum(Y >= segments[-1]))  # For the last segment
    return all(count >= min_count for count in segment_counts)

# Create a list of valid segmentations
valid_segments = []
for split_points in combinations(Y, N-1):  # We need N-1 split points for N segments
    if is_valid_segmentation(split_points, min_number_per_seg):
        valid_segments.append(split_points)

# If no valid segments, exit early
if not valid_segments:
    print("No valid segmentations found. Exiting.")
    exit()

# Set up the plot
fig, ax = plt.subplots()
sns.set(style="whitegrid")

# Initialize the plot elements
def init():
    ax.clear()
    ax.set_xlim(np.min(Y), np.max(Y))
    ax.set_ylim(0, 20)  # Adjust ylim based on data
    return []

# Animation function
def animate(i):
    ax.clear()
    segments = valid_segments[i]
    df['segment'] = np.digitize(df['value'], bins=segments, right=False)
    
    # Plot each segment as a histogram using Seaborn
    sns.histplot(df, x='value', hue='segment', element="step", palette='tab10', ax=ax)
    
    ax.set_title(f'Valid Segmentation {i+1}')
    return []

# Create the animation
ani = FuncAnimation(fig, animate, init_func=init, frames=len(valid_segments), interval=200, blit=False)

# Save the animation as a GIF file
ani.save('segmented_histogram_animation.gif', writer='pillow')

plt.show()







import numpy as np
import matplotlib.pyplot as plt
from matplotlib.animation import FuncAnimation

# Sample data for demonstration
Y = np.random.rand(100) * 10  # Random float numbers between 0 and 10
Y.sort()
min_number_per_seg = 25


def is_valid_segmentation(S1, S2, min_count):
    # Count numbers in each segment
    count1 = np.sum(Y < S1)
    count2 = np.sum((Y >= S1) & (Y < S2))
    count3 = np.sum(Y >= S2)
    return (count1 >= min_count) and (count2 >= min_count) and (count3 >= min_count)

# Create a list of valid segmentations
valid_segments = []
for S1 in Y:
    for S2 in Y:
        if S1 < S2:
            if is_valid_segmentation(S1, S2, min_number_per_seg):
                valid_segments.append((S1, S2))

# Set up the plot
fig, ax = plt.subplots()
line1, = ax.plot([], [], 'r-', label='Segment 1')
line2, = ax.plot([], [], 'g-', label='Segment 2')
line3, = ax.plot([], [], 'b-', label='Segment 3')
ax.legend()

# Initialize the plot elements
def init():
    ax.set_xlim(np.min(Y), np.max(Y))
    ax.set_ylim(0, len(Y))
    line1.set_data([], [])
    line2.set_data([], [])
    line3.set_data([], [])
    return line1, line2, line3

# Animation function
def animate(i):
    S1, S2 = valid_segments[i]
    Y1 = Y[Y < S1]
    Y2 = Y[(Y >= S1) & (Y < S2)]
    Y3 = Y[Y >= S2]
    line1.set_data(Y1, np.zeros_like(Y1) + 1)
    line2.set_data(Y2, np.zeros_like(Y2) + 2)
    line3.set_data(Y3, np.zeros_like(Y3) + 3)
    return line1, line2, line3

# Create the animation
ani = FuncAnimation(fig, animate, init_func=init, frames=len(valid_segments), interval=200, blit=True)

plt.show()



# Using conda
conda install -c conda-forge imagemagick

# Using pip (might require ImageMagick to be installed on your system)
pip install imagemagick

pip install pillow


import numpy as np
import matplotlib.pyplot as plt
from matplotlib.animation import FuncAnimation

# This line is for static plots in Jupyter Notebooks
%matplotlib inline

# Set up the figure, the axis, and the plot element we want to animate
fig, ax = plt.subplots()
x = np.linspace(0, 2 * np.pi, 200)
line, = ax.plot(x, np.sin(x))

# Initialization function: plot the background of each frame
def init():
    line.set_ydata([np.nan] * len(x))
    return line,

# Animation function: this is called sequentially
def animate(i):
    line.set_ydata(np.sin(x + i / 10))  # Update the data
    return line,

# Call the animator
ani = FuncAnimation(fig, animate, init_func=init, frames=100, interval=20, blit=True)

# Save the animation as a GIF file
ani.save('sine_wave_animation.gif', writer='pillow')

plt.show()





import numpy as np
import matplotlib.pyplot as plt
from matplotlib.animation import FuncAnimation

# This line is for static plots in Jupyter Notebooks
%matplotlib inline

# Set up the figure, the axis, and the plot element we want to animate
fig, ax = plt.subplots()
x = np.linspace(0, 2 * np.pi, 200)
line, = ax.plot(x, np.sin(x))

# Initialization function: plot the background of each frame
def init():
    line.set_ydata([np.nan] * len(x))
    return line,

# Animation function: this is called sequentially
def animate(i):
    line.set_ydata(np.sin(x + i / 10))  # Update the data
    return line,

# Call the animator
ani = FuncAnimation(fig, animate, init_func=init, frames=100, interval=20, blit=True)

# Save the animation as an MP4 file or GIF (optional)
ani.save('sine_wave_animation.mp4', writer='ffmpeg')

plt.show()




import numpy as np
import matplotlib.pyplot as plt
from matplotlib.animation import FuncAnimation

# This line is important for Jupyter Notebooks
%matplotlib notebook

# Set up the figure, the axis, and the plot element we want to animate
fig, ax = plt.subplots()
x = np.linspace(0, 2 * np.pi, 200)
line, = ax.plot(x, np.sin(x))

# Initialization function: plot the background of each frame
def init():
    line.set_ydata([np.nan] * len(x))
    return line,

# Animation function: this is called sequentially
def animate(i):
    line.set_ydata(np.sin(x + i / 10))  # Update the data
    return line,

# Call the animator
ani = FuncAnimation(fig, animate, init_func=init, frames=100, interval=20, blit=True)

# Display the animation
plt.show()




import numpy as np
import matplotlib.pyplot as plt
from matplotlib.animation import FuncAnimation

# Set up the figure, the axis, and the plot element we want to animate
fig, ax = plt.subplots()
x = np.linspace(0, 2 * np.pi, 200)
line, = ax.plot(x, np.sin(x))

# Initialization function: plot the background of each frame
def init():
    line.set_ydata([np.nan] * len(x))
    return line,

# Animation function: this is called sequentially
def animate(i):
    line.set_ydata(np.sin(x + i / 10))  # Update the data
    return line,

# Call the animator
ani = FuncAnimation(fig, animate, init_func=init, frames=100, interval=20, blit=True)

# Display the animation
plt.show()







Objet : Demande d'approbation pour l'email à Sabrina

Bonjour Solène,

J'espère que vous allez bien.

Je souhaite reporter la discussion RH avec Sabrina et j'ai préparé deux options d'email. Pourriez-vous s'il vous plaît examiner ces messages et me dire lequel vous semble le plus approprié ?

Option 1 :

Objet : Report de la discussion RH

Bonjour Sabrina,

J'espère que vous allez bien.

Pourrions-nous reporter la discussion RH à lundi prochain ?

Merci beaucoup !

Cordialement,

Mohamed

Option 2 :

Bonjour Sabrina,

J'espère que vous allez bien.

Je vous serais très reconnaissant si nous pouvions reporter la discussion RH à la semaine prochaine, à un moment qui vous conviendrait. Merci beaucoup pour votre compréhension et votre flexibilité.

Merci encore pour votre aide.

Cordialement,

Mohamed






# Create a continuous float variable y in the DataFrame
df_float = pd.DataFrame({'y': np.linspace(1.0, 100.0, 100)})

# Adjusting the function to handle float values in y
def create_segmentation_float(y, boundaries):
    y_seg = np.zeros_like(y, dtype=int)
    for i, boundary in enumerate(boundaries):
        y_seg[(y > boundaries[i-1]) & (y <= boundary)] = i if i > 0 else 0
    y_seg[y > boundaries[-1]] = len(boundaries)
    return y_seg

def general_segmentations_float(df, var_name, num_segs, min_number):
    y = df[var_name].values
    max_y = y[-1]
    initial_segments = list(np.linspace(min(y), max_y, num_segs, endpoint=False)[1:])
    
    segmentations = pd.DataFrame({var_name: y})
    
    def plot_segmentation(y, segmentation, boundaries, step):
        plt.figure(figsize=(10, 6))
        plt.scatter(y, segmentation, c=segmentation, cmap='viridis', alpha=0.7, edgecolors='w')
        plt.title(f'Segmentation at Step {step}: Boundaries {boundaries}')
        plt.xlabel(var_name)
        plt.ylabel('Segment')
        plt.grid(True)
        plt.show()
    
    step = 1
    
    for idx in reversed(range(num_segs - 1)):
        for i in np.linspace(initial_segments[idx], max_y, 50):  # finer steps for float
            boundaries = initial_segments[:]
            boundaries[idx] = i
            segmentation = create_segmentation_float(y, boundaries)
            if all(np.sum(segmentation == j) >= min_number for j in range(len(boundaries) + 1)):
                column_name = f'{var_name}_seg_{"_".join(map(lambda x: f"{x:.2f}", boundaries))}'
                segmentations[column_name] = segmentation
                plot_segmentation(y, segmentation, boundaries, step)
                step += 1
    
    return segmentations

# Generate general segmentations for float values
general_segmentations_float_result = general_segmentations_float(df_float, 'y', num_segs, min_number)
tools.display_dataframe_to_user(name="General Segmentations with Float Values", dataframe=general_segmentations_float_result)





def general_segmentations(df, var_name, num_segs, min_number):
    y = df[var_name].values
    max_y = y[-1]
    initial_segments = list(np.linspace(min(y), max_y, num_segs, endpoint=False, dtype=int)[1:])
    
    segmentations = pd.DataFrame({var_name: y})
    
    def plot_segmentation(y, segmentation, boundaries, step):
        plt.figure(figsize=(10, 6))
        plt.scatter(y, segmentation, c=segmentation, cmap='viridis', alpha=0.7, edgecolors='w')
        plt.title(f'Segmentation at Step {step}: Boundaries {boundaries}')
        plt.xlabel(var_name)
        plt.ylabel('Segment')
        plt.grid(True)
        plt.show()
    
    step = 1
    
    for idx in reversed(range(num_segs - 1)):
        for i in range(initial_segments[idx] + 1, max_y + 1):
            boundaries = initial_segments[:]
            boundaries[idx] = i
            segmentation = create_segmentation(y, boundaries)
            if all(np.sum(segmentation == j) >= min_number for j in range(len(boundaries) + 1)):
                column_name = f'{var_name}_seg_{"_".join(map(str, boundaries))}'
                segmentations[column_name] = segmentation
                plot_segmentation(y, segmentation, boundaries, step)
                step += 1
    
    return segmentations

# Example usage with a dataframe and 10 segments
df = pd.DataFrame({'y': np.arange(1, 101)})
num_segs = 10
min_number = 5

# Generate general segmentations
general_segmentations_result = general_segmentations(df, 'y', num_segs, min_number)
tools.display_dataframe_to_user(name="General Segmentations with 10 Segments", dataframe=general_segmentations_result)
i



mport matplotlib.pyplot as plt

def create_segmentations_with_corrected_steps(y, initial_segments, min_number):
    segmentations = pd.DataFrame({'y': y})
    max_y = y[-1]
    initial_s1, initial_s2, initial_s3 = initial_segments
    
    # Function to plot segmentations
    def plot_segmentation(y, segmentation, boundaries, step):
        plt.figure(figsize=(10, 6))
        plt.scatter(y, segmentation, c=segmentation, cmap='viridis', alpha=0.7, edgecolors='w')
        plt.title(f'Segmentation at Step {step}: Boundaries {boundaries}')
        plt.xlabel('y')
        plt.ylabel('Segment')
        plt.grid(True)
        plt.show()
    
    step = 1
    
    # Step 1: Fix S1, S2, S3; change S4
    for s4 in range(initial_s3 + 1, max_y + 1):
        boundaries = [initial_s1, initial_s2, initial_s3, s4]
        segmentation = create_segmentation(y, boundaries)
        if all(np.sum(segmentation == j) >= min_number for j in range(len(boundaries) + 1)):
            column_name = f'y_seg_{"_".join(map(str, boundaries))}'
            segmentations[column_name] = segmentation
            plot_segmentation(y, segmentation, boundaries, step)
            step += 1
    
    # Step 2: Fix S1, S2; change S3, then S4
    for s3 in range(initial_s2 + 1, max_y):
        for s4 in range(s3 + 1, max_y + 1):
            boundaries = [initial_s1, initial_s2, s3, s4]
            segmentation = create_segmentation(y, boundaries)
            if all(np.sum(segmentation == j) >= min_number for j in range(len(boundaries) + 1)):
                column_name = f'y_seg_{"_".join(map(str, boundaries))}'
                segmentations[column_name] = segmentation
                plot_segmentation(y, segmentation, boundaries, step)
                step += 1
    
    # Step 3: Fix S1; change S2, then S3, then S4
    for s2 in range(initial_s1 + 1, max_y):
        for s3 in range(s2 + 1, max_y):
            for s4 in range(s3 + 1, max_y + 1):
                boundaries = [initial_s1, s2, s3, s4]
                segmentation = create_segmentation(y, boundaries)
                if all(np.sum(segmentation == j) >= min_number for j in range(len(boundaries) + 1)):
                    column_name = f'y_seg_{"_".join(map(str, boundaries))}'
                    segmentations[column_name] = segmentation
                    plot_segmentation(y, segmentation, boundaries, step)
                    step += 1
    
    return segmentations

# Generate segmentations with corrected steps and plotting
corrected_segmentations_with_plots = create_segmentations_with_corrected_steps(y, initial_segments, min_number)
tools.display_dataframe_to_user(name="Corrected Segmentations with Plots", dataframe=corrected_segmentations_with_plots)






# Redefine the function to include the steps as specified
def create_segmentations_with_steps(y, initial_segments, min_number):
    segmentations = pd.DataFrame({'y': y})
    max_y = y[-1]
    initial_s1, initial_s2, initial_s3 = initial_segments
    
    # Step 1: Fix S1, S2, S3; change S4
    for s4 in range(initial_s3 + 1, max_y + 1):
        boundaries = [initial_s1, initial_s2, initial_s3, s4]
        segmentation = create_segmentation(y, boundaries)
        if all(np.sum(segmentation == j) >= min_number for j in range(len(boundaries) + 1)):
            column_name = f'y_seg_{"_".join(map(str, boundaries))}'
            segmentations[column_name] = segmentation
    
    # Step 2: Fix S1, S2; change S3, then S4
    for s3 in range(initial_s2 + 1, max_y):
        for s4 in range(s3 + 1, max_y + 1):
            boundaries = [initial_s1, initial_s2, s3, s4]
            segmentation = create_segmentation(y, boundaries)
            if all(np.sum(segmentation == j) >= min_number for j in range(len(boundaries) + 1)):
                column_name = f'y_seg_{"_".join(map(str, boundaries))}'
                segmentations[column_name] = segmentation
    
    # Step 3: Fix S1; change S2, then S3, then S4
    for s2 in range(initial_s1 + 1, max_y):
        for s3 in range(s2 + 1, max_y):
            for s4 in range(s3 + 1, max_y + 1):
                boundaries = [initial_s1, s2, s3, s4]
                segmentation = create_segmentation(y, boundaries)
                if all(np.sum(segmentation == j) >= min_number for j in range(len(boundaries) + 1)):
                    column_name = f'y_seg_{"_".join(map(str, boundaries))}'
                    segmentations[column_name] = segmentation
    
    return segmentations

# Generate segmentations with the corrected steps
corrected_segmentations = create_segmentations_with_steps(y, initial_segments, min_number)
tools.display_dataframe_to_user(name="Corrected Segmentations", dataframe=corrected_segmentations)





import matplotlib.pyplot as plt

# Define a function to plot segmentations
def plot_segmentations(segmentations, y, step_boundaries):
    for column in segmentations.columns[1:]:  # Skip the 'y' column
        boundaries = list(map(int, column.split('_')[2:]))
        fig, ax = plt.subplots()
        for i, boundary in enumerate(boundaries):
            ax.axvline(boundary, color='r', linestyle='--', label=f'Boundary {i+1}: {boundary}')
        ax.scatter(y, segmentations[column], c=segmentations[column], cmap='viridis', label='Segmentation')
        ax.set_title(f'Segmentation: {column}')
        ax.set_xlabel('y')
        ax.set_ylabel('Segment')
        ax.legend(loc='best')
        plt.show()

# Plot the segmentations
plot_segmentations(segmentations, y, initial_segments)




import numpy as np
import pandas as pd

# Define the initial continuous variable y
y = np.arange(1, 101)  # y = [1, 2, 3, ..., 100]

# Define initial segment boundaries and minimum number of observations
initial_segments = [25, 50, 75]
min_number = 5

# Create an empty DataFrame to store the segmentations
segmentations = pd.DataFrame({'y': y})

# Function to create a segmentation based on given boundaries
def create_segmentation(y, boundaries):
    y_seg = np.zeros_like(y)
    for i, boundary in enumerate(boundaries):
        y_seg[(y > boundaries[i-1]) & (y <= boundary)] = i if i > 0 else 0
    y_seg[y > boundaries[-1]] = len(boundaries)
    return y_seg

# Iterate over each boundary, starting with the last one and moving backwards
for i in range(len(initial_segments) - 1, -1, -1):
    boundary_name = f'S{i+1}'
    max_value = y[-1] if i == len(initial_segments) - 1 else initial_segments[i+1]
    min_value = 1 if i == 0 else initial_segments[i-1] + 1
    
    for new_boundary in range(initial_segments[i], max_value + 1):
        new_boundaries = initial_segments.copy()
        new_boundaries[i] = new_boundary
        segmentation = create_segmentation(y, new_boundaries)
        
        # Check if the segmentation is valid
        valid = all(np.sum(segmentation == j) >= min_number for j in range(len(new_boundaries) + 1))
        if valid:
            column_name = f'y_seg_{"_".join(map(str, new_boundaries))}'
            segmentations[column_name] = segmentation

# Display the generated segmentations
import ace_tools as tools; tools.display_dataframe_to_user(name="Generated Segmentations", dataframe=segmentations)





import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeRegressor
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split
from xgboost import XGBClassifier

# Generate a synthetic dataset for the example
np.random.seed(0)
data = pd.DataFrame(np.random.randn(100, 5), columns=[f'feature_{i}' for i in range(5)])
data['target'] = np.random.randn(100)

# Desired number of clusters and range for min_samples_split
num_clusters = 10
min_samples_split_values = range(2, 21)  # Testing values from 2 to 20

# Initialize variables to store metrics
metrics = []

# Iterate over different values of min_samples_split
for min_samples in min_samples_split_values:
    # Store F1 scores for each min_samples_split value
    current_metrics = {'min_samples_split': min_samples, 'weighted_f1': [], 'cluster_f1': {}}

    # Iterate over each feature to segment it using the target variable
    for feature_index in range(data.shape[1] - 1):  # Exclude the target column
        feature_name = data.columns[feature_index]
        X_feature = data[[feature_name]].values.reshape(-1, 1)
        y = data['target'].values.reshape(-1, 1)
        
        # Segment the feature using the target variable
        dt = DecisionTreeRegressor(min_samples_split=min_samples, max_leaf_nodes=num_clusters, random_state=0)
        dt.fit(y, X_feature)
        predicted_X = dt.predict(y)
        
        # Convert the continuous segment predictions into discrete labels
        label_encoder = LabelEncoder()
        segment_labels = label_encoder.fit_transform(predicted_X)
        
        # Split the data into training and testing sets
        X_train, X_test, y_train, y_test = train_test_split(
            data.drop(columns='target'), segment_labels, test_size=0.3, random_state=0
        )
        
        # Use all features (excluding the target variable) to predict these segments
        xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')
        xgb.fit(X_train, y_train)
        
        # Predict the segments on the test set
        predicted_segments = xgb.predict(X_test)
        
        # Generate a classification report
        report = classification_report(y_test, predicted_segments, output_dict=True)
        
        # Store the weighted average F1 score and individual cluster F1 scores
        current_metrics['weighted_f1'].append(report['weighted avg']['f1-score'])
        for label, metrics in report.items():
            if isinstance(metrics, dict):  # Only store scores for each cluster
                if label not in current_metrics['cluster_f1']:
                    current_metrics['cluster_f1'][label] = []
                current_metrics['cluster_f1'][label].append(metrics['f1-score'])
    
    # Store metrics for the current min_samples_split value
    metrics.append(current_metrics)

# Process and plot the results
min_samples_split_vals = [m['min_samples_split'] for m in metrics]
weighted_f1_scores = [np.mean(m['weighted_f1']) for m in metrics]

plt.figure(figsize=(12, 6))
plt.plot(min_samples_split_vals, weighted_f1_scores, marker='o', label='Weighted F1 Score')
plt.xlabel('min_samples_split')
plt.ylabel('F1 Score')
plt.title('Weighted F1 Score Evolution')
plt.legend()
plt.grid(True)
plt.show()

# Plot the F1 scores for each cluster across different min_samples_split values
plt.figure(figsize=(12, 6))
for cluster_label in metrics[0]['cluster_f1'].keys():
    cluster_scores = [m['cluster_f1'][cluster_label] for m in metrics]
    mean_cluster_scores = [np.mean(scores) for scores in cluster_scores]
    plt.plot(min_samples_split_vals, mean_cluster_scores, marker='o', label=f'Cluster {cluster_label}')

plt.xlabel('min_samples_split')
plt.ylabel('F1 Score')
plt.title('Cluster F1 Scores Evolution')
plt.legend()
plt.grid(True)
plt.show()







import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeRegressor
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split
from xgboost import XGBClassifier

# Generate a synthetic dataset for the example
np.random.seed(0)
data = pd.DataFrame(np.random.randn(100, 5), columns=[f'feature_{i}' for i in range(5)])
data['target'] = np.random.randn(100)

# Desired number of clusters and range for min_samples_split
num_clusters = 10
min_samples_split_values = range(2, 21)  # Testing values from 2 to 20

# Initialize variables to store metrics
metrics = []

# Iterate over different values of min_samples_split
for min_samples in min_samples_split_values:
    # Store F1 scores for each min_samples_split value
    current_metrics = {'min_samples_split': min_samples, 'weighted_f1': [], 'cluster_f1': []}

    # Iterate over each feature to segment it using the target variable
    for feature_index in range(data.shape[1] - 1):  # Exclude the target column
        feature_name = data.columns[feature_index]
        X_feature = data[[feature_name]].values.reshape(-1, 1)
        y = data['target'].values.reshape(-1, 1)
        
        # Segment the feature using the target variable
        dt = DecisionTreeRegressor(min_samples_split=min_samples, max_leaf_nodes=num_clusters, random_state=0)
        dt.fit(y, X_feature)
        predicted_X = dt.predict(y)
        
        # Convert the continuous segment predictions into discrete labels
        label_encoder = LabelEncoder()
        segment_labels = label_encoder.fit_transform(predicted_X)
        
        # Split the data into training and testing sets
        X_train, X_test, y_train, y_test = train_test_split(
            data.drop(columns='target'), segment_labels, test_size=0.3, random_state=0
        )
        
        # Use all features (excluding the target variable) to predict these segments
        xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')
        xgb.fit(X_train, y_train)
        
        # Predict the segments on the test set
        predicted_segments = xgb.predict(X_test)
        
        # Generate a classification report
        report = classification_report(y_test, predicted_segments, output_dict=True)
        
        # Store the weighted average F1 score and individual cluster F1 scores
        current_metrics['weighted_f1'].append(report['weighted avg']['f1-score'])
        for label, metrics in report.items():
            if isinstance(metrics, dict):  # Only store scores for each cluster
                current_metrics['cluster_f1'].append((label, metrics['f1-score']))
    
    # Store metrics for the current min_samples_split value
    metrics.append(current_metrics)

# Process and plot the results
min_samples_split_vals = [m['min_samples_split'] for m in metrics]
weighted_f1_scores = [np.mean(m['weighted_f1']) for m in metrics]

plt.figure(figsize=(12, 6))
plt.plot(min_samples_split_vals, weighted_f1_scores, marker='o', label='Weighted F1 Score')
plt.xlabel('min_samples_split')
plt.ylabel('F1 Score')
plt.title('Weighted F1 Score Evolution')
plt.legend()
plt.grid(True)
plt.show()

# Plot the F1 scores for each cluster across different min_samples_split values
plt.figure(figsize=(12, 6))
for i, cluster_f1 in enumerate(metrics[0]['cluster_f1']):
    cluster_label = cluster_f1[0]
    cluster_scores = [m['cluster_f1'][i][1] for m in metrics]
    plt.plot(min_samples_split_vals, cluster_scores, marker='o', label=f'Cluster {cluster_label}')

plt.xlabel('min_samples_split')
plt.ylabel('F1 Score')
plt.title('Cluster F1 Scores Evolution')
plt.legend()
plt.grid(True)
plt.show()






import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeRegressor
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split
from xgboost import XGBClassifier

# Generate a synthetic dataset for the example
np.random.seed(0)
data = pd.DataFrame(np.random.randn(100, 5), columns=[f'feature_{i}' for i in range(5)])
data['target'] = np.random.randn(100)

# Desired number of clusters
num_clusters = 10

# Initialize variables to store the best feature and corresponding results
best_f1 = 0
best_feature_index = -1
best_segment_labels = None
best_report = None

# Iterate over each feature to segment it using the target variable
for feature_index in range(data.shape[1] - 1):  # Exclude the target column
    feature_name = data.columns[feature_index]
    X_feature = data[[feature_name]].values.reshape(-1, 1)
    y = data['target'].values.reshape(-1, 1)
    
    # Segment the feature using the target variable
    dt = DecisionTreeRegressor(min_samples_split=5, max_leaf_nodes=num_clusters, random_state=0)
    dt.fit(y, X_feature)
    predicted_X = dt.predict(y)
    
    # Convert the continuous segment predictions into discrete labels
    label_encoder = LabelEncoder()
    segment_labels = label_encoder.fit_transform(predicted_X)
    
    # Split the data into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(
        data.drop(columns='target'), segment_labels, test_size=0.3, random_state=0
    )
    
    # Use all features (excluding the target variable) to predict these segments
    xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')
    xgb.fit(X_train, y_train)
    
    # Predict the segments on the test set
    predicted_segments = xgb.predict(X_test)
    
    # Generate a classification report
    report = classification_report(y_test, predicted_segments, output_dict=True)
    
    # Get the weighted average F1 score
    weighted_f1 = report['weighted avg']['f1-score']
    
    # Check if this is the best F1 score
    if weighted_f1 > best_f1:
        best_f1 = weighted_f1
        best_feature_index = feature_index
        best_segment_labels = label_encoder.fit_transform(dt.predict(data['target'].values.reshape(-1, 1)))
        best_report = report
    
    # Clean up
    del data['temp_segments']

# Add the best segments to the DataFrame as a new column
best_feature_name = data.columns[best_feature_index]
data['best_segments'] = best_segment_labels

# Output the best feature index and F1 score
print(f"Best Feature Index: {best_feature_index} ({best_feature_name}), Best Weighted F1 Score: {best_f1}")

# Output the detailed classification report for the best feature
print("\nDetailed Classification Report:")
for label, metrics in best_report.items():
    if isinstance(metrics, dict):  # Only print details for each class, not overall metrics
        print(f"Cluster {label}:")
        for metric_name, value in metrics.items():
            print(f"  {metric_name}: {value}")

# Plot the feature colored by the best segmentation
plt.figure(figsize=(10, 6))
plt.scatter(range(len(data)), data[best_feature_name], c=data['best_segments'], cmap='viridis', marker='o')
plt.title(f'Feature {best_feature_name} Segmentation with Highest F1 Score')
plt.xlabel('Sample Index')
plt.ylabel(f'{best_feature_name} Value')
plt.colorbar(label='Segment Label')
plt.grid(True)
plt.show()





import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeRegressor
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split
from xgboost import XGBClassifier

# Generate a synthetic dataset for the example
np.random.seed(0)
data = pd.DataFrame(np.random.randn(100, 5), columns=[f'feature_{i}' for i in range(5)])
data['target'] = np.random.randn(100)

# Desired number of clusters
num_clusters = 10

# Initialize variables to store the best feature and corresponding results
best_f1 = 0
best_feature_index = -1
best_segment_labels = None
best_report = None

# Iterate over each feature to segment it using the target variable
for feature_index in range(data.shape[1] - 1):  # Exclude the target column
    feature_name = data.columns[feature_index]
    X_feature = data[[feature_name]].values.reshape(-1, 1)
    y = data['target'].values.reshape(-1, 1)
    
    # Segment the feature using the target variable
    dt = DecisionTreeRegressor(min_samples_split=5, max_leaf_nodes=num_clusters, random_state=0)
    dt.fit(y, X_feature)
    predicted_X = dt.predict(y)
    
    # Convert the continuous segment predictions into discrete labels
    label_encoder = LabelEncoder()
    segment_labels = label_encoder.fit_transform(predicted_X)
    
    # Split the data into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(
        data.drop(columns='target'), segment_labels, test_size=0.3, random_state=0
    )
    
    # Use all features (excluding the target variable) to predict these segments
    xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')
    xgb.fit(X_train, y_train)
    
    # Predict the segments on the test set
    predicted_segments = xgb.predict(X_test)
    
    # Generate a classification report
    report = classification_report(y_test, predicted_segments, output_dict=True)
    
    # Get the weighted average F1 score
    weighted_f1 = report['weighted avg']['f1-score']
    
    # Check if this is the best F1 score
    if weighted_f1 > best_f1:
        best_f1 = weighted_f1
        best_feature_index = feature_index
        best_segment_labels = label_encoder.fit_transform(dt.predict(data['target'].values.reshape(-1, 1)))
        best_report = report
    
    # Clean up
    del data['temp_segments']

# Add the best segments to the DataFrame as a new column
best_feature_name = data.columns[best_feature_index]
data['best_segments'] = best_segment_labels

# Output the best feature index and F1 score
print(f"Best Feature Index: {best_feature_index} ({best_feature_name}), Best Weighted F1 Score: {best_f1}")

# Output the detailed classification report for the best feature
print("\nDetailed Classification Report:")
for label, metrics in best_report.items():
    if isinstance(metrics, dict):  # Only print details for each class, not overall metrics
        print(f"Cluster {label}:")
        for metric_name, value in metrics.items():
            print(f"  {metric_name}: {value}")

# Plot the feature colored by the best segmentation
plt.figure(figsize=(10, 6))
plt.scatter(range(len(data)), data[best_feature_name], c=data['best_segments'], cmap='viridis', marker='o')
plt.title(f'Feature {best_feature_name} Segmentation with Highest F1 Score')
plt.xlabel('Sample Index')
plt.ylabel(f'{best_feature_name} Value')
plt.colorbar(label='Segment Label')
plt.grid(True)
plt.show()





import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeRegressor
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import f1_score
from sklearn.model_selection import train_test_split
from xgboost import XGBClassifier

# Generate a synthetic dataset for the example
np.random.seed(0)
data = pd.DataFrame(np.random.randn(100, 5), columns=[f'feature_{i}' for i in range(5)])
data['target'] = np.random.randn(100)

# Desired number of clusters
num_clusters = 10

# Initialize variables to store the best feature and F1 score
best_f1 = 0
best_feature_index = -1
best_segment_labels = None

# Iterate over each feature to segment it using the target variable
for feature_index in range(data.shape[1] - 1):  # Exclude the target column
    feature_name = data.columns[feature_index]
    X_feature = data[[feature_name]].values.reshape(-1, 1)
    y = data['target'].values.reshape(-1, 1)
    
    # Segment the feature using the target variable
    dt = DecisionTreeRegressor(min_samples_split=5, max_leaf_nodes=num_clusters, random_state=0)
    dt.fit(y, X_feature)
    predicted_X = dt.predict(y)
    
    # Convert the continuous segment predictions into discrete labels
    label_encoder = LabelEncoder()
    segment_labels = label_encoder.fit_transform(predicted_X)
    
    # Split the data into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(
        data.drop(columns='target'), segment_labels, test_size=0.3, random_state=0
    )
    
    # Use all features (excluding the target variable) to predict these segments
    xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')
    xgb.fit(X_train, y_train)
    
    # Predict the segments and calculate the F1 score on the test set
    predicted_segments = xgb.predict(X_test)
    f1 = f1_score(y_test, predicted_segments, average='weighted')
    
    # Check if this is the best F1 score
    if f1 > best_f1:
        best_f1 = f1
        best_feature_index = feature_index
        best_segment_labels = label_encoder.fit_transform(dt.predict(data['target'].values.reshape(-1, 1)))
    
    # Clean up
    del data['temp_segments']

# Add the best segments to the DataFrame as a new column
best_feature_name = data.columns[best_feature_index]
data['best_segments'] = best_segment_labels

# Output the best feature index and F1 score
print(f"Best Feature Index: {best_feature_index} ({best_feature_name}), Best F1 Score: {best_f1}")

# Plot the feature colored by the best segmentation
plt.figure(figsize=(10, 6))
plt.scatter(range(len(data)), data[best_feature_name], c=data['best_segments'], cmap='viridis', marker='o')
plt.title(f'Feature {best_feature_name} Segmentation with Highest F1 Score')
plt.xlabel('Sample Index')
plt.ylabel(f'{best_feature_name} Value')
plt.colorbar(label='Segment Label')
plt.grid(True)
plt.show()




import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import f1_score, classification_report, ConfusionMatrixDisplay
from sklearn.model_selection import train_test_split
from xgboost import XGBClassifier

# Generate a synthetic dataset for the example
np.random.seed(0)
X = np.random.randn(100, 5)  # 100 samples, 5 features
y = np.random.randn(100)     # Target variable

# Store the best F1 score and corresponding feature index
best_f1 = 0
best_feature_index = -1
best_segments = None

# Iterate over each feature to segment the target variable
for feature_index in range(X.shape[1]):
    # Segment the target variable using the current feature
    dt = DecisionTreeRegressor(min_samples_split=5, random_state=0)
    dt.fit(X[:, feature_index].reshape(-1, 1), y)
    segments = dt.predict(X[:, feature_index].reshape(-1, 1))

    # Split the data into training and testing sets
    X_train, X_test, segments_train, segments_test = train_test_split(X, segments, test_size=0.2, random_state=0)

    # Use these segments as labels and predict using all features with XGBoost
    xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')
    xgb.fit(X_train, segments_train)

    # Predict the segments on the test set and calculate the F1 score
    predicted_segments = xgb.predict(X_test)
    f1 = f1_score(segments_test, predicted_segments, average='weighted')

    # Check if this is the best F1 score
    if f1 > best_f1:
        best_f1 = f1
        best_feature_index = feature_index
        best_segments = segments

# Output the best feature index and F1 score
print(f"Best Feature Index: {best_feature_index}, Best F1 Score: {best_f1}")

# Plot the target variable colored by the best segmentation
plt.figure(figsize=(10, 6))
plt.scatter(range(len(y)), y, c=best_segments, cmap='viridis', marker='o', label='Target variable')
plt.title(f'Target Variable Segmentation by Feature {best_feature_index}')
plt.xlabel('Sample Index')
plt.ylabel('Target Variable Value')
plt.colorbar(label='Segment Label')
plt.grid(True)
plt.legend()
plt.show()

# Classification report and confusion matrix for the best feature
xgb.fit(X, best_segments)
predicted_segments = xgb.predict(X)
report = classification_report(best_segments, predicted_segments)
print("Classification Report:")
print(report)

cm = confusion_matrix(best_segments, predicted_segments)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot(cmap=plt.cm.Blues)
plt.title("Confusion Matrix")
plt.show()





import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import cross_val_predict, StratifiedKFold
from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay
from xgboost import XGBClassifier

# Load your dataset
# For demonstration, we'll generate a synthetic dataset with multiple features and a binary target
np.random.seed(0)
data = pd.DataFrame(np.random.randn(1000, 10), columns=[f'feature_{i}' for i in range(10)])
data['target'] = np.random.randint(0, 2, 1000)  # Binary target variable

# Split the data into features and target
X = data.drop(columns='target')
y = data['target']

# Initialize the XGBClassifier
xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss')

# Set up cross-validation
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)

# Perform cross-validation and get predictions
y_pred = cross_val_predict(xgb, X, y, cv=cv)

# Compute the confusion matrix
cm = confusion_matrix(y, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot(cmap=plt.cm.Blues)
plt.title("Confusion Matrix")
plt.show()

# Generate and print the classification report
report = classification_report(y, y_pred)
print("Classification Report:")
print(report)

# Plot feature importance
xgb.fit(X, y)
plt.figure(figsize=(10, 6))
plt.barh(range(len(xgb.feature_importances_)), xgb.feature_importances_)
plt.yticks(range(len(X.columns)), X.columns)
plt.xlabel("Feature Importance")
plt.ylabel("Feature")
plt.title("Feature Importance in XGBClassifier")
plt.show()





import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import cross_val_score, StratifiedKFold
from sklearn.metrics import classification_report, ConfusionMatrixDisplay, confusion_matrix
from xgboost import XGBClassifier

# Load your dataset
# For demonstration, we'll generate a synthetic dataset with multiple features and a binary target
np.random.seed(0)
data = pd.DataFrame(np.random.randn(1000, 10), columns=[f'feature_{i}' for i in range(10)])
data['target'] = np.random.randint(0, 2, 1000)  # Binary target variable

# Split the data into features and target
X = data.drop(columns='target')
y = data['target']

# Initialize the XGBClassifier
xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss')

# Set up cross-validation
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)

# Perform cross-validation
cv_scores = cross_val_score(xgb, X, y, cv=cv, scoring='accuracy')
print(f"Cross-Validation Accuracy Scores: {cv_scores}")
print(f"Mean CV Accuracy: {cv_scores.mean()}")

# Train the model on the entire dataset and evaluate
xgb.fit(X, y)
y_pred = cross_val_score(xgb, X, y, cv=cv, scoring='accuracy')

# Predict using cross-validation and calculate the confusion matrix
y_pred_all = cross_val_score(xgb, X, y, cv=cv, scoring='accuracy')
cm = confusion_matrix(y, y_pred_all)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot(cmap=plt.cm.Blues)
plt.title("Confusion Matrix")
plt.show()

# Generate and print the classification report for the last fold
xgb.fit(X, y)
y_pred_last_fold = xgb.predict(X)
report = classification_report(y, y_pred_last_fold)
print("Classification Report:")
print(report)

# Plot feature importance
plt.figure(figsize=(10, 6))
plt.barh(range(len(xgb.feature_importances_)), xgb.feature_importances_)
plt.yticks(range(len(X.columns)), X.columns)
plt.xlabel("Feature Importance")
plt.ylabel("Feature")
plt.title("Feature Importance in XGBClassifier")
plt.show()






import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay
from xgboost import XGBClassifier

# Load your dataset
# For demonstration, we'll generate a synthetic dataset with multiple features and a binary target
np.random.seed(0)
data = pd.DataFrame(np.random.randn(1000, 10), columns=[f'feature_{i}' for i in range(10)])
data['target'] = np.random.randint(0, 2, 1000)  # Binary target variable

# Split the data into features and target
X = data.drop(columns='target')
y = data['target']

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# Initialize and train the XGBClassifier
xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss')
xgb.fit(X_train, y_train)

# Predict the target values for the test set
y_pred = xgb.predict(X_test)

# Compute the confusion matrix
cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot(cmap=plt.cm.Blues)
plt.title("Confusion Matrix")
plt.show()

# Generate and print the classification report
report = classification_report(y_test, y_pred)
print("Classification Report:")
print(report)

# Plot feature importance
plt.figure(figsize=(10, 6))
plt.barh(range(len(xgb.feature_importances_)), xgb.feature_importances_)
plt.yticks(range(len(X.columns)), X.columns)
plt.xlabel("Feature Importance")
plt.ylabel("Feature")
plt.title("Feature Importance in XGBClassifier")
plt.show()






import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeRegressor
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import f1_score
from xgboost import XGBClassifier

# Generate a synthetic dataset for the example
np.random.seed(0)
data = pd.DataFrame(np.random.randn(100, 5), columns=[f'feature_{i}' for i in range(5)])
data['target'] = np.random.randn(100)

# Desired number of clusters
num_clusters = 10

# Initialize variables to store the best feature and F1 score
best_f1 = 0
best_feature_index = -1
best_segment_labels = None

# Iterate over each feature to segment it using the target variable
for feature_index in range(data.shape[1] - 1):  # Exclude the target column
    feature_name = data.columns[feature_index]
    X_feature = data[[feature_name]].values.reshape(-1, 1)
    y = data['target'].values.reshape(-1, 1)
    
    # Segment the feature using the target variable
    dt = DecisionTreeRegressor(min_samples_split=5, max_leaf_nodes=num_clusters, random_state=0)
    dt.fit(y, X_feature)
    predicted_X = dt.predict(y)
    
    # Convert the continuous segment predictions into discrete labels
    label_encoder = LabelEncoder()
    segment_labels = label_encoder.fit_transform(predicted_X)
    
    # Add the segment labels to the DataFrame temporarily for classification
    data['temp_segments'] = segment_labels
    
    # Use all features (excluding the target variable) to predict these segments
    X_all_features = data.drop(columns=['target', 'temp_segments']).values
    xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')
    xgb.fit(X_all_features, segment_labels)
    
    # Predict the segments and calculate the F1 score
    predicted_segments = xgb.predict(X_all_features)
    f1 = f1_score(segment_labels, predicted_segments, average='weighted')
    
    # Check if this is the best F1 score
    if f1 > best_f1:
        best_f1 = f1
        best_feature_index = feature_index
        best_segment_labels = segment_labels
    
    # Remove the temporary column
    data.drop(columns=['temp_segments'], inplace=True)

# Add the best segments to the DataFrame as a new column
best_feature_name = data.columns[best_feature_index]
data['best_segments'] = best_segment_labels

# Output the best feature index and F1 score
print(f"Best Feature Index: {best_feature_index} ({best_feature_name}), Best F1 Score: {best_f1}")

# Plot the feature colored by the best segmentation
plt.figure(figsize=(10, 6))
plt.scatter(range(len(data)), data[best_feature_name], c=data['best_segments'], cmap='viridis', marker='o')
plt.title(f'Feature {best_feature_name} Segmentation with Highest F1 Score')
plt.xlabel('Sample Index')
plt.ylabel(f'{best_feature_name} Value')
plt.colorbar(label='Segment Label')
plt.grid(True)
plt.show()




import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeRegressor
from sklearn.preprocessing import LabelEncoder
from xgboost import XGBClassifier
from sklearn.metrics import f1_score

# Generate a synthetic dataset for the example
np.random.seed(0)
data = pd.DataFrame({
    'feature': np.random.randn(100),
    'target': np.random.randn(100)
})

# Desired number of clusters
num_clusters = 10

# Input feature and target variable
X = data['feature'].values.reshape(-1, 1)  # Single feature as 2D array
y = data['target']

# Segment the feature (X) using the target variable (y)
dt = DecisionTreeRegressor(min_samples_split=5, max_leaf_nodes=num_clusters, random_state=0)
dt.fit(y.values.reshape(-1, 1), X)

# Obtain the predicted values of X as segments
predicted_X = dt.predict(y.values.reshape(-1, 1))

# Convert these continuous values into discrete segment labels
label_encoder = LabelEncoder()
segment_labels = label_encoder.fit_transform(predicted_X)

# Use these segments as labels and predict using the target variable with XGBoost
xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')
xgb.fit(y.values.reshape(-1, 1), segment_labels)

# Predict the segments and calculate the F1 score
predicted_segments = xgb.predict(y.values.reshape(-1, 1))
f1 = f1_score(segment_labels, predicted_segments, average='weighted')

# Add the segments to the DataFrame as a new column
data['best_segments'] = segment_labels

# Output the F1 score
print(f"F1 Score: {f1}")

# Plot the feature colored by the best segmentation
plt.figure(figsize=(10, 6))
plt.scatter(range(len(data)), data['feature'], c=data['best_segments'], cmap='viridis', marker='o')
plt.title('Feature Segmentation Based on Target Variable')
plt.xlabel('Sample Index')
plt.ylabel('Feature Value')
plt.colorbar(label='Segment Label')
plt.grid(True)
plt.show()




import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeRegressor
from sklearn.preprocessing import LabelEncoder
from xgboost import XGBClassifier
from sklearn.metrics import f1_score

# Generate a synthetic dataset for the example
np.random.seed(0)
data = pd.DataFrame({
    'feature': np.random.randn(100),
    'target': np.random.randn(100)
})

# Desired number of clusters
num_clusters = 10

# Input feature and target variable
X = data[['feature']]  # Single feature
y = data['target']

# Segment the target variable (y) directly using a Decision Tree Regressor
dt = DecisionTreeRegressor(min_samples_split=5, max_leaf_nodes=num_clusters, random_state=0)
dt.fit(X, y)

# Obtain the predicted values of y as segments
predicted_y = dt.predict(X)

# Convert these continuous values into discrete segment labels
label_encoder = LabelEncoder()
segment_labels = label_encoder.fit_transform(predicted_y)

# Use these segments as labels and predict using the single feature with XGBoost
xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')
xgb.fit(X, segment_labels)

# Predict the segments and calculate the F1 score
predicted_segments = xgb.predict(X)
f1 = f1_score(segment_labels, predicted_segments, average='weighted')

# Add the segments to the DataFrame as a new column
data['best_segments'] = segment_labels

# Output the F1 score
print(f"F1 Score: {f1}")

# Plot the target variable colored by the best segmentation
plt.figure(figsize=(10, 6))
plt.scatter(range(len(data)), data['target'], c=data['best_segments'], cmap='viridis', marker='o')
plt.title('Target Variable Segmentation into Disjoint Clusters')
plt.xlabel('Sample Index')
plt.ylabel('Target Variable Value')
plt.colorbar(label='Segment Label')
plt.grid(True)
plt.show()



import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import f1_score
from xgboost import XGBClassifier
from sklearn.preprocessing import LabelEncoder

# Generate a synthetic dataset for the example
np.random.seed(0)
data = pd.DataFrame(np.random.randn(100, 5), columns=[f'feature_{i}' for i in range(5)])
data['target'] = np.random.randn(100)

# Desired number of clusters
num_clusters = 10

# Input features and target variable
X = data.drop(columns='target')
y = data['target']

# Segment the target variable (y) directly using a Decision Tree Regressor
dt = DecisionTreeRegressor(min_samples_split=5, max_leaf_nodes=num_clusters, random_state=0)
dt.fit(X, y)

# Obtain the predicted values of y as segments
predicted_y = dt.predict(X)

# Convert these continuous values into discrete segment labels
label_encoder = LabelEncoder()
segment_labels = label_encoder.fit_transform(predicted_y)

# Use these segments as labels and predict using all features with XGBoost
xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')
xgb.fit(X, segment_labels)

# Predict the segments and calculate the F1 score
predicted_segments = xgb.predict(X)
f1 = f1_score(segment_labels, predicted_segments, average='weighted')

# Add the segments to the DataFrame as a new column
data['best_segments'] = segment_labels

# Output the F1 score
print(f"F1 Score: {f1}")

# Plot the target variable colored by the best segmentation
plt.figure(figsize=(10, 6))
plt.scatter(range(len(data)), data['target'], c=data['best_segments'], cmap='viridis', marker='o')
plt.title('Target Variable Segmentation into Disjoint Clusters')
plt.xlabel('Sample Index')
plt.ylabel('Target Variable Value')
plt.colorbar(label='Segment Label')
plt.grid(True)
plt.show()




import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import f1_score
from xgboost import XGBClassifier
from sklearn.preprocessing import LabelEncoder

# Generate a synthetic dataset for the example
np.random.seed(0)
data = pd.DataFrame(np.random.randn(100, 5), columns=[f'feature_{i}' for i in range(5)])
data['target'] = np.random.randn(100)

# Desired number of clusters
num_clusters = 10

# Input features and target variable
X = data.drop(columns='target')
y = data['target']

# Segment the target variable using a Decision Tree Regressor
dt = DecisionTreeRegressor(min_samples_split=5, max_leaf_nodes=num_clusters, random_state=0)
dt.fit(X, y)

# Assign each sample to a segment (leaf node)
segments = dt.apply(X)

# Convert the segments (leaf nodes) into categorical labels
label_encoder = LabelEncoder()
segment_labels = label_encoder.fit_transform(segments)

# Use these segments as labels and predict using all features with XGBoost
xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')
xgb.fit(X, segment_labels)

# Predict the segments and calculate the F1 score
predicted_segments = xgb.predict(X)
f1 = f1_score(segment_labels, predicted_segments, average='weighted')

# Add the segments to the DataFrame as a new column
data['best_segments'] = segment_labels

# Output the F1 score
print(f"F1 Score: {f1}")

# Plot the target variable colored by the best segmentation
plt.figure(figsize=(10, 6))
plt.scatter(range(len(data)), data['target'], c=data['best_segments'], cmap='viridis', marker='o')
plt.title('Target Variable Segmentation into Disjoint Clusters')
plt.xlabel('Sample Index')
plt.ylabel('Target Variable Value')
plt.colorbar(label='Segment Label')
plt.grid(True)
plt.show()




import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeRegressor
from sklearn.preprocessing import LabelEncoder

# Generate a synthetic dataset for the example
np.random.seed(0)
data = pd.DataFrame(np.random.randn(100, 5), columns=[f'feature_{i}' for i in range(5)])
data['target'] = np.random.randn(100)

# Desired number of clusters
num_clusters = 10

# Input features and target variable
X = data.drop(columns='target')
y = data['target']

# Segment the target variable using a Decision Tree Regressor
dt = DecisionTreeRegressor(min_samples_split=5, max_leaf_nodes=num_clusters, random_state=0)
dt.fit(X, y)

# Assign each sample to a segment (leaf node)
segments = dt.apply(X)

# Convert the segments (leaf nodes) into categorical labels
label_encoder = LabelEncoder()
data['best_segments'] = label_encoder.fit_transform(segments)

# Output the unique segments
unique_segments = data['best_segments'].unique()
print(f"Unique Segments: {len(unique_segments)}, Segments: {unique_segments}")

# Plot the target variable colored by the segments
plt.figure(figsize=(10, 6))
plt.scatter(range(len(data)), data['target'], c=data['best_segments'], cmap='viridis', marker='o')
plt.title('Target Variable Segmentation into Disjoint Clusters')
plt.xlabel('Sample Index')
plt.ylabel('Target Variable Value')
plt.colorbar(label='Segment Label')
plt.grid(True)
plt.show()



import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeRegressor
from sklearn.preprocessing import LabelEncoder

# Generate a synthetic dataset for the example
np.random.seed(0)
data = pd.DataFrame(np.random.randn(100, 5), columns=[f'feature_{i}' for i in range(5)])
data['target'] = np.random.randn(100)

# Desired number of clusters
num_clusters = 10

# Store the best F1 score and corresponding feature index
best_f1 = 0
best_feature_index = -1
best_segments = None

# Iterate over each feature to segment the target variable
for feature_index in range(data.shape[1] - 1):  # Exclude target column
    feature_name = data.columns[feature_index]
    X = data.drop(columns='target')
    y = data['target']
    
    # Segment the target variable using the current feature
    dt = DecisionTreeRegressor(min_samples_split=5, max_leaf_nodes=num_clusters, random_state=0)
    dt.fit(X[[feature_name]], y)
    segments = dt.apply(X[[feature_name]])

    # Check for disjoint segments by ensuring non-overlapping intervals
    # This is a simplified example; more sophisticated checks and adjustments may be needed
    unique_segments = np.unique(segments)
    is_disjoint = len(unique_segments) <= num_clusters

    # Convert segments to categorical labels if disjoint
    if is_disjoint:
        label_encoder = LabelEncoder()
        segment_labels = label_encoder.fit_transform(segments)
    else:
        continue  # Skip if the segments are not disjoint

    # Check if this configuration is the best
    if len(unique_segments) > len(set(best_segments)) if best_segments is not None else 0:
        best_segments = segment_labels
        best_feature_index = feature_index

# Add the best segments to the DataFrame as a new column if disjoint segments were found
if best_segments is not None:
    data['best_segments'] = best_segments
    best_feature_name = data.columns[best_feature_index]
    print(f"Best Feature Index: {best_feature_index} ({best_feature_name}), Unique Segments: {len(set(best_segments))}")
else:
    print("No disjoint segments found with the given configuration.")

# Plot the target variable colored by the best segmentation if available
if best_segments is not None:
    plt.figure(figsize=(10, 6))
    plt.scatter(range(len(data)), data['target'], c=data['best_segments'], cmap='viridis', marker='o', label='Target variable')
    plt.title(f'Target Variable Segmentation by Feature {best_feature_name} with {num_clusters} Clusters')
    plt.xlabel('Sample Index')
    plt.ylabel('Target Variable Value')
    plt.colorbar(label='Segment Label')
    plt.grid(True)
    plt.legend()
    plt.show()





import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score, ConfusionMatrixDisplay
from sklearn.model_selection import train_test_split
from xgboost import XGBClassifier

# Example DataFrame with features and target
np.random.seed(0)
data = pd.DataFrame(np.random.randn(100, 5), columns=[f'feature_{i}' for i in range(5)])
data['target'] = np.random.choice([0, 1], size=100)  # Binary target for classification

# Split the data into training and testing sets
X = data.drop(columns='target')
y = data['target']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# Train the XGBoost classifier
xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')
xgb.fit(X_train, y_train)

# Predict the target values for the test set
y_pred = xgb.predict(X_test)

# Calculate evaluation metrics
conf_matrix = confusion_matrix(y_test, y_pred)
f1 = f1_score(y_test, y_pred, average='weighted')
precision = precision_score(y_test, y_pred, average='weighted')
recall = recall_score(y_test, y_pred, average='weighted')

# Display the confusion matrix
disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=xgb.classes_)
disp.plot(cmap=plt.cm.Blues)
plt.title('Confusion Matrix')
plt.show()

# Print the evaluation metrics
print(f"F1 Score: {f1}")
print(f"Precision: {precision}")
print(f"Recall: {recall}")






import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import f1_score
from xgboost import XGBClassifier
from sklearn.preprocessing import LabelEncoder

# Generate a synthetic dataset for the example
np.random.seed(0)
data = pd.DataFrame(np.random.randn(100, 5), columns=[f'feature_{i}' for i in range(5)])
data['target'] = np.random.randn(100)

# Store the best F1 score and corresponding feature index
best_f1 = 0
best_feature_index = -1
best_segments = None

# Iterate over each feature to segment the target variable
for feature_index in range(data.shape[1] - 1):  # Exclude target column
    feature_name = data.columns[feature_index]
    X = data.drop(columns='target')
    y = data['target']
    
    # Segment the target variable using the current feature
    dt = DecisionTreeRegressor(min_samples_split=5, random_state=0)
    dt.fit(X[[feature_name]], y)
    segments = dt.apply(X[[feature_name]])

    # Convert segments to categorical labels
    label_encoder = LabelEncoder()
    segment_labels = label_encoder.fit_transform(segments)

    # Use these segments as labels and predict using all features with XGBoost
    xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')
    xgb.fit(X, segment_labels)

    # Predict the segments and calculate the F1 score
    predicted_segments = xgb.predict(X)
    f1 = f1_score(segment_labels, predicted_segments, average='weighted')

    # Check if this is the best F1 score
    if f1 > best_f1:
        best_f1 = f1
        best_feature_index = feature_index
        best_segments = segment_labels

# Add the best segments to the DataFrame as a new column
data['best_segments'] = best_segments

# Output the best feature index and F1 score
best_feature_name = data.columns[best_feature_index]
print(f"Best Feature Index: {best_feature_index} ({best_feature_name}), Best F1 Score: {best_f1}")

# Plot the target variable colored by the best segmentation
plt.figure(figsize=(10, 6))
plt.scatter(range(len(data)), data['target'], c=data['best_segments'], cmap='viridis', marker='o', label='Target variable')
plt.title(f'Target Variable Segmentation by Feature {best_feature_name}')
plt.xlabel('Sample Index')
plt.ylabel('Target Variable Value')
plt.colorbar(label='Segment Label')
plt.grid(True)
plt.legend()
plt.show()




import numpy as np
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import f1_score
from xgboost import XGBClassifier
from sklearn.preprocessing import LabelEncoder

# Generate a synthetic dataset for the example
np.random.seed(0)
X = np.random.randn(100, 5)  # 100 samples, 5 features
y = np.random.randn(100)     # Target variable

# Store the best F1 score and corresponding feature index
best_f1 = 0
best_feature_index = -1
best_segments = None

# Iterate over each feature to segment the target variable
for feature_index in range(X.shape[1]):
    # Segment the target variable using the current feature
    dt = DecisionTreeRegressor(min_samples_split=5, random_state=0)
    dt.fit(X[:, feature_index].reshape(-1, 1), y)
    segments = dt.apply(X[:, feature_index].reshape(-1, 1))

    # Convert segments to categorical labels
    label_encoder = LabelEncoder()
    segment_labels = label_encoder.fit_transform(segments)

    # Use these segments as labels and predict using all features with XGBoost
    xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')
    xgb.fit(X, segment_labels)

    # Predict the segments and calculate the F1 score
    predicted_segments = xgb.predict(X)
    f1 = f1_score(segment_labels, predicted_segments, average='weighted')

    # Check if this is the best F1 score
    if f1 > best_f1:
        best_f1 = f1
        best_feature_index = feature_index
        best_segments = segment_labels

# Output the best feature index and F1 score
print(f"Best Feature Index: {best_feature_index}, Best F1 Score: {best_f1}")

# Plot the target variable colored by the best segmentation
plt.figure(figsize=(10, 6))
plt.scatter(range(len(y)), y, c=best_segments, cmap='viridis', marker='o', label='Target variable')
plt.title(f'Target Variable Segmentation by Feature {best_feature_index}')
plt.xlabel('Sample Index')
plt.ylabel('Target Variable Value')
plt.colorbar(label='Segment Label')
plt.grid(True)
plt.legend()
plt.show()





import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import f1_score
from xgboost import XGBClassifier
from sklearn.preprocessing import KBinsDiscretizer

# Generate a synthetic dataset for the example
np.random.seed(0)
X = np.random.randn(100, 5)  # 100 samples, 5 features
y = np.random.randn(100)     # Target variable

# Store the best F1 score and corresponding feature index
best_f1 = 0
best_feature_index = -1
best_segments = None

# Iterate over each feature to segment the target variable
for feature_index in range(X.shape[1]):
    # Segment the target variable using the current feature
    dt = DecisionTreeRegressor(min_samples_split=5, random_state=0)
    dt.fit(X[:, feature_index].reshape(-1, 1), y)
    segments = dt.apply(X[:, feature_index].reshape(-1, 1))

    # Use these segments as labels and predict using all features with XGBoost
    xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')
    xgb.fit(X, segments)

    # Predict the segments and calculate the F1 score
    predicted_segments = xgb.predict(X)
    f1 = f1_score(segments, predicted_segments, average='weighted')

    # Check if this is the best F1 score
    if f1 > best_f1:
        best_f1 = f1
        best_feature_index = feature_index
        best_segments = segments

# Output the best feature index and F1 score
print(f"Best Feature Index: {best_feature_index}, Best F1 Score: {best_f1}")

# Plot the target variable colored by the best segmentation
plt.figure(figsize=(10, 6))
plt.scatter(range(len(y)), y, c=best_segments, cmap='viridis', marker='o', label='Target variable')
plt.title(f'Target Variable Segmentation by Feature {best_feature_index}')
plt.xlabel('Sample Index')
plt.ylabel('Target Variable Value')
plt.colorbar(label='Segment Label')
plt.grid(True)
plt.legend()
plt.show()




import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import f1_score
from xgboost import XGBClassifier

# Generate a synthetic dataset for the example
np.random.seed(0)
X = np.random.randn(100, 5)  # 100 samples, 5 features
y = np.random.randn(100)     # Target variable

# Store the best F1 score and corresponding feature index
best_f1 = 0
best_feature_index = -1
best_segments = None

# Iterate over each feature to segment the target variable
for feature_index in range(X.shape[1]):
    # Segment the target variable using the current feature
    dt = DecisionTreeRegressor(min_samples_split=5, random_state=0)
    dt.fit(X[:, feature_index].reshape(-1, 1), y)
    segments = dt.predict(X[:, feature_index].reshape(-1, 1))

    # Use these segments as labels and predict using all features with XGBoost
    xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')
    xgb.fit(X, segments)

    # Predict the segments and calculate the F1 score
    predicted_segments = xgb.predict(X)
    f1 = f1_score(segments, predicted_segments, average='weighted')

    # Check if this is the best F1 score
    if f1 > best_f1:
        best_f1 = f1
        best_feature_index = feature_index
        best_segments = segments

# Output the best feature index and F1 score
print(f"Best Feature Index: {best_feature_index}, Best F1 Score: {best_f1}")

# Plot the target variable colored by the best segmentation
plt.figure(figsize=(10, 6))
plt.scatter(range(len(y)), y, c=best_segments, cmap='viridis', marker='o', label='Target variable')
plt.title(f'Target Variable Segmentation by Feature {best_feature_index}')
plt.xlabel('Sample Index')
plt.ylabel('Target Variable Value')
plt.colorbar(label='Segment Label')
plt.grid(True)
plt.legend()
plt.show()





import numpy as np
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeRegressor
from sklearn.datasets import make_regression
from sklearn.model_selection import train_test_split

# Generate a sample dataset with multiple features
X, y = make_regression(n_samples=100, n_features=2, noise=0.1, random_state=0)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# Fit the Decision Tree Regressor
tree = DecisionTreeRegressor(min_samples_split=5, random_state=0)
tree.fit(X_train, y_train)

# Predict using the decision tree
y_pred_train = tree.predict(X_train)
y_pred_test = tree.predict(X_test)

# Plot the original data and the decision tree segments
fig, ax = plt.subplots(1, 2, figsize=(14, 6))

# Training data plot
ax[0].scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap='viridis', label='Original data')
ax[0].scatter(X_train[:, 0], X_train[:, 1], c=y_pred_train, cmap='viridis', marker='x', label='Predicted segments')
ax[0].set_title('Training Data')
ax[0].set_xlabel('Feature 1')
ax[0].set_ylabel('Feature 2')
ax[0].legend()
ax[0].grid(True)

# Testing data plot
ax[1].scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap='viridis', label='Original data')
ax[1].scatter(X_test[:, 0], X_test[:, 1], c=y_pred_test, cmap='viridis', marker='x', label='Predicted segments')
ax[1].set_title('Testing Data')
ax[1].set_xlabel('Feature 1')
ax[1].set_ylabel('Feature 2')
ax[1].legend()
ax[1].grid(True)

plt.tight_layout()
plt.show()



import numpy as np
import matplotlib.pyplot as plt

# Generate the data
np.random.seed(0)  # For reproducibility
data = np.random.randn(100)  # Generate 100 random points

# Set the minimum number of observations per segment
min_obs_per_seg = 5

def generate_segments(data, min_obs_per_seg):
    n = len(data)
    segments = []
    for start in range(n):
        for end in range(start + min_obs_per_seg, n + 1):
            segments.append((start, end))
    return segments

segments = generate_segments(data, min_obs_per_seg)

# Plot the entire data with each segment highlighted
for i, (start, end) in enumerate(segments):
    plt.figure()
    plt.plot(data, 'k-', alpha=0.3)  # Plot the full data in a lighter color
    plt.plot(range(start, end), data[start:end], 'b-', linewidth=2)  # Highlight the current segment
    plt.title(f'Segment {i + 1}: {start} to {end}')
    plt.xlabel('Index')
    plt.ylabel('Value')
    plt.grid(True)
    plt.show()




import numpy as np
import matplotlib.pyplot as plt

# Generate the data
np.random.seed(0)  # For reproducibility
data = np.random.randn(100)  # Generate 100 random points

# Set the minimum number of observations per segment
min_obs_per_seg = 5

def generate_segments(data, min_obs_per_seg):
    n = len(data)
    segments = []
    for start in range(n):
        for end in range(start + min_obs_per_seg, n + 1):
            segments.append((start, end))
    return segments

segments = generate_segments(data, min_obs_per_seg)

# Plotting the segments step-by-step
for i in range(len(segments)):
    plt.figure(figsize=(10, 5))
    plt.plot(data, label='Data', alpha=0.5)
    
    # Plot each segment up to the current iteration
    for j in range(i + 1):
        start, end = segments[j]
        plt.plot(range(start, end), data[start:end], marker='o', label=f'Segment {j + 1}')

    plt.title(f'Segmentation Step {i + 1}')
    plt.xlabel('Index')
    plt.ylabel('Value')
    plt.legend()
    plt.grid(True)
    plt.savefig(f'segment_step_{i + 1}.png')  # Save each plot as an image file
    plt.show()




import numpy as np
import matplotlib.pyplot as plt

# Generate the data
np.random.seed(0)  # For reproducibility
data = np.random.randn(100)  # Generate 100 random points

# Set the minimum number of observations per segment
min_obs_per_seg = 5

def generate_segments(data, min_obs_per_seg):
    n = len(data)
    segments = []
    for start in range(n):
        for end in range(start + min_obs_per_seg, n + 1):
            segments.append((start, end))
    return segments

segments = generate_segments(data, min_obs_per_seg)

# Plot each segment
for i, (start, end) in enumerate(segments):
    plt.figure()
    x = range(start, end)
    y = data[start:end]
    plt.plot(x, y, marker='o')
    plt.title(f'Segment {i + 1}: {start} to {end}')
    plt.xlabel('Index')
    plt.ylabel('Value')
    plt.grid(True)
    plt.savefig(f'segment_{i + 1}.png')  # Save each plot as an image file
    plt.show()





import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib.animation import FuncAnimation

# Step 1: Generate the data
np.random.seed(0)  # For reproducibility
data = np.random.randn(100)  # Generate 100 random points

# Step 2: Create segments based on a minimum number of observations per segment
min_obs_per_seg = 5

def generate_segments(data, min_obs_per_seg):
    n = len(data)
    # This function will generate the possible segmentations
    segments = []
    for start in range(n):
        for end in range(start + min_obs_per_seg, n + 1):
            segments.append((start, end))
    return segments

segments = generate_segments(data, min_obs_per_seg)

# Step 3: Animate the plot
fig, ax = plt.subplots()
ax.set_xlim(0, len(data))
ax.set_ylim(np.min(data), np.max(data))
line, = ax.plot([], [], lw=2)
title = ax.set_title('')

def init():
    line.set_data([], [])
    return line,

def update(frame):
    start, end = segments[frame]
    x = range(start, end)
    y = data[start:end]
    line.set_data(x, y)
    title.set_text(f'Segment {frame + 1}/{len(segments)}: {start} to {end}')
    return line, title

ani = FuncAnimation(fig, update, frames=range(len(segments)), init_func=init, blit=True, repeat=False)
plt.show()






import numpy as np
import pandas as pd
import xgboost as xgb
from sklearn.metrics import f1_score
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from itertools import combinations

def generate_possible_segments(y, num_segments, min_obs_per_seg):
    """
    Generates all possible segmentations for the target variable `y` with a given number of segments and minimum observations per segment.
    
    Parameters:
    - y: pd.Series - The target variable.
    - num_segments: int - The number of segments to create.
    - min_obs_per_seg: int - Minimum number of observations per segment.
    
    Returns:
    - possible_segments: List of lists containing segment boundaries.
    """
    possible_segments = []
    sorted_values = np.sort(y.unique())
    n_values = len(sorted_values)
    
    for combination in combinations(range(1, n_values), num_segments - 1):
        segments = np.split(sorted_values, combination)
        if all(len(seg) >= min_obs_per_seg for seg in segments):
            segment_boundaries = [seg[-1] for seg in segments[:-1]]  # Get the last value in each segment except the last
            segment_boundaries = [sorted_values[0] - 1] + segment_boundaries + [sorted_values[-1] + 1]
            possible_segments.append(segment_boundaries)
    
    return possible_segments

def optimize_segments(df, target_var, num_segments, min_obs_per_seg):
    """
    Optimizes the segmentation of a target variable in a DataFrame to maximize the F1 score of an XGBoost model.

    Parameters:
    - df: pd.DataFrame - The input DataFrame.
    - target_var: str - The target variable column name.
    - num_segments: int - The number of segments to create.
    - min_obs_per_seg: int - Minimum number of observations per segment.

    Returns:
    - df_with_segments: pd.DataFrame - The DataFrame with an added 'segment' column.
    - best_f1: float - The best F1 score achieved.
    """
    data = df.copy()
    X = data.drop(columns=[target_var])
    y = data[target_var]
    
    possible_segments = generate_possible_segments(y, num_segments, min_obs_per_seg)
    best_f1 = -np.inf
    best_segments = None

    for boundaries in possible_segments:
        labels = pd.cut(y, bins=boundaries, labels=False, include_lowest=True)
        data['segment'] = labels

        # Train an XGBoost model and evaluate F1 score
        X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)
        model = xgb.XGBClassifier(objective='multi:softmax', num_class=num_segments)
        model.fit(X_train, y_train)
        predictions = model.predict(X_test)
        f1 = f1_score(y_test, predictions, average='weighted')

        if f1 > best_f1:
            best_f1 = f1
            best_segments = boundaries

    # Assign the best segments to the DataFrame
    data['segment'] = pd.cut(y, bins=best_segments, labels=False, include_lowest=True)

    # Plotting the target variable with segments
    plt.figure(figsize=(12, 6))
    plt.scatter(range(len(y)), y, c=data['segment'], cmap='viridis', label='Segments', alpha=0.6)
    plt.colorbar(label='Segment')
    plt.title(f'Target Variable Segmentation with Best F1 Score = {best_f1:.4f}')
    plt.xlabel('Index')
    plt.ylabel(target_var)
    plt.grid(True)
    plt.legend()
    plt.show()

    return data, best_f1

# Example usage:
# df = pd.read_csv('your_data.csv')
# df_with_segments, best_f1 = optimize_segments(df, 'target_variable', num_segments=5, min_obs_per_seg=50)
# print("Data with segments:\n", df_with_segments.head())
# print("Best F1 score:", best_f1)








import numpy as np
import pandas as pd
import xgboost as xgb
from sklearn.metrics import f1_score
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

def optimize_segments(df, target_var, num_segments, min_obs_per_seg):
    """
    Optimizes the segmentation of a target variable in a DataFrame to maximize the F1 score of an XGBoost model.

    Parameters:
    - df: pd.DataFrame - The input DataFrame.
    - target_var: str - The target variable column name.
    - num_segments: int - The number of segments to create.
    - min_obs_per_seg: int - Minimum number of observations per segment.

    Returns:
    - df_with_segments: pd.DataFrame - The DataFrame with an added 'segment' column.
    - best_f1: float - The best F1 score achieved.
    """
    data = df.copy()
    X = data.drop(columns=[target_var])
    y = data[target_var]

    # Create initial segment boundaries
    initial_segment_boundaries = np.linspace(y.min(), y.max(), num_segments + 1)
    best_f1 = -np.inf
    best_segments = initial_segment_boundaries

    def evaluate_segments(boundaries):
        nonlocal best_f1, best_segments
        
        # Create segment labels based on boundaries
        labels = pd.cut(y, bins=boundaries, labels=False, include_lowest=True)
        data['segment'] = labels
        
        # Check if each segment has the minimum required observations
        segment_counts = data['segment'].value_counts()
        if (segment_counts < min_obs_per_seg).any():
            return -np.inf  # Return a very low F1 score if any segment is too small
        
        # Train an XGBoost model and evaluate F1 score
        X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)
        model = xgb.XGBClassifier(objective='multi:softmax', num_class=num_segments)
        model.fit(X_train, y_train)
        predictions = model.predict(X_test)
        f1 = f1_score(y_test, predictions, average='weighted')
        
        if f1 > best_f1:
            best_f1 = f1
            best_segments = boundaries
        
        return f1

    # Optimization loop - this is a placeholder for a more sophisticated optimization approach
    for _ in range(100):  # Number of iterations, adjust based on needs
        new_boundaries = initial_segment_boundaries + np.random.normal(0, 0.1, size=initial_segment_boundaries.shape)
        new_boundaries = np.sort(np.clip(new_boundaries, y.min(), y.max()))
        evaluate_segments(new_boundaries)

    # Assign the best segments to the DataFrame
    data['segment'] = pd.cut(y, bins=best_segments, labels=False, include_lowest=True)

    # Plotting the target variable with segments
    plt.figure(figsize=(12, 6))
    plt.scatter(range(len(y)), y, c=data['segment'], cmap='viridis', label='Segments', alpha=0.6)
    plt.colorbar(label='Segment')
    plt.title(f'Target Variable Segmentation with F1 Score = {best_f1:.4f}')
    plt.xlabel('Index')
    plt.ylabel(target_var)
    plt.grid(True)
    plt.legend()
    plt.show()

    return data, best_f1

# Example usage:
# df = pd.read_csv('your_data.csv')
# df_with_segments, best_f1 = optimize_segments(df, 'target_variable', num_segments=5, min_obs_per_seg=50)
# print("Data with segments:\n", df_with_segments.head())
# print("Best F1 score:", best_f1)








import numpy as np
import pandas as pd
import xgboost as xgb
from sklearn.metrics import r2_score
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

def optimize_segments(df, target_var, num_segments, min_obs_per_seg):
    """
    Optimizes the segmentation of a target variable in a DataFrame to maximize the R² score of an XGBoost model.

    Parameters:
    - df: pd.DataFrame - The input DataFrame.
    - target_var: str - The target variable column name.
    - num_segments: int - The number of segments to create.
    - min_obs_per_seg: int - Minimum number of observations per segment.

    Returns:
    - df_with_segments: pd.DataFrame - The DataFrame with an added 'segment' column.
    - best_r2: float - The best R² score achieved.
    """
    data = df.copy()
    X = data.drop(columns=[target_var])
    y = data[target_var]

    # Create initial segment boundaries
    initial_segment_boundaries = np.linspace(y.min(), y.max(), num_segments + 1)
    best_r2 = -np.inf
    best_segments = initial_segment_boundaries

    def evaluate_segments(boundaries):
        nonlocal best_r2, best_segments
        
        # Create segment labels based on boundaries
        labels = pd.cut(y, bins=boundaries, labels=False, include_lowest=True)
        data['segment'] = labels
        
        # Check if each segment has the minimum required observations
        segment_counts = data['segment'].value_counts()
        if (segment_counts < min_obs_per_seg).any():
            return -np.inf  # Return a very low R² if any segment is too small
        
        # Train an XGBoost model and evaluate R²
        X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)
        model = xgb.XGBRegressor(objective='reg:squarederror')
        model.fit(X_train, y_train)
        predictions = model.predict(X_test)
        r2 = r2_score(y_test, predictions)
        
        if r2 > best_r2:
            best_r2 = r2
            best_segments = boundaries
        
        return r2

    # Optimization loop - this is a placeholder for a more sophisticated optimization approach
    for _ in range(100):  # Number of iterations, adjust based on needs
        new_boundaries = initial_segment_boundaries + np.random.normal(0, 0.1, size=initial_segment_boundaries.shape)
        new_boundaries = np.sort(np.clip(new_boundaries, y.min(), y.max()))
        evaluate_segments(new_boundaries)

    # Assign the best segments to the DataFrame
    data['segment'] = pd.cut(y, bins=best_segments, labels=False, include_lowest=True)

    # Plotting the target variable with segments
    plt.figure(figsize=(12, 6))
    plt.scatter(range(len(y)), y, c=data['segment'], cmap='viridis', label='Segments', alpha=0.6)
    plt.colorbar(label='Segment')
    plt.title(f'Target Variable Segmentation with R² = {best_r2:.4f}')
    plt.xlabel('Index')
    plt.ylabel(target_var)
    plt.grid(True)
    plt.legend()
    plt.show()

    return data, best_r2

# Example usage:
# df = pd.read_csv('your_data.csv')
# df_with_segments, best_r2 = optimize_segments(df, 'target_variable', num_segments=5, min_obs_per_seg=50)
# print("Data with segments:\n", df_with_segments.head())
# print("Best R² score:", best_r2)






import xgboost as xgb
from sklearn.datasets import make_regression, make_classification
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

def plot_top_k_features(model, feature_names, k=5, title="Feature Importance"):
    # Get feature importances
    feature_importances = model.feature_importances_
    feature_importances_percentage = 100 * (feature_importances / feature_importances.sum())

    # Create a DataFrame for visualization
    importance_df = pd.DataFrame({
        'Feature': feature_names,
        'Importance': feature_importances_percentage
    }).sort_values(by='Importance', ascending=False).head(k)

    # Plot feature importances
    plt.figure(figsize=(10, 6))
    sns.barplot(x='Importance', y='Feature', data=importance_df)
    plt.xlabel('Importance (%)')
    plt.ylabel('Feature')
    plt.title(title)
    plt.show()

# Generate a sample regression dataset
X_reg, y_reg = make_regression(n_samples=1000, n_features=10, random_state=42)
X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X_reg, y_reg, test_size=0.2, random_state=42)

# Train an XGBoost regression model
regressor = xgb.XGBRegressor()
regressor.fit(X_train_reg, y_train_reg)

# Plot top k feature importances for regression
plot_top_k_features(regressor, [f'feature_{i}' for i in range(X_reg.shape[1])], k=5, title="Top 5 Features for XGBoost Regression")

# Generate a sample classification dataset
X_clf, y_clf = make_classification(n_samples=1000, n_features=10, random_state=42)
X_train_clf, X_test_clf, y_train_clf, y_test_clf = train_test_split(X_clf, y_clf, test_size=0.2, random_state=42)

# Train an XGBoost classification model
classifier = xgb.XGBClassifier()
classifier.fit(X_train_clf, y_train_clf)

# Plot top k feature importances for classification
plot_top_k_features(classifier, [f'feature_{i}' for i in range(X_clf.shape[1])], k=5, title="Top 5 Features for XGBoost Classification")

# Generate a sample dataset for RandomForestRegressor
X_rf, y_rf = make_regression(n_samples=100, n_features=5, noise=0.1, random_state=42)
feature_names_rf = [f'feature_{i}' for i in range(X_rf.shape[1])]

# Train a RandomForestRegressor
model_rf = RandomForestRegressor(random_state=42)
model_rf.fit(X_rf, y_rf)

# Plot top k feature importances for RandomForestRegressor
plot_top_k_features(model_rf, feature_names_rf, k=5, title="Top 5 Features for RandomForestRegressor")





import xgboost as xgb
from sklearn.datasets import make_regression
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import numpy as np

# Generate a sample regression dataset
X, y = make_regression(n_samples=1000, n_features=10, random_state=42)

# Split the data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train an XGBoost regression model
regressor = xgb.XGBRegressor()
regressor.fit(X_train, y_train)

# Get feature importance
importance = regressor.get_booster().get_score(importance_type='weight')
importance = {k: v / sum(importance.values()) for k, v in importance.items()}  # Calculate percentages

# Sort importance by feature
sorted_importance = sorted(importance.items(), key=lambda x: x[1], reverse=True)
features = [x[0] for x in sorted_importance]
importance_values = [x[1] * 100 for x in sorted_importance]  # Convert to percentages

# Plot feature importance
fig, ax = plt.subplots()
ax.barh(features, importance_values)
ax.set_title("Feature Importance for XGBoost Regression (Percentage)")
ax.set_xlabel("Percentage")
ax.set_ylabel("Features")
plt.show()






import xgboost as xgb
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from xgboost import plot_importance
import matplotlib.pyplot as plt

# Generate a sample classification dataset
X, y = make_classification(n_samples=1000, n_features=10, random_state=42)

# Split the data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train an XGBoost classification model
classifier = xgb.XGBClassifier()
classifier.fit(X_train, y_train)

# Plot feature importance
fig, ax = plt.subplots()
plot_importance(classifier, ax=ax)
ax.set_title("Feature Importance for XGBoost Classification")
plt.show()
import xgboost as xgb
from sklearn.datasets import make_regression
from sklearn.model_selection import train_test_split
from xgboost import plot_importance
import matplotlib.pyplot as plt

# Generate a sample regression dataset
X, y = make_regression(n_samples=1000, n_features=10, random_state=42)

# Split the data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train an XGBoost regression model
regressor = xgb.XGBRegressor()
regressor.fit(X_train, y_train)

# Plot feature importance
fig, ax = plt.subplots()
plot_importance(regressor, ax=ax)
ax.set_title("Feature Importance for XGBoost Regression")
plt.show()





import numpy as np
import pandas as pd
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
from xgboost import XGBClassifier
from sklearn.metrics import classification_report, precision_recall_curve

# Generate a synthetic dataset with class imbalance
X, y = make_classification(n_samples=1000, n_features=20, n_informative=2,
                           n_redundant=10, n_clusters_per_class=1, n_classes=10,
                           weights=[0.1]*9 + [0.1], flip_y=0, random_state=42)

# Split into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize results dictionary
results = {}

# Approach 1: SMOTE (Oversampling)
smote = SMOTE(random_state=42)
X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)
classifier_smote = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')
classifier_smote.fit(X_train_smote, y_train_smote)
y_pred_smote = classifier_smote.predict(X_test)
results['SMOTE'] = classification_report(y_test, y_pred_smote, output_dict=True)

# Approach 2: Random Undersampling
rus = RandomUnderSampler(random_state=42)
X_train_rus, y_train_rus = rus.fit_resample(X_train, y_train)
classifier_rus = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')
classifier_rus.fit(X_train_rus, y_train_rus)
y_pred_rus = classifier_rus.predict(X_test)
results['Random Undersampling'] = classification_report(y_test, y_pred_rus, output_dict=True)

# Approach 3: Class Weight Adjustment
class_weights = {i: len(y_train) / (10 * sum(y_train == i)) for i in np.unique(y_train)}
classifier_weighted = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', scale_pos_weight=class_weights)
classifier_weighted.fit(X_train, y_train)
y_pred_weighted = classifier_weighted.predict(X_test)
results['Class Weight Adjustment'] = classification_report(y_test, y_pred_weighted, output_dict=True)

# Approach 4: Threshold Moving
classifier_threshold = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')
classifier_threshold.fit(X_train, y_train)
y_probs = classifier_threshold.predict_proba(X_test)
thresholds = {}
best_thresholds = {}

for i in range(10):
    precision, recall, thr = precision_recall_curve(y_test == i, y_probs[:, i])
    f1_scores = 2 * (precision * recall) / (precision + recall)
    best_threshold = thr[np.argmax(f1_scores)]
    thresholds[i] = best_threshold
    best_thresholds[i] = best_threshold

y_pred_adjusted = np.zeros_like(y_test)
for i in range(len(y_test)):
    class_probs = y_probs[i]
    class_probs_thresholded = (class_probs >= [thresholds[j] for j in range(10)]).astype(int)
    y_pred_adjusted[i] = np.argmax(class_probs_thresholded)

results['Threshold Moving'] = classification_report(y_test, y_pred_adjusted, output_dict=True)

# Print results
for approach, metrics in results.items():
    print(f"Approach: {approach}")
    print(pd.DataFrame(metrics).transpose())
    print("\n")

# Evaluate the models
import matplotlib.pyplot as plt

approaches = ['SMOTE', 'Random Undersampling', 'Class Weight Adjustment', 'Threshold Moving']
f1_scores = [results[approach]['weighted avg']['f1-score'] for approach in approaches]

plt.figure(figsize=(10, 6))
plt.bar(approaches, f1_scores, color=['blue', 'green', 'red', 'purple'])
plt.xlabel('Approaches')
plt.ylabel('F1-Score')
plt.title('Comparison of Approaches for Handling Imbalanced Data')
plt.show()






import numpy as np
import pandas as pd
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE
from sklearn.utils.class_weight import compute_class_weight
from xgboost import XGBClassifier
from sklearn.metrics import classification_report, precision_recall_curve

# Generate a synthetic dataset with class imbalance
X, y = make_classification(n_samples=1000, n_features=20, n_informative=2,
                           n_redundant=10, n_clusters_per_class=1, n_classes=10,
                           weights=[0.05]*9 + [0.55], flip_y=0, random_state=42)

# Split into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Apply SMOTE to oversample the minority classes
smote = SMOTE(random_state=42)
X_train_res, y_train_res = smote.fit_resample(X_train, y_train)

# Calculate class weights
class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train_res), y=y_train_res)
class_weights_dict = dict(enumerate(class_weights))

# Train an XGBoost classifier with class weights
classifier = XGBClassifier(scale_pos_weight=class_weights_dict)
classifier.fit(X_train_res, y_train_res)

# Predict probabilities
y_probs = classifier.predict_proba(X_test)

# Example of adjusting the threshold for one class (class 1)
precision, recall, thresholds = precision_recall_curve(y_test == 1, y_probs[:, 1])
f1_scores = 2 * (precision * recall) / (precision + recall)
best_threshold = thresholds[np.argmax(f1_scores)]

# Apply the best threshold
y_pred_adjusted = (y_probs[:, 1] >= best_threshold).astype(int)

# Evaluate the model
print("Classification Report with Adjusted Threshold:")
print(classification_report(y_test, y_pred_adjusted))

# Standard classification report for comparison
y_pred = classifier.predict(X_test)
print("Standard Classification Report:")
print(classification_report(y_test, y_pred))




from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE
from xgboost import XGBClassifier
from sklearn.metrics import classification_report

# Generate a synthetic imbalanced dataset
X, y = make_classification(n_samples=1000, n_features=20, n_informative=2,
                           n_redundant=10, n_clusters_per_class=1,
                           weights=[0.99], flip_y=0, random_state=42)

# Split the data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Apply SMOTE to oversample the minority class
smote = SMOTE(random_state=42)
X_train_res, y_train_res = smote.fit_resample(X_train, y_train)

# Train an XGBoost classifier with balanced class weights
classifier = XGBClassifier(scale_pos_weight=(len(y_train) - sum(y_train)) / sum(y_train))
classifier.fit(X_train_res, y_train_res)

# Evaluate the model
y_pred = classifier.predict(X_test)
print(classification_report(y_test, y_pred))






import xgboost as xgb
from sklearn.datasets import make_regression
from sklearn.model_selection import train_test_split
from xgboost import plot_importance
import matplotlib.pyplot as plt

# Generate a sample regression dataset
X, y = make_regression(n_samples=1000, n_features=10, random_state=42)

# Split the data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train an XGBoost regression model
regressor = xgb.XGBRegressor()
regressor.fit(X_train, y_train)

# Plot feature importance
plot_importance(regressor)
plt.title("Feature Importance for XGBoost Regression")
plt.show()

import xgboost as xgb
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from xgboost import plot_importance
import matplotlib.pyplot as plt

# Generate a sample classification dataset
X, y = make_classification(n_samples=1000, n_features=10, random_state=42)

# Split the data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train an XGBoost classification model
classifier = xgb.XGBClassifier()
classifier.fit(X_train, y_train)

# Plot feature importance
plot_importance(classifier)
plt.title("Feature Importance for XGBoost Classification")
plt.show()






import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestRegressor
from sklearn.datasets import make_regression

# Generate a sample dataset
X, y = make_regression(n_samples=100, n_features=5, noise=0.1, random_state=42)
feature_names = [f'feature_{i}' for i in range(X.shape[1])]
data = pd.DataFrame(X, columns=feature_names)
data['target'] = y

# Train a RandomForestRegressor
model = RandomForestRegressor(random_state=42)
model.fit(data[feature_names], data['target'])

# Get feature importances
feature_importances = model.feature_importances_

# Create a DataFrame for visualization
importance_df = pd.DataFrame({
    'Feature': feature_names,
    'Importance': feature_importances
}).sort_values(by='Importance', ascending=False)

# Plot feature importances
sns.barplot(x='Importance', y='Feature', data=importance_df)
plt.title('Feature Importance')
plt.show()





import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd

# Sample data
data = pd.DataFrame({
    'x': range(10),
    'y1': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],
    'y2': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11],
    'y3': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
})

# Convert data to long format
data_melted = pd.melt(data, ['x'])

# Plot with seaborn
sns.lineplot(data=data_melted, x='x', y='value', hue='variable')

# Show plot
plt.show()





import pandas as pd
import numpy as np
from sklearn.cluster import KMeans
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import confusion_matrix, f1_score, ConfusionMatrixDisplay
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from catboost import CatBoostClassifier
import matplotlib.pyplot as plt

# Sample DataFrame creation for demonstration
np.random.seed(0)
df = pd.DataFrame({
    'Age': np.random.randint(18, 70, size=100),
    'Income': np.random.uniform(30000, 100000, size=100),
    'Category1': np.random.choice(['A', 'B', 'C', np.nan], size=100),
    'Category2': np.random.choice(['X', 'Y', 'Z', np.nan], size=100),
    'Target': np.random.uniform(0, 100, size=100)
})

# Replace missing values with a new category "missing" and convert all to strings
df.fillna('missing', inplace=True)
df['Category1'] = df['Category1'].astype(str)
df['Category2'] = df['Category2'].astype(str)

# Encode categorical variables
label_encoders = {}
for col in df.select_dtypes(include=['object']).columns:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col])
    label_encoders[col] = le

# Apply k-means clustering to segment the target variable
optimal_clusters = 3  # Example: Adjust based on your previous result
kmeans = KMeans(n_clusters=optimal_clusters, random_state=0)
df['Cluster'] = kmeans.fit_predict(df[['Target']])

# Combine the columns for stratification
df['Stratify'] = df['Age'].astype(str) + '_' + df['Income'].round(0).astype(str) + '_' + df['Category1'].astype(str) + '_' + df['Category2'].astype(str)

# Perform the train-test split with stratification
train_df, test_df = train_test_split(df, test_size=0.2, random_state=0, stratify=df['Stratify'])

# Drop the stratification column from the train and test sets
train_df = train_df.drop(columns=['Stratify']).reset_index(drop=True)
test_df = test_df.drop(columns=['Stratify']).reset_index(drop=True)

# Prepare training and testing sets
X_train = train_df.drop(columns=['Target', 'Cluster'])
y_train = train_df['Cluster']
X_test = test_df.drop(columns=['Target', 'Cluster'])
y_test = test_df['Cluster']

# Define classifiers and their hyperparameters
classifiers = {
    'XGBoost': XGBClassifier(random_state=0, use_label_encoder=False, eval_metric='mlogloss'),
    'LightGBM': LGBMClassifier(random_state=0),
    'CatBoost': CatBoostClassifier(random_state=0, verbose=0)
}

param_grids = {
    'XGBoost': {'n_estimators': [50, 100], 'learning_rate': [0.01, 0.1], 'max_depth': [3, 5]},
    'LightGBM': {'n_estimators': [50, 100], 'learning_rate': [0.01, 0.1], 'num_leaves': [31, 50]},
    'CatBoost': {'iterations': [50, 100], 'learning_rate': [0.01, 0.1], 'depth': [3, 5]}
}

# Train, evaluate and plot results for each classifier
results = {}

for clf_name, clf in classifiers.items():
    print(f"Training {clf_name}...")
    grid_search = GridSearchCV(clf, param_grids[clf_name], cv=5, scoring='f1_macro', n_jobs=-1)
    grid_search.fit(X_train, y_train)
    best_clf = grid_search.best_estimator_
    y_pred = best_clf.predict(X_test)
    
    # Compute confusion matrix and F1 score
    conf_matrix = confusion_matrix(y_test, y_pred)
    f1 = f1_score(y_test, y_pred, average='macro')
    
    # Store results
    results[clf_name] = {
        'conf_matrix': conf_matrix,
        'f1_score': f1
    }
    
    # Plot confusion matrix
    disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=best_clf.classes_)
    disp.plot(cmap=plt.cm.Blues)
    plt.title(f'{clf_name} Confusion Matrix')
    plt.show()
    
    # Print F1 score
    print(f'{clf_name} F1 Score: {f1:.2f}')

# Plot F1 scores for all classifiers
f1_scores = {clf_name: res['f1_score'] for clf_name, res in results.items()}
plt.figure(figsize=(10, 6))
plt.bar(f1_scores.keys(), f1_scores.values())
plt.xlabel('Classifier')
plt.ylabel('F1 Score')
plt.title('F1 Scores for Different Classifiers')
plt.show()






import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split

# Sample DataFrame creation for demonstration
np.random.seed(0)
df = pd.DataFrame({
    'Age': np.random.randint(18, 70, size=100),
    'Income': np.random.uniform(30000, 100000, size=100),
    'Category1': np.random.choice(['A', 'B', 'C', np.nan], size=100),
    'Category2': np.random.choice(['X', 'Y', 'Z', np.nan], size=100),
    'Target': np.random.uniform(0, 100, size=100)
})

# Replace missing values with a new category "missing" and convert all to strings
df.fillna('missing', inplace=True)
df['Category1'] = df['Category1'].astype(str)
df['Category2'] = df['Category2'].astype(str)

# Encode categorical variables
label_encoders = {}
for col in df.select_dtypes(include=['object']).columns:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col])
    label_encoders[col] = le

# Combine the columns for stratification
df['Stratify'] = df['Age'].astype(str) + '_' + df['Income'].round(0).astype(str) + '_' + df['Category1'].astype(str) + '_' + df['Category2'].astype(str)

# Perform the train-test split with stratification
train_df, test_df = train_test_split(df, test_size=0.2, random_state=0, stratify=df['Stratify'])

# Drop the stratification column from the train and test sets
train_df = train_df.drop(columns=['Stratify']).reset_index(drop=True)
test_df = test_df.drop(columns=['Stratify']).reset_index(drop=True)

# Check the distribution
print("Training set distribution:\n", train_df['Stratify'].value_counts(normalize=True))
print("\nTesting set distribution:\n", test_df['Stratify'].value_counts(normalize=True))

# Proceed with your further code (clustering, modeling, etc.)





import pandas as pd
import numpy as np
from sklearn.cluster import KMeans
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import r2_score
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression, Ridge, Lasso, HuberRegressor
import matplotlib.pyplot as plt
from sklearn.mixture import GaussianMixture
from sklearn.metrics import silhouette_score

# Sample DataFrame creation for demonstration
np.random.seed(0)
df = pd.DataFrame({
    'Age': np.random.randint(18, 70, size=100),
    'Income': np.random.uniform(30000, 100000, size=100),
    'Category1': np.random.choice(['A', 'B', 'C', np.nan], size=100),
    'Category2': np.random.choice(['X', 'Y', 'Z', np.nan], size=100),
    'Target': np.random.uniform(0, 100, size=100)
})

# Replace missing values with a new category "missing" and convert all to strings
df.fillna('missing', inplace=True)
df['Category1'] = df['Category1'].astype(str)
df['Category2'] = df['Category2'].astype(str)

# Encode categorical variables
label_encoders = {}
for col in df.select_dtypes(include=['object']).columns:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col])
    label_encoders[col] = le

# Plot AIC and BIC for different number of clusters
n_clusters = range(1, 11)
aic_values = []
bic_values = []
silhouette_scores = []

for n in n_clusters:
    gmm = GaussianMixture(n_components=n, random_state=0)
    gmm.fit(df[['Target']])
    aic_values.append(gmm.aic(df[['Target']]))
    bic_values.append(gmm.bic(df[['Target']]))
    if n > 1:
        silhouette_scores.append(silhouette_score(df[['Target']], gmm.predict(df[['Target']])))

plt.figure(figsize=(12, 6))
plt.plot(n_clusters, aic_values, label='AIC')
plt.plot(n_clusters, bic_values, label='BIC')
plt.xlabel('Number of clusters')
plt.ylabel('Score')
plt.title('AIC and BIC for different number of clusters')
plt.legend()
plt.show()

plt.figure(figsize=(12, 6))
plt.plot(n_clusters[1:], silhouette_scores, label='Silhouette Score')
plt.xlabel('Number of clusters')
plt.ylabel('Score')
plt.title('Silhouette Score for different number of clusters')
plt.legend()
plt.show()

# Choose the optimal number of clusters based on BIC (you can also choose based on AIC or silhouette score)
optimal_clusters = np.argmin(bic_values) + 1
print(f'Optimal number of clusters: {optimal_clusters}')

# Apply k-means clustering to segment the target variable
kmeans = KMeans(n_clusters=optimal_clusters, random_state=0)
df['Cluster'] = kmeans.fit_predict(df[['Target']])

# Separate data into clusters based on k-means clustering
clusters = [df[df['Cluster'] == i] for i in range(optimal_clusters)]

# Calculate and display intervals for each cluster
intervals = []
for cluster_id, cluster in enumerate(clusters):
    min_value = cluster['Target'].min()
    max_value = cluster['Target'].max()
    intervals.append((min_value, max_value))

# Sort intervals to ensure they are in order
intervals.sort()

# Adjust intervals to ensure no gaps
adjusted_intervals = []
for i, (min_value, max_value) in enumerate(intervals):
    if i == 0:
        adjusted_intervals.append((min_value, max_value))
    else:
        previous_max = adjusted_intervals[-1][1]
        adjusted_intervals.append((previous_max, max_value))

# Print adjusted intervals
for i, (min_value, max_value) in enumerate(adjusted_intervals):
    print(f'Cluster {i}: {min_value:.2f} to {max_value:.2f}')

# Define models to train
models = {
    'RandomForest': RandomForestRegressor(random_state=0),
    'LinearRegression': LinearRegression(),
    'Ridge': Ridge(),
    'Lasso': Lasso(),
    'Huber': HuberRegressor()
}

param_grid = {
    'RandomForest': {'n_estimators': [50, 100], 'max_depth': [3, 5]},
    'Ridge': {'alpha': [0.01, 0.1, 1]},
    'Lasso': {'alpha': [0.01, 0.1, 1]},
    'Huber': {'epsilon': [1.35, 1.5]}
}

# Function to train and evaluate models
def train_evaluate_models(X_train, X_test, y_train, y_test, model, param_grid):
    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='r2', n_jobs=-1)
    grid_search.fit(X_train, y_train)
    best_model = grid_search.best_estimator_
    y_pred = best_model.predict(X_test)
    r2 = r2_score(y_test, y_pred)
    return r2

# Train and evaluate models for each cluster
results = {}
for cluster_id, cluster in enumerate(clusters):
    X = cluster.drop(columns=['Target', 'Cluster'])
    y = cluster['Target']
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)
    cluster_results = {}
    for model_name, model in models.items():
        r2 = train_evaluate_models(X_train, X_test, y_train, y_test, model, param_grid.get(model_name, {}))
        cluster_results[model_name] = r2
    results[f'Cluster {cluster_id}'] = cluster_results

# Display results
results_df = pd.DataFrame(results).T
print(results_df)

# Plot R² scores for each model across different clusters
results_df.plot(kind='bar', figsize=(12, 6))
plt.xlabel('Cluster')
plt.ylabel('R² Score')
plt.title('R² Scores for Different Models across Clusters')
plt.legend()
plt.show()











import xgboost as xgb
from sklearn.metrics import r2_score
import itertools

# Define the parameter grid
etas = [0.01, 0.1, 0.3]
max_depths = [2, 4, 6]
subsamples = [0.8, 1.0]
colsample_bytree = [1.0, 0.8]

# List to store results
results = []

# Iterate over all parameter combinations
for eta, max_depth, subsample, colsample in itertools.product(etas, max_depths, subsamples, colsample_bytree):
    xgb_params = {
        'eta': eta,
        'max_depth': max_depth,
        'subsample': subsample,
        'colsample_bytree': colsample,
        'objective': 'reg:squarederror',
        'seed': 1989
    }
    
    xgb_cv = xgb.cv(
        params=xgb_params,
        dtrain=train_xgb,
        num_boost_round=10000,
        nfold=5,
        early_stopping_rounds=10,
        verbose_eval=0
    )
    
    # Extract the best number of boosting rounds
    best_num_boost_rounds = len(xgb_cv['train-rmse-mean'])
    
    # Train the model with the best number of boosting rounds
    model = xgb.train(
        params=xgb_params,
        dtrain=train_xgb,
        num_boost_round=best_num_boost_rounds
    )
    
    # Make predictions
    y_pred = model.predict(test_xgb)
    
    # Evaluate using R2 score
    r2 = r2_score(y_test, y_pred)
    
    # Store the results
    results.append({
        'eta': eta,
        'max_depth': max_depth,
        'subsample': subsample,
        'colsample_bytree': colsample,
        'best_num_boost_rounds': best_num_boost_rounds,
        'r2': r2
    })

# Find the best result
best_result = max(results, key=lambda x: x['r2'])

# Print the best parameters and corresponding R2 score
print("Best parameters found: ", best_result)
print("Best R2 score: ", best_result['r2'])











import pandas as pd
import numpy as np
from sklearn.cluster import KMeans
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import r2_score
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression, Ridge, Lasso, HuberRegressor
import matplotlib.pyplot as plt
from sklearn.mixture import GaussianMixture
from sklearn.metrics import silhouette_score

# Sample DataFrame creation for demonstration
np.random.seed(0)
df = pd.DataFrame({
    'Age': np.random.randint(18, 70, size=100),
    'Income': np.random.uniform(30000, 100000, size=100),
    'Category1': np.random.choice(['A', 'B', 'C', np.nan], size=100),
    'Category2': np.random.choice(['X', 'Y', 'Z', np.nan], size=100),
    'Target': np.random.uniform(0, 100, size=100)
})

# Replace missing values with a new category "missing" and convert all to strings
df.fillna('missing', inplace=True)
df['Category1'] = df['Category1'].astype(str)
df['Category2'] = df['Category2'].astype(str)

# Encode categorical variables
label_encoders = {}
for col in df.select_dtypes(include=['object']).columns:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col])
    label_encoders[col] = le

# Plot AIC and BIC for different number of clusters
n_clusters = range(1, 11)
aic_values = []
bic_values = []
silhouette_scores = []

for n in n_clusters:
    gmm = GaussianMixture(n_components=n, random_state=0)
    gmm.fit(df[['Target']])
    aic_values.append(gmm.aic(df[['Target']]))
    bic_values.append(gmm.bic(df[['Target']]))
    if n > 1:
        silhouette_scores.append(silhouette_score(df[['Target']], gmm.predict(df[['Target']])))

plt.figure(figsize=(12, 6))
plt.plot(n_clusters, aic_values, label='AIC')
plt.plot(n_clusters, bic_values, label='BIC')
plt.xlabel('Number of clusters')
plt.ylabel('Score')
plt.title('AIC and BIC for different number of clusters')
plt.legend()
plt.show()

plt.figure(figsize=(12, 6))
plt.plot(n_clusters[1:], silhouette_scores, label='Silhouette Score')
plt.xlabel('Number of clusters')
plt.ylabel('Score')
plt.title('Silhouette Score for different number of clusters')
plt.legend()
plt.show()

# Choose the optimal number of clusters based on BIC (you can also choose based on AIC or silhouette score)
optimal_clusters = np.argmin(bic_values) + 1
print(f'Optimal number of clusters: {optimal_clusters}')

# Apply k-means clustering to segment the target variable
kmeans = KMeans(n_clusters=optimal_clusters, random_state=0)
df['Cluster'] = kmeans.fit_predict(df[['Target']])

# Separate data into clusters based on k-means clustering
clusters = [df[df['Cluster'] == i] for i in range(optimal_clusters)]

# Calculate and display intervals for each cluster
intervals = {}
for cluster_id, cluster in enumerate(clusters):
    min_value = cluster['Target'].min()
    max_value = cluster['Target'].max()
    intervals[f'Cluster {cluster_id}'] = (min_value, max_value)
    print(f'Cluster {cluster_id}: {min_value:.2f} to {max_value:.2f}')

# Define models to train
models = {
    'RandomForest': RandomForestRegressor(random_state=0),
    'LinearRegression': LinearRegression(),
    'Ridge': Ridge(),
    'Lasso': Lasso(),
    'Huber': HuberRegressor()
}

param_grid = {
    'RandomForest': {'n_estimators': [50, 100], 'max_depth': [3, 5]},
    'Ridge': {'alpha': [0.01, 0.1, 1]},
    'Lasso': {'alpha': [0.01, 0.1, 1]},
    'Huber': {'epsilon': [1.35, 1.5]}
}

# Function to train and evaluate models
def train_evaluate_models(X_train, X_test, y_train, y_test, model, param_grid):
    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='r2', n_jobs=-1)
    grid_search.fit(X_train, y_train)
    best_model = grid_search.best_estimator_
    y_pred = best_model.predict(X_test)
    r2 = r2_score(y_test, y_pred)
    return r2

# Train and evaluate models for each cluster
results = {}
for cluster_id, cluster in enumerate(clusters):
    X = cluster.drop(columns=['Target', 'Cluster'])
    y = cluster['Target']
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)
    cluster_results = {}
    for model_name, model in models.items():
        r2 = train_evaluate_models(X_train, X_test, y_train, y_test, model, param_grid.get(model_name, {}))
        cluster_results[model_name] = r2
    results[f'Cluster {cluster_id}'] = cluster_results

# Display results
results_df = pd.DataFrame(results).T
print(results_df)

# Plot R² scores for each model across different clusters
results_df.plot(kind='bar', figsize=(12, 6))
plt.xlabel('Cluster')
plt.ylabel('R² Score')
plt.title('R² Scores for Different Models across Clusters')
plt.legend()
plt.show()














import pandas as pd
import numpy as np

# Load your dataset
# Replace 'your_dataset.csv' with the path to your dataset and 'target' with the target variable name
df = pd.read_csv('your_dataset.csv')

# Define the target variable
target = 'your_target_variable'

# Calculate the IQR (Interquartile Range) to identify outliers
Q1 = df[target].quantile(0.25)
Q3 = df[target].quantile(0.75)
IQR = Q3 - Q1

# Define the bounds for identifying outliers
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# Create the first dataset with outliers and negative target values
outliers_negative = df[(df[target] < lower_bound) | (df[target] > upper_bound) | (df[target] < 0)]

# Create the second dataset with the rest
non_outliers = df[~((df[target] < lower_bound) | (df[target] > upper_bound) | (df[target] < 0))]

# Save the datasets to CSV files (optional)
outliers_negative.to_csv('outliers_negative.csv', index=False)
non_outliers.to_csv('non_outliers.csv', index=False)

# Display the datasets
print("Outliers and Negative Target Values Dataset")
print(outliers_negative.head())

print("\nNon-Outliers Dataset")
print(non_outliers.head())



import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import mean_squared_error, r2_score
import xgboost as xgb

# Sample DataFrame creation for demonstration
np.random.seed(0)
df = pd.DataFrame({
    'Feature': np.random.randn(100) * 20,
    'Target': np.random.uniform(0, 100, size=100)
})

# Split the data into features and target
X = df[['Feature']]
y = df['Target']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# Define parameter grid for XGBoost
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [3, 5, 7],
    'learning_rate': [0.01, 0.1, 0.3],
    'min_child_weight': [1, 5, 10]
}

# Initialize and train XGBoost model with GridSearchCV
xgb_reg = xgb.XGBRegressor(objective='reg:squarederror', random_state=0)
grid_search = GridSearchCV(estimator=xgb_reg, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1, return_train_score=True)
grid_search.fit(X_train, y_train)

# Get the best model
best_model = grid_search.best_estimator_

# Predict and evaluate the best model
y_train_pred = best_model.predict(X_train)
y_test_pred = best_model.predict(X_test)

mse_train = mean_squared_error(y_train, y_train_pred)
mse_test = mean_squared_error(y_test, y_test_pred)
r2_train = r2_score(y_train, y_train_pred)
r2_test = r2_score(y_test, y_test_pred)

print(f'Best Parameters: {grid_search.best_params_}')
print(f'XGBoost - MSE Train: {mse_train}, MSE Test: {mse_test}, R^2 Train: {r2_train}, R^2 Test: {r2_test}')

# Plotting train vs test results
plt.figure(figsize=(14, 6))

plt.subplot(1, 2, 1)
plt.scatter(y_train, y_train_pred, alpha=0.5)
plt.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], '--r')
plt.xlabel('Actual Values (Train)')
plt.ylabel('Predicted Values (Train)')
plt.title('XGBoost - Train')

plt.subplot(1, 2, 2)
plt.scatter(y_test, y_test_pred, alpha=0.5)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], '--r')
plt.xlabel('Actual Values (Test)')
plt.ylabel('Predicted Values (Test)')
plt.title('XGBoost - Test')

plt.suptitle('Actual vs Predicted Values (XGBoost)')
plt.show()

# Display results in a dataframe
results = {
    'MSE Train': mse_train,
    'MSE Test': mse_test,
    'R^2 Train': r2_train,
    'R^2 Test': r2_test
}
results_df = pd.DataFrame([results])
print(results_df)














import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import mean_squared_error, r2_score
import xgboost as xgb

# Sample DataFrame creation for demonstration
np.random.seed(0)
df = pd.DataFrame({
    'Feature': np.random.randn(100) * 20,
    'Target': np.random.uniform(0, 100, size=100)
})

# Split the data into features and target
X = df[['Feature']]
y = df['Target']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# Define parameter grid for XGBoost
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [3, 5, 7],
    'learning_rate': [0.01, 0.1, 0.3],
    'min_child_weight': [1, 5, 10]
}

# Initialize and train XGBoost model with GridSearchCV
xgb_reg = xgb.XGBRegressor(objective='reg:squarederror', random_state=0)
grid_search = GridSearchCV(estimator=xgb_reg, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1, return_train_score=True)
grid_search.fit(X_train, y_train)

# Get the results in a DataFrame
results = pd.DataFrame(grid_search.cv_results_)

# Calculate RMSE for train and test sets
results['mean_train_rmse'] = np.sqrt(-results['mean_train_score'])
results['mean_test_rmse'] = np.sqrt(-results['mean_test_score'])

# Plot R² scores
plt.figure(figsize=(14, 6))

plt.subplot(1, 2, 1)
for learning_rate in param_grid['learning_rate']:
    subset = results[results.param_learning_rate == learning_rate]
    plt.plot(subset['param_n_estimators'], subset['mean_train_score'], label=f'Train - lr={learning_rate}')
    plt.plot(subset['param_n_estimators'], subset['mean_test_score'], linestyle='--', label=f'Test - lr={learning_rate}')
plt.xlabel('Number of Estimators')
plt.ylabel('Neg MSE')
plt.title('Neg MSE vs Number of Estimators')
plt.legend()

# Plot RMSE scores
plt.subplot(1, 2, 2)
for learning_rate in param_grid['learning_rate']:
    subset = results[results.param_learning_rate == learning_rate]
    plt.plot(subset['param_n_estimators'], subset['mean_train_rmse'], label=f'Train - lr={learning_rate}')
    plt.plot(subset['param_n_estimators'], subset['mean_test_rmse'], linestyle='--', label=f'Test - lr={learning_rate}')
plt.xlabel('Number of Estimators')
plt.ylabel('RMSE')
plt.title('RMSE vs Number of Estimators')
plt.legend()

plt.tight_layout()
plt.show()

# Print the best parameters
print("Best Parameters:", grid_search.best_params_)
print("Best R² Score:", grid_search.best_score_)








import xgboost as xgb
from sklearn.model_selection import GridSearchCV, train_test_split
from sklearn.metrics import r2_score, make_scorer
import pandas as pd
import matplotlib.pyplot as plt

# Sample data preparation (assuming you have your dataset as X and y)
# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Define XGBoost regressor
xgb_reg = xgb.XGBRegressor()

# Define parameter grid
param_grid = {
    'eta': [0.01, 0.02, 0.03],
    'max_depth': [3, 5, 7],
    'n_estimators': [100, 200, 300]
}

# Define R^2 scorer
r2_scorer = make_scorer(r2_score)

# Perform GridSearchCV
grid_search = GridSearchCV(estimator=xgb_reg, param_grid=param_grid, scoring=r2_scorer, cv=5, return_train_score=True)
grid_search.fit(X_train, y_train)

# Extract results
results = pd.DataFrame(grid_search.cv_results_)

# Plotting the evolution of R^2
plt.figure(figsize=(14, 7))

plt.plot(results['param_eta'], results['mean_train_score'], label='Train R^2')
plt.plot(results['param_eta'], results['mean_test_score'], label='Test R^2')

plt.xlabel('Learning Rate (eta)')
plt.ylabel('R^2 Score')
plt.title('Evolution of R^2 for different Learning Rates')
plt.legend()
plt.grid(True)
plt.show()






import xgboost as xgb
import pandas as pd
from sklearn.metrics import r2_score

# Define XGBoost parameters
xgb_para = {
    'eta': 0.02,
    'booster': 'gbtree',
    'max_depth': 10
}

# Perform cross-validation
xgb_cv = xgb.cv(
    params=xgb_para,
    dtrain=train_xgb,
    num_boost_round=500,
    nfold=5,
    metrics={'rmse'},  # RMSE is used for early stopping
    as_pandas=True,
    seed=42
)

# Extract the train and test predictions from the cross-validation
train_predictions = xgb_cv['train-rmse-mean']
test_predictions = xgb_cv['test-rmse-mean']

# Calculate R^2 for train and test
train_r2 = [r2_score(train_xgb.get_label(), train_predictions)]
test_r2 = [r2_score(test_xgb.get_label(), test_predictions)]

# Convert R^2 scores to a DataFrame for plotting
r2_df = pd.DataFrame({
    'train-r2': train_r2,
    'test-r2': test_r2
})

# Plot R^2 scores
r2_df.plot()










import xgboost as xgb
from sklearn.model_selection import GridSearchCV
import pandas as pd

# Define the parameter grid
param_grid = {
    'eta': [0.01, 0.02, 0.1],
    'booster': ['gbtree', 'gblinear'],
    'max_depth': [6, 10, 15]
}

# Convert your training data to DMatrix format
dtrain = xgb.DMatrix(data=train_data, label=train_labels)

# Define the model
xgb_model = xgb.XGBRegressor()

# Perform the grid search
grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=3, scoring='neg_mean_squared_error', verbose=1)

# Fit the grid search
grid_search.fit(train_data, train_labels)

# Get the results
cv_results = pd.DataFrame(grid_search.cv_results_)

# Print the best parameters
print("Best parameters:", grid_search.best_params_)

# Plot the results
cv_results[['mean_test_score', 'std_test_score']].plot()
















Rapport sur la Valeur de R² et son Interprétation Statistique
Introduction
La valeur de R², ou coefficient de détermination, est souvent mal comprise. En particulier, beaucoup de gens pensent que R² ne peut être qu'entre 0 et 1. Cependant, il peut être négatif dans certains cas. Ce rapport explique pourquoi et comment cela peut se produire, avec une explication détaillée des calculs de R² et une illustration pratique.

Calcul de R²
Pour comprendre pourquoi R² peut être négatif, nous devons examiner comment il est calculé. Nous utilisons trois variables clés dans ce calcul : RSS (Residual Sum of Squares), TSS (Total Sum of Squares), et ESS (Explained Sum of Squares).

Calcul de RSS :
Pour chaque variable indépendante 
𝑥
x, nous avons une variable dépendante 
𝑦
y. Nous traçons une ligne de régression linéaire qui prédit les valeurs de 
𝑦
y pour chaque valeur de 
𝑥
x. Appelons les valeurs prédites 
𝑦
^
y
^
​
 . L'erreur entre ce que la ligne prédit et les valeurs réelles de 
𝑦
y est calculée par soustraction. Toutes ces différences sont mises au carré et additionnées, ce qui donne la somme des carrés des résidus, RSS.

𝑅
𝑆
𝑆
=
∑
(
𝑦
−
𝑦
^
)
2
RSS=∑(y− 
y
^
​
 ) 
2
 
Calcul de TSS :
Nous pouvons calculer la valeur moyenne de 
𝑦
y, appelée 
𝑦
ˉ
y
ˉ
​
 . Si nous traçons 
𝑦
ˉ
y
ˉ
​
 , c'est simplement une ligne horizontale à travers les données. En soustrayant 
𝑦
ˉ
y
ˉ
​
  de chaque valeur réelle de 
𝑦
y, nous obtenons la somme totale des carrés, TSS.

𝑇
𝑆
𝑆
=
∑
(
𝑦
−
𝑦
ˉ
)
2
TSS=∑(y− 
y
ˉ
​
 ) 
2
 
Calcul de ESS :
Les différences entre les valeurs prédites 
𝑦
^
y
^
​
  et la valeur moyenne 
𝑦
ˉ
y
ˉ
​
  sont mises au carré et additionnées. Ceci est la somme expliquée des carrés, ESS.

𝐸
𝑆
𝑆
=
∑
(
𝑦
^
−
𝑦
ˉ
)
2
ESS=∑( 
y
^
​
 − 
y
ˉ
​
 ) 
2
 
Relation entre TSS, RSS et ESS
Lorsque nous avons une ligne de régression avec une interception, la relation suivante est toujours vraie :

𝑇
𝑆
𝑆
=
𝑅
𝑆
𝑆
+
𝐸
𝑆
𝑆
TSS=RSS+ESS
En divisant tous les termes par TSS et en réarrangeant, nous obtenons :

𝑅
2
=
1
−
𝑅
𝑆
𝑆
𝑇
𝑆
𝑆
R 
2
 =1− 
TSS
RSS
​
 
Dans ce cas, R² est toujours positif.

Cas où R² peut être négatif
Cependant, sans interception, la relation ci-dessus change. La formule devient :

𝑇
𝑆
𝑆
=
𝑅
𝑆
𝑆
+
𝐸
𝑆
𝑆
+
2
∑
(
𝑦
−
𝑦
^
)
(
𝑦
^
−
𝑦
ˉ
)
TSS=RSS+ESS+2∑(y− 
y
^
​
 )( 
y
^
​
 − 
y
ˉ
​
 )
En divisant tous les termes par TSS, nous obtenons :

𝑅
2
=
𝐸
𝑆
𝑆
+
2
∑
(
𝑦
−
𝑦
^
)
(
𝑦
^
−
𝑦
ˉ
)
𝑇
𝑆
𝑆
R 
2
 = 
TSS
ESS+2∑(y− 
y
^
​
 )( 
y
^
​
 − 
y
ˉ
​
 )
​
 
Le terme supplémentaire peut rendre le numérateur négatif, ce qui fait que R² peut être négatif. Cela se produit lorsque la ligne horizontale 
𝑦
ˉ
y
ˉ
​
  explique mieux les données que la ligne de régression.

Quand le terme 
2
∑
(
𝑦
−
𝑦
^
)
(
𝑦
^
−
𝑦
ˉ
)
2∑(y− 
y
^
​
 )( 
y
^
​
 − 
y
ˉ
​
 ) est nul ou non nul
Nul : Ce terme est nul lorsque la ligne de régression passe par le point moyen des données 
(
𝑥
ˉ
,
𝑦
ˉ
)
( 
x
ˉ
 , 
y
ˉ
​
 ), ce qui se produit lorsque le modèle inclut une interception. Dans ce cas, les erreurs 
(
𝑦
−
𝑦
^
)
(y− 
y
^
​
 ) et les différences 
(
𝑦
^
−
𝑦
ˉ
)
( 
y
^
​
 − 
y
ˉ
​
 ) sont orthogonales, ce qui signifie que leur produit est en moyenne nul.
Non nul : Ce terme n'est pas nécessairement nul lorsque la régression ne comprend pas d'interception. Dans ce cas, la ligne de régression peut ne pas passer par le point moyen des données, et les erreurs et les différences peuvent avoir une covariance non nulle, conduisant ainsi à un terme supplémentaire qui peut être positif ou négatif.
Exemple Simple
Considérons un exemple simple pour illustrer ce concept. Supposons que nous ayons les données suivantes :

x	y
1	1
2	2
3	1.3
4	3.75
5	2.25
Calculons la régression linéaire avec et sans interception :

Régression avec interception :
La ligne de régression a une interception et la formule obtenue est :

𝑦
^
=
0.425
+
0.475
𝑥
y
^
​
 =0.425+0.475x
Régression sans interception :
La ligne de régression passe par l'origine (sans interception) et la formule obtenue est :

𝑦
^
=
0.63
𝑥
y
^
​
 =0.63x
La moyenne des 
𝑦
y est 
𝑦
ˉ
=
2.06
y
ˉ
​
 =2.06.

En traçant les lignes de régression et la moyenne de 
𝑦
y sur un graphique, nous observons que la ligne de régression sans interception ne passe pas par la moyenne des données, ce qui peut rendre le terme 
2
∑
(
𝑦
−
𝑦
^
)
(
𝑦
^
−
𝑦
ˉ
)
2∑(y− 
y
^
​
 )( 
y
^
​
 − 
y
ˉ
​
 ) non nul et potentiellement négatif, rendant ainsi 
𝑅
2
R 
2
  négatif.

Conclusion
La valeur de R² peut être négative si le modèle de régression n'a pas d'interception et s'adapte très mal aux données. Dans ce cas, une ligne horizontale pourrait fournir une meilleure explication des variations dans les données que le modèle lui-même. Comprendre cette nuance est crucial pour une interprétation correcte des résultats de régression linéaire.

Visualisation avec Matplotlib
Voici un code Python qui illustre cet exemple :

python
Copy code
import matplotlib.pyplot as plt
import numpy as np

# Données simples
x = np.array([1, 2, 3, 4, 5])
y = np.array([1, 2, 1.3, 3.75, 2.25])

# Calcul de la régression linéaire avec interception
coeffs_with_intercept = np.polyfit(x, y, 1)
y_hat_with_intercept = np.polyval(coeffs_with_intercept, x)

# Calcul de la régression linéaire sans interception
coeffs_without_intercept = np.polyfit(x, y, 1, full=True)[0]
y_hat_without_intercept = np.polyval([coeffs_without_intercept[0]], x)

# Calcul de la moyenne de y
y_bar = np.mean(y)

# Visualisation des données et des lignes de régression
plt.scatter(x, y, label='Données')
plt.plot(x, y_hat_with_intercept, label='Régression avec interception', color='green')
plt.plot(x, y_hat_without_intercept, label='Régression sans interception', color='red')
plt.axhline(y=y_bar, color='blue', linestyle='--', label='Moyenne de y')

plt.xlabel('x')
plt.ylabel('y')
plt.legend()
plt.title('Régression Linéaire avec et sans Interception')
plt.show()
Ce graphique montre les données avec deux lignes de régression : une avec interception (en vert) et une sans interception (en rouge), ainsi qu'une ligne horizontale représentant la moyenne de 
𝑦
y (en bleu). La ligne rouge ne passe pas par le point moyen des données, ce qui explique pourquoi 
𝑅
2
R 
2
  peut être négatif dans ce cas.





import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score

# Generate data that follows the line y = x
np.random.seed(0)
X = np.linspace(-10, 10, 100).reshape(-1, 1)
y = X.flatten()  # y = x

# Fit a linear regression model with the equation y = -x
model = LinearRegression()
model.fit(X, -X)  # The model is trained with y = -x

# Predict using the fitted model
y_pred = model.predict(X)

# Compute R^2 value
r2 = r2_score(y, y_pred)

# Plot the results
plt.figure(figsize=(10, 6))
plt.scatter(X, y, color='black', label='Data: y = x')
plt.plot(X, y_pred, color='red', linewidth=2, label='Model: y = -x')
plt.xlabel('X')
plt.ylabel('Y')
plt.title(f'Linear Regression with y = -x\nR² = {r2:.2f}')
plt.legend()
plt.grid(True)
plt.show()

print(f"R²: {r2:.2f}")












import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score

# Generate non-linear data
np.random.seed(0)
X = np.sort(5 * np.random.rand(80, 1), axis=0)
y = np.sin(X).ravel() + np.random.randn(80) * 0.5

# Fit linear model
model = LinearRegression()
model.fit(X, y)
y_pred = model.predict(X)

# Calculate R^2
r2 = r2_score(y, y_pred)
print(f"R^2: {r2}")

# Plot
plt.scatter(X, y, color='black')
plt.plot(X, y_pred, color='blue', linewidth=3)
plt.title(f'Linear Regression on Non-linear Data\nR^2 = {r2:.2f}')
plt.show()


from sklearn.model_selection import train_test_split

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# Fit model on training data
model.fit(X_train, y_train)
y_test_pred = model.predict(X_test)

# Calculate R^2 on test data
r2_test = r2_score(y_test, y_test_pred)
print(f"R^2 on test data: {r2_test}")
















import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.ensemble import IsolationForest
from sklearn.model_selection import train_test_split, GridSearchCV
import xgboost as xgb
from sklearn.metrics import mean_squared_error, r2_score

# Sample DataFrame creation for demonstration
np.random.seed(0)
df = pd.DataFrame({
    'Value': np.random.randn(100) * 20  # Generating a dataset with potential outliers
})

# Introduce extreme outliers
df.loc[::10, 'Value'] = df['Value'] * 100

# Function to apply Isolation Forest and adjust outliers
def apply_isolation_forest(df, contamination, n_estimators):
    iso_forest = IsolationForest(contamination=contamination, n_estimators=n_estimators, random_state=0)
    df['Outlier'] = iso_forest.fit_predict(df[['Value']])
    df['Outlier'] = df['Outlier'].apply(lambda x: 'Outlier' if x == -1 else 'Inlier')
    return df

# Apply Isolation Forest
contamination = 0.1
n_estimators = 100
df = apply_isolation_forest(df, contamination, n_estimators)

# Calculate the replacement values
quantiles = df[df['Outlier'] == 'Inlier']['Value'].quantile([0.05, 0.1, 0.6, 0.7, 0.8, 0.9])
mean_value = df[df['Outlier'] == 'Inlier']['Value'].mean()

# Replace outliers based on specified rules
def replace_outliers(row, quantiles, mean_value):
    noise = np.random.normal(0, 1)
    if row['Outlier'] == 'Outlier':
        if row['Value'] > mean_value:
            if row['Value'] > quantiles[0.9]:
                return quantiles[0.7] + noise
            elif row['Value'] > quantiles[0.8]:
                return quantiles[0.6] + noise
        else:
            return quantiles[0.1] + noise if row['Value'] < quantiles[0.05] else quantiles[0.05] + noise
    else:
        return row['Value']

df['Adjusted'] = df.apply(lambda row: replace_outliers(row, quantiles, mean_value), axis=1)

# Plot original data with outliers highlighted
plt.figure(figsize=(12, 8))
sns.scatterplot(data=df, x=range(len(df)), y='Value', hue='Outlier', palette='tab10', legend='full')
plt.title('Isolation Forest Outlier Detection')
plt.xlabel('Index')
plt.ylabel('Value')
plt.show()

# Plot original and adjusted data distributions
plt.figure(figsize=(12, 8))
sns.displot(df, x='Value', hue='Outlier', kind='kde', fill=True, height=5, aspect=2)
plt.title('Original Data with Outliers Highlighted')

sns.displot(df, x='Adjusted', kind='kde', fill=True, height=5, aspect=2)
plt.title('Data after Outlier Adjustment')

plt.show()

# Show the impact of adjusting outliers
print("Original Data:")
print(df['Value'].describe())
print("\nAdjusted Data:")
print(df['Adjusted'].describe())

# Split the data into features and target
X = df[['Value']]
y = df['Adjusted']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# Define parameter grid for XGBoost
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [3, 5, 7],
    'learning_rate': [0.01, 0.1, 0.3],
    'min_child_weight': [1, 5, 10]
}

# Initialize and train XGBoost model with GridSearchCV
xgb_reg = xgb.XGBRegressor(objective='reg:squarederror', random_state=0)
grid_search = GridSearchCV(estimator=xgb_reg, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)
grid_search.fit(X_train, y_train)

# Get the best model
best_model = grid_search.best_estimator_

# Predict and evaluate the best model
y_train_pred = best_model.predict(X_train)
y_test_pred = best_model.predict(X_test)

mse_train = mean_squared_error(y_train, y_train_pred)
mse_test = mean_squared_error(y_test, y_test_pred)
r2_train = r2_score(y_train, y_train_pred)
r2_test = r2_score(y_test, y_test_pred)

print(f'Best Parameters: {grid_search.best_params_}')
print(f'XGBoost - MSE Train: {mse_train}, MSE Test: {mse_test}, R^2 Train: {r2_train}, R^2 Test: {r2_test}')

# Plotting train vs test results
plt.figure(figsize=(14, 6))

plt.subplot(1, 2, 1)
plt.scatter(y_train, y_train_pred, alpha=0.5)
plt.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], '--r')
plt.xlabel('Actual Values (Train)')
plt.ylabel('Predicted Values (Train)')
plt.title('XGBoost - Train')

plt.subplot(1, 2, 2)
plt.scatter(y_test, y_test_pred, alpha=0.5)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], '--r')
plt.xlabel('Actual Values (Test)')
plt.ylabel('Predicted Values (Test)')
plt.title('XGBoost - Test')

plt.suptitle('Actual vs Predicted Values (XGBoost)')
plt.show()









import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.ensemble import IsolationForest
from sklearn.model_selection import train_test_split, GridSearchCV
import xgboost as xgb
from sklearn.metrics import mean_squared_error, r2_score

# Sample DataFrame creation for demonstration
np.random.seed(0)
df = pd.DataFrame({
    'Value': np.random.randn(100) * 20  # Generating a dataset with potential outliers
})

# Introduce extreme outliers
df.loc[::10, 'Value'] = df['Value'] * 100

# Function to apply Isolation Forest and adjust outliers
def apply_isolation_forest(df, contamination, n_estimators):
    iso_forest = IsolationForest(contamination=contamination, n_estimators=n_estimators, random_state=0)
    df['Outlier'] = iso_forest.fit_predict(df[['Value']])
    df['Outlier'] = df['Outlier'].apply(lambda x: 'Outlier' if x == -1 else 'Inlier')
    return df

# Apply Isolation Forest
contamination = 0.1
n_estimators = 100
df = apply_isolation_forest(df, contamination, n_estimators)

# Calculate the replacement values
mean_value = df[df['Outlier'] == 'Inlier']['Value'].mean()
max_value = df[df['Outlier'] == 'Inlier']['Value'].max()
quantile_5th = df[df['Outlier'] == 'Inlier']['Value'].quantile(0.05)

# Replace outliers based on specified rules
def replace_outliers(row, mean_value, max_value, quantile_5th):
    if row['Outlier'] == 'Outlier':
        noise = np.random.normal(0, 1)
        if row['Value'] > mean_value:
            return 0.1 * max_value + noise
        else:
            return quantile_5th + noise
    else:
        return row['Value']

df['Adjusted'] = df.apply(lambda row: replace_outliers(row, mean_value, max_value, quantile_5th), axis=1)

# Plot original data with outliers highlighted
plt.figure(figsize=(12, 8))
sns.scatterplot(data=df, x=range(len(df)), y='Value', hue='Outlier', palette='tab10', legend='full')
plt.title('Isolation Forest Outlier Detection')
plt.xlabel('Index')
plt.ylabel('Value')
plt.show()

# Plot original and adjusted data distributions
plt.figure(figsize=(12, 8))
sns.displot(df, x='Value', hue='Outlier', kind='kde', fill=True, height=5, aspect=2)
plt.title('Original Data with Outliers Highlighted')

sns.displot(df, x='Adjusted', kind='kde', fill=True, height=5, aspect=2)
plt.title('Data after Outlier Adjustment')

plt.show()

# Show the impact of adjusting outliers
print("Original Data:")
print(df['Value'].describe())
print("\nAdjusted Data:")
print(df['Adjusted'].describe())

# Split the data into features and target
X = df[['Value']]
y = df['Adjusted']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# Define parameter grid for XGBoost
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [3, 5, 7],
    'learning_rate': [0.01, 0.1, 0.3],
    'min_child_weight': [1, 5, 10]
}

# Initialize and train XGBoost model with GridSearchCV
xgb_reg = xgb.XGBRegressor(objective='reg:squarederror', random_state=0)
grid_search = GridSearchCV(estimator=xgb_reg, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)
grid_search.fit(X_train, y_train)

# Get the best model
best_model = grid_search.best_estimator_

# Predict and evaluate the best model
y_train_pred = best_model.predict(X_train)
y_test_pred = best_model.predict(X_test)

mse_train = mean_squared_error(y_train, y_train_pred)
mse_test = mean_squared_error(y_test, y_test_pred)
r2_train = r2_score(y_train, y_train_pred)
r2_test = r2_score(y_test, y_test_pred)

print(f'Best Parameters: {grid_search.best_params_}')
print(f'XGBoost - MSE Train: {mse_train}, MSE Test: {mse_test}, R^2 Train: {r2_train}, R^2 Test: {r2_test}')

# Plotting train vs test results
plt.figure(figsize=(14, 6))

plt.subplot(1, 2, 1)
plt.scatter(y_train, y_train_pred, alpha=0.5)
plt.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], '--r')
plt.xlabel('Actual Values (Train)')
plt.ylabel('Predicted Values (Train)')
plt.title('XGBoost - Train')

plt.subplot(1, 2, 2)
plt.scatter(y_test, y_test_pred, alpha=0.5)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], '--r')
plt.xlabel('Actual Values (Test)')
plt.ylabel('Predicted Values (Test)')
plt.title('XGBoost - Test')

plt.suptitle('Actual vs Predicted Values (XGBoost)')
plt.show()









import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.ensemble import IsolationForest
from sklearn.model_selection import train_test_split
import xgboost as xgb
from sklearn.metrics import mean_squared_error, r2_score

# Sample DataFrame creation for demonstration
np.random.seed(0)
df = pd.DataFrame({
    'Value': np.random.randn(100) * 20  # Generating a dataset with potential outliers
})

# Introduce extreme outliers
df.loc[::10, 'Value'] = df['Value'] * 100

# Function to apply Isolation Forest and adjust outliers
def apply_isolation_forest(df, contamination, n_estimators):
    iso_forest = IsolationForest(contamination=contamination, n_estimators=n_estimators, random_state=0)
    df['Outlier'] = iso_forest.fit_predict(df[['Value']])
    df['Outlier'] = df['Outlier'].apply(lambda x: 'Outlier' if x == -1 else 'Inlier')
    return df

# Apply Isolation Forest
contamination = 0.1
n_estimators = 100
df = apply_isolation_forest(df, contamination, n_estimators)

# Calculate the replacement values
mean_value = df[df['Outlier'] == 'Inlier']['Value'].mean()
max_value = df[df['Outlier'] == 'Inlier']['Value'].max()
quantile_5th = df[df['Outlier'] == 'Inlier']['Value'].quantile(0.05)

# Replace outliers based on specified rules
def replace_outliers(row, mean_value, max_value, quantile_5th):
    if row['Outlier'] == 'Outlier':
        noise = np.random.normal(0, 1)
        if row['Value'] > mean_value:
            return 0.1 * max_value + noise
        else:
            return quantile_5th + noise
    else:
        return row['Value']

df['Adjusted'] = df.apply(lambda row: replace_outliers(row, mean_value, max_value, quantile_5th), axis=1)

# Plot original data with outliers highlighted
plt.figure(figsize=(12, 8))
sns.scatterplot(data=df, x=range(len(df)), y='Value', hue='Outlier', palette='tab10', legend='full')
plt.title('Isolation Forest Outlier Detection')
plt.xlabel('Index')
plt.ylabel('Value')
plt.show()

# Plot original and adjusted data distributions
plt.figure(figsize=(12, 8))
sns.displot(df, x='Value', hue='Outlier', kind='kde', fill=True, height=5, aspect=2)
plt.title('Original Data with Outliers Highlighted')

sns.displot(df, x='Adjusted', kind='kde', fill=True, height=5, aspect=2)
plt.title('Data after Outlier Adjustment')

plt.show()

# Show the impact of adjusting outliers
print("Original Data:")
print(df['Value'].describe())
print("\nAdjusted Data:")
print(df['Adjusted'].describe())

# Split the data into features and target
X = df[['Value']]
y = df['Adjusted']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# Initialize and train XGBoost model with enable_categorical set to True
xgb_reg = xgb.XGBRegressor(objective='reg:squarederror', random_state=0, enable_categorical=False)
xgb_reg.fit(X_train, y_train)

# Predict and evaluate the model
y_train_pred = xgb_reg.predict(X_train)
y_test_pred = xgb_reg.predict(X_test)

mse_train = mean_squared_error(y_train, y_train_pred)
mse_test = mean_squared_error(y_test, y_test_pred)
r2_train = r2_score(y_train, y_train_pred)
r2_test = r2_score(y_test, y_test_pred)

print(f'XGBoost - MSE Train: {mse_train}, MSE Test: {mse_test}, R^2 Train: {r2_train}, R^2 Test: {r2_test}')

# Plotting train vs test results
plt.figure(figsize=(14, 6))

plt.subplot(1, 2, 1)
plt.scatter(y_train, y_train_pred, alpha=0.5)
plt.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], '--r')
plt.xlabel('Actual Values (Train)')
plt.ylabel('Predicted Values (Train)')
plt.title('XGBoost - Train')

plt.subplot(1, 2, 2)
plt.scatter(y_test, y_test_pred, alpha=0.5)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], '--r')
plt.xlabel('Actual Values (Test)')
plt.ylabel('Predicted Values (Test)')
plt.title('XGBoost - Test')

plt.suptitle('Actual vs Predicted Values (XGBoost)')
plt.show()









import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.ensemble import IsolationForest
from sklearn.model_selection import train_test_split, GridSearchCV
import xgboost as xgb
from sklearn.metrics import mean_squared_error, r2_score

# Sample DataFrame creation for demonstration
np.random.seed(0)
df = pd.DataFrame({
    'Value': np.random.randn(100) * 20  # Generating a dataset with potential outliers
})

# Introduce extreme outliers
df.loc[::10, 'Value'] = df['Value'] * 100

# Function to apply Isolation Forest and adjust outliers
def apply_isolation_forest(df, contamination, n_estimators):
    iso_forest = IsolationForest(contamination=contamination, n_estimators=n_estimators, random_state=0)
    df['Outlier'] = iso_forest.fit_predict(df[['Value']])
    df['Outlier'] = df['Outlier'].apply(lambda x: 'Outlier' if x == -1 else 'Inlier')
    return df

# Apply Isolation Forest
contamination = 0.1
n_estimators = 100
df = apply_isolation_forest(df, contamination, n_estimators)

# Calculate the replacement values
mean_value = df[df['Outlier'] == 'Inlier']['Value'].mean()
max_value = df[df['Outlier'] == 'Inlier']['Value'].max()
quantile_5th = df[df['Outlier'] == 'Inlier']['Value'].quantile(0.05)

# Replace outliers based on specified rules
def replace_outliers(row, mean_value, max_value, quantile_5th):
    if row['Outlier'] == 'Outlier':
        noise = np.random.normal(0, 1)
        if row['Value'] > mean_value:
            return 0.1 * max_value + noise
        else:
            return quantile_5th + noise
    else:
        return row['Value']

df['Adjusted'] = df.apply(lambda row: replace_outliers(row, mean_value, max_value, quantile_5th), axis=1)

# Plot original data with outliers highlighted
plt.figure(figsize=(12, 8))
sns.scatterplot(data=df, x=range(len(df)), y='Value', hue='Outlier', palette='tab10', legend='full')
plt.title('Isolation Forest Outlier Detection')
plt.xlabel('Index')
plt.ylabel('Value')
plt.show()

# Plot original and adjusted data distributions
plt.figure(figsize=(12, 8))
sns.displot(df, x='Value', hue='Outlier', kind='kde', fill=True, height=5, aspect=2)
plt.title('Original Data with Outliers Highlighted')

sns.displot(df, x='Adjusted', kind='kde', fill=True, height=5, aspect=2)
plt.title('Data after Outlier Adjustment')

plt.show()

# Show the impact of adjusting outliers
print("Original Data:")
print(df['Value'].describe())
print("\nAdjusted Data:")
print(df['Adjusted'].describe())

# Split the data into features and target
X = df[['Value']]
y = df['Adjusted']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# Initialize and train XGBoost model
xgb_reg = xgb.XGBRegressor(objective='reg:squarederror', random_state=0)
xgb_reg.fit(X_train, y_train)

# Predict and evaluate the model
y_train_pred = xgb_reg.predict(X_train)
y_test_pred = xgb_reg.predict(X_test)

mse_train = mean_squared_error(y_train, y_train_pred)
mse_test = mean_squared_error(y_test, y_test_pred)
r2_train = r2_score(y_train, y_train_pred)
r2_test = r2_score(y_test, y_test_pred)

print(f'XGBoost - MSE Train: {mse_train}, MSE Test: {mse_test}, R^2 Train: {r2_train}, R^2 Test: {r2_test}')

# Plotting train vs test results
plt.figure(figsize=(14, 6))

plt.subplot(1, 2, 1)
plt.scatter(y_train, y_train_pred, alpha=0.5)
plt.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], '--r')
plt.xlabel('Actual Values (Train)')
plt.ylabel('Predicted Values (Train)')
plt.title('XGBoost - Train')

plt.subplot(1, 2, 2)
plt.scatter(y_test, y_test_pred, alpha=0.5)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], '--r')
plt.xlabel('Actual Values (Test)')
plt.ylabel('Predicted Values (Test)')
plt.title('XGBoost - Test')

plt.suptitle('Actual vs Predicted Values (XGBoost)')
plt.show()








import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.ensemble import IsolationForest
from sklearn.model_selection import train_test_split
import xgboost as xgb
from sklearn.metrics import mean_squared_error, r2_score

# Sample DataFrame creation for demonstration
np.random.seed(0)
df = pd.DataFrame({
    'Value': np.random.randn(100) * 20  # Generating a dataset with potential outliers
})

# Introduce extreme outliers
df.loc[::10, 'Value'] = df['Value'] * 100

# Function to apply Isolation Forest and adjust outliers
def apply_isolation_forest(df, contamination, n_estimators):
    iso_forest = IsolationForest(contamination=contamination, n_estimators=n_estimators, random_state=0)
    df['Outlier'] = iso_forest.fit_predict(df[['Value']])
    df['Outlier'] = df['Outlier'].apply(lambda x: 'Outlier' if x == -1 else 'Inlier')
    return df

# Apply Isolation Forest
contamination = 0.1
n_estimators = 100
df = apply_isolation_forest(df, contamination, n_estimators)

# Calculate the replacement values
mean_value = df[df['Outlier'] == 'Inlier']['Value'].mean()
max_value = df[df['Outlier'] == 'Inlier']['Value'].max()
quantile_5th = df[df['Outlier'] == 'Inlier']['Value'].quantile(0.05)

# Replace outliers based on specified rules
def replace_outliers(row, mean_value, max_value, quantile_5th):
    if row['Outlier'] == 'Outlier':
        noise = np.random.normal(0, 1)
        if row['Value'] > mean_value:
            return 0.1 * max_value + noise
        else:
            return quantile_5th + noise
    else:
        return row['Value']

df['Adjusted'] = df.apply(lambda row: replace_outliers(row, mean_value, max_value, quantile_5th), axis=1)

# Plot original data with outliers highlighted
plt.figure(figsize=(12, 8))
sns.scatterplot(data=df, x=range(len(df)), y='Value', hue='Outlier', palette='tab10', legend='full')
plt.title('Isolation Forest Outlier Detection')
plt.xlabel('Index')
plt.ylabel('Value')
plt.show()

# Plot original and adjusted data distributions
plt.figure(figsize=(12, 8))
sns.displot(df, x='Value', hue='Outlier', kind='kde', fill=True, height=5, aspect=2)
plt.title('Original Data with Outliers Highlighted')

sns.displot(df, x='Adjusted', kind='kde', fill=True, height=5, aspect=2)
plt.title('Data after Outlier Adjustment')

plt.show()

# Show the impact of adjusting outliers
print("Original Data:")
print(df['Value'].describe())
print("\nAdjusted Data:")
print(df['Adjusted'].describe())












import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder
from sklearn.tree import DecisionTreeRegressor, plot_tree
import seaborn as sns
import matplotlib.pyplot as plt

# Sample DataFrame creation for demonstration
np.random.seed(0)
df = pd.DataFrame({
    'CatVar1': np.random.choice(['A', 'B', 'C', np.nan], size=100),
    'CatVar2': np.random.choice(['X', 'Y', 'Z', np.nan], size=100),
    'Target': np.random.uniform(0, 100, size=100)
})

# Replace missing values with a new category "missing" and convert all to strings
df.fillna('missing', inplace=True)
df['CatVar1'] = df['CatVar1'].astype(str)
df['CatVar2'] = df['CatVar2'].astype(str)

# Function to group using Decision Tree and plot the tree
def group_classes_with_decision_tree(df, cat_vars, target_var):
    group_mappings = {}
    for cat_var in cat_vars:
        le = LabelEncoder()
        df[f'{cat_var}_encoded'] = le.fit_transform(df[cat_var])
        X = df[[f'{cat_var}_encoded']]
        y = df[target_var]
        
        dt_reg = DecisionTreeRegressor(max_depth=3, random_state=0)
        dt_reg.fit(X, y)
        
        # Predict the leaves for each sample
        leaf_ids = dt_reg.apply(X).reshape(-1)  # Flatten to 1D array
        unique_leaf_ids = np.unique(leaf_ids)
        leaf_id_to_group = {leaf_id: idx for idx, leaf_id in enumerate(unique_leaf_ids)}
        
        df[f'Grouped_{cat_var}'] = pd.Series(leaf_ids).map(leaf_id_to_group)
        
        # Create a mapping from original categories to new groups
        original_to_group = {}
        for category in le.classes_:
            category_encoded = le.transform([category])[0]
            group = df[df[f'{cat_var}_encoded'] == category_encoded][f'Grouped_{cat_var}'].mode()[0]
            original_to_group[category] = group
        
        group_mappings[cat_var] = original_to_group

        # Plot the Decision Tree
        plt.figure(figsize=(12, 8))
        plot_tree(dt_reg, feature_names=[cat_var], filled=True, rounded=True, fontsize=10)
        plt.title(f'Decision Tree for {cat_var}')
        plt.show()
        
    return df, group_mappings

# Apply Decision Tree grouping
cat_vars = ['CatVar1', 'CatVar2']
df_grouped, group_mappings = group_classes_with_decision_tree(df, cat_vars, 'Target')

# Display the grouped DataFrame
print(df_grouped.head())

# Display the mappings from original to new groups
for cat_var, mapping in group_mappings.items():
    print(f'\nMapping for {cat_var}:')
    groups = {}
    for original, group in mapping.items():
        if group not in groups:
            groups[group] = []
        groups[group].append(original)
    for group, categories in groups.items():
        print(f'  Group {group + 1}: {categories}')

# Plot the distribution of the target variable by the grouped categories
for cat_var in cat_vars:
    plt.figure(figsize=(12, 6))
    sns.boxplot(x=f'Grouped_{cat_var}', y='Target', data=df_grouped)
    plt.title(f'Distribution of Target by Grouped {cat_var}')
    plt.show()









import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder
from sklearn.tree import DecisionTreeRegressor
import seaborn as sns
import matplotlib.pyplot as plt

# Sample DataFrame creation for demonstration
np.random.seed(0)
df = pd.DataFrame({
    'CatVar1': np.random.choice(['A', 'B', 'C', np.nan], size=100),
    'CatVar2': np.random.choice(['X', 'Y', 'Z', np.nan], size=100),
    'Target': np.random.uniform(0, 100, size=100)
})

# Replace missing values with a new category "missing" and convert all to strings
df.fillna('missing', inplace=True)
df['CatVar1'] = df['CatVar1'].astype(str)
df['CatVar2'] = df['CatVar2'].astype(str)

# Function to group using Decision Tree
def group_classes_with_decision_tree(df, cat_vars, target_var):
    group_mappings = {}
    for cat_var in cat_vars:
        le = LabelEncoder()
        df[f'{cat_var}_encoded'] = le.fit_transform(df[cat_var])
        X = df[[f'{cat_var}_encoded']]
        y = df[target_var]
        
        dt_reg = DecisionTreeRegressor(max_depth=3, random_state=0)
        dt_reg.fit(X, y)
        
        # Predict the leaves for each sample
        leaf_ids = dt_reg.apply(X).reshape(-1)  # Flatten to 1D array
        unique_leaf_ids = np.unique(leaf_ids)
        leaf_id_to_group = {leaf_id: idx for idx, leaf_id in enumerate(unique_leaf_ids)}
        
        df[f'Grouped_{cat_var}'] = pd.Series(leaf_ids).map(leaf_id_to_group)
        
        # Create a mapping from original categories to new groups
        original_to_group = {}
        for category in le.classes_:
            category_encoded = le.transform([category])[0]
            group = df[df[f'{cat_var}_encoded'] == category_encoded][f'Grouped_{cat_var}'].mode()[0]
            original_to_group[category] = group
        
        group_mappings[cat_var] = original_to_group
        
    return df, group_mappings

# Apply Decision Tree grouping
cat_vars = ['CatVar1', 'CatVar2']
df_grouped, group_mappings = group_classes_with_decision_tree(df, cat_vars, 'Target')

# Display the grouped DataFrame
print(df_grouped.head())

# Display the mappings from original to new groups
for cat_var, mapping in group_mappings.items():
    print(f'\nMapping for {cat_var}:')
    groups = {}
    for original, group in mapping.items():
        if group not in groups:
            groups[group] = []
        groups[group].append(original)
    for group, categories in groups.items():
        print(f'  Group {group + 1}: {categories}')

# Plot the distribution of the target variable by the grouped categories
for cat_var in cat_vars:
    plt.figure(figsize=(12, 6))
    sns.boxplot(x=f'Grouped_{cat_var}', y='Target', data=df_grouped)
    plt.title(f'Distribution of Target by Grouped {cat_var}')
    plt.show()
