{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation for Model Building\n",
    "\n",
    "This notebook prepares two dataframes, `df_er` and `df_rest`, for the rest of the modeling process. It involves reading multiple data files, cleaning, merging, aggregating, and preparing the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "\n",
    "We read monthly data files for the year 2018 from January to December."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read monthly data files\n",
    "file_paths = ['data/STOCK_PROFILPRO_CLIENTS_{:02d}2018.csv'.format(i) for i in range(1, 13)]\n",
    "dataframes = []\n",
    "for i, file_path in enumerate(file_paths, 1):\n",
    "    df = pd.read_csv(file_path, sep=';', encoding='latin-1')\n",
    "    df['col'] = i  # Add a column to track the month\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Concatenate all dataframes\n",
    "df = pd.concat(dataframes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add a 'col' column to each dataframe to track the month number (from 1 to 12) before concatenating them into a single dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "### Dropping Unnecessary Columns\n",
    "\n",
    "We drop columns that are not needed for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "columns_to_drop = ['seg_mark_op', 'risque_defaut', 'NSCO085', 'NSCO032', 'NSCO041', 'NSCO033', \n",
    "                   'NSCO110', 'NSCO121', 'dcl', 'rtr', 'communaute_pro', 'CBS', 'poste_banque']\n",
    "df.drop(columns=columns_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming Columns\n",
    "\n",
    "We rename some columns for better readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "df.rename(columns={\n",
    "    'QPCL063': 'compte epargne',\n",
    "    'QPCL064': 'compte epargne a echeance',\n",
    "    'QPCL065': 'compte à terme',\n",
    "    'QPCL069': 'prêt immo',\n",
    "    'QPCL071': 'compte titre',\n",
    "    'QPCL072': 'prêt perso',\n",
    "    'QPCL074': 'crédit fonctionnement',\n",
    "    'QPCL075': 'crédit équipement',\n",
    "    'QPCL076': 'engagement par signature',\n",
    "    'QPCL079': 'santé prévoyance',\n",
    "    'QPCL080': 'dommage',\n",
    "    'QPCL083': 'assurance vie',\n",
    "    'QPCL089': 'Cartes de Paiement',\n",
    "    'QPCL373': 'Esprit Libre PRO',\n",
    "    'QPCL142': 'BNP NET Pro et Evolution',\n",
    "    'QPCL165': 'Contrat Commerçant'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering Data\n",
    "\n",
    "We select rows where `NANCCLI == 2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data where NANCCLI == 2\n",
    "df_pro = df[df['NANCCLI'] == 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Duplicates\n",
    "\n",
    "We sort the dataframe and remove duplicates, keeping the last occurrence based on 'CCLI' and 'CCLIKPI'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the dataframe by 'CCLI', 'CCLIKPI', and 'col'\n",
    "df_pro = df_pro.sort_values(by=['CCLI', 'CCLIKPI', 'col'])\n",
    "\n",
    "# Drop duplicates keeping the last one based on 'CCLI' and 'CCLIKPI'\n",
    "df_pro_unique = df_pro.drop_duplicates(subset=['CCLI', 'CCLIKPI'], keep='last')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Data\n",
    "\n",
    "We exclude rows where `CNOUVSEG == 'AS'`, then split the data into two dataframes based on `CNOUVSEG`:\n",
    "\n",
    "- `df_pro_unique_er`: where `CNOUVSEG == 'ER'`\n",
    "- `df_pro_unique_rest`: the rest of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude rows where CNOUVSEG == 'AS'\n",
    "df_pro_unique = df_pro_unique[df_pro_unique['CNOUVSEG'] != 'AS']\n",
    "\n",
    "# Split into 'ER' and 'Rest'\n",
    "df_pro_unique_er = df_pro_unique[df_pro_unique['CNOUVSEG'] == 'ER']\n",
    "df_pro_unique_rest = df_pro_unique[df_pro_unique['CNOUVSEG'] != 'ER']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Priority Orders for Aggregation\n",
    "\n",
    "We define custom aggregation functions for categorical variables where we have a priority order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom aggregation function for categorical variables with priority order\n",
    "def agg_priority(series, priority_order):\n",
    "    for priority in priority_order:\n",
    "        if priority in series.values:\n",
    "            return priority\n",
    "    return series.values[0]  # Fallback to the first value if no priority match found\n",
    "\n",
    "# Wrapper function to apply the correct priority order\n",
    "def agg_wrapper(column, priority_orders):\n",
    "    return lambda series: agg_priority(series, priority_orders[column])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping and Aggregating Data\n",
    "\n",
    "We define custom aggregation functions with priority orders for categorical variables and aggregate the data accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define priority order for categorical variables\n",
    "priority_orders = {\n",
    "    'CNOUVSEG': ['ER'],\n",
    "    'CMOTENT1': [98., 26., 44., 4., 1., 97., 28., 69., 96., 83., 7., 76., 89., 21., 49.],\n",
    "    'CUODR': [8065, 8061, 8060, 8085, 8063, 8058, 8080, 8066, 8064, 8054, 8052,\n",
    "              8055, 8062, 8075, 8053, 8051, 8040, 8056, 8057],\n",
    "    'CENSEIGNE': [0, 1],\n",
    "    'etebac': [0, 1, 2],\n",
    "    'prevoyance_pro': [0, 1, 2],\n",
    "    'section': [\"Commerce ; réparation d'automobiles et de motocycles\",\n",
    "                'Construction',\n",
    "                'Activités spécialisées, scientifiques et techniques',\n",
    "                'Autres activités de services', 'Industrie manufacturière',\n",
    "                'Hébergement et restauration',\n",
    "                \"Activités financières et d'assurance\", 'Activités immobilières',\n",
    "                'Agriculture, sylviculture et pêche', ' Pas de section',\n",
    "                'Transports et entreposage',\n",
    "                'Activités de services administratifs et de soutien',\n",
    "                'Information et communication', 'Santé humaine et action sociale',\n",
    "                'Enseignement',\n",
    "                \"Production et distribution d'eau ; assainissement, ges\",\n",
    "                \"Production et distribution d'électricité, de gaz, de v\",\n",
    "                'Arts, spectacles et activités récréatives',\n",
    "                'Industries extractives', 'Activités extra-territoriales'],\n",
    "    'code_sous_marche': ['52', '45', '74', '93', '29', '55', '28', '70', '05', '51', '00',\n",
    "                         '60', '20', 'COM', '72', '67', '01', '50', '85', '92', '63', 'nan',\n",
    "                         '31', '22', '73', '25', '71', '80', '36', '90', '15', '65', '17',\n",
    "                         '40', '21', '37', '18', '64', '32', '35', 'SRV', '24', '26', 'ART',\n",
    "                         '34', 'LIB', '33', '30', '61', '19', '14', '27', 'AUT', 'INC',\n",
    "                         'SAN', '99', '02'],\n",
    "    'CCOTABNP': [9., 8., 7., 5., 2., 1., 'nan']\n",
    "}\n",
    "\n",
    "# Define aggregation methods for each column\n",
    "agg_dict = {\n",
    "    'CTYPCLI': 'mean',\n",
    "    'CNOUVSEG': agg_wrapper('CNOUVSEG', priority_orders),\n",
    "    'AGE': 'max',\n",
    "    'NANCCLI': 'max',\n",
    "    'CMOTENT1': agg_wrapper('CMOTENT1', priority_orders),\n",
    "    'CUODR': agg_wrapper('CUODR', priority_orders),\n",
    "    'CENSEIGNE': agg_wrapper('CENSEIGNE', priority_orders),\n",
    "    'MACMPROF': 'sum',\n",
    "    'flux_annuel': 'sum',\n",
    "    'pnb_annuel': 'sum',\n",
    "    'pnb_an_rep': 'sum',\n",
    "    'nb_op_annuel': 'sum',\n",
    "    'compte epargne': 'sum',\n",
    "    'compte epargne a echeance': 'sum',\n",
    "    'compte à terme': 'sum',\n",
    "    'prêt immo': 'sum',\n",
    "    'compte titre': 'sum',\n",
    "    'prêt perso': 'sum',\n",
    "    'crédit fonctionnement': 'sum',\n",
    "    'crédit équipement': 'sum',\n",
    "    'engagement par signature': 'sum',\n",
    "    'santé prévoyance': 'sum',\n",
    "    'prevoyance_pro': 'sum',\n",
    "    'dommage': 'sum',\n",
    "    'assurance vie': 'sum',\n",
    "    'Cartes de Paiement': 'sum',\n",
    "    'carte_business': 'sum',\n",
    "    'carte_affaire': 'sum',\n",
    "    'Esprit Libre PRO': 'sum',\n",
    "    'BNP NET Pro et Evolution': 'sum',\n",
    "    'Contrat Commerçant': 'sum',\n",
    "    'etebac': 'sum',\n",
    "    'pee': 'sum',\n",
    "    'perco': 'sum',\n",
    "    'perm_mad': 'sum',\n",
    "    'credit_inv': 'sum',\n",
    "    'credit_bail': 'sum',\n",
    "    'securite_pro': 'sum',\n",
    "    'EL_pro': 'sum',\n",
    "    'net_pro_evol': 'sum',\n",
    "    'CA': 'sum',\n",
    "    'nb_salaries': 'sum',\n",
    "    'section': agg_wrapper('section', priority_orders),\n",
    "    'code_sous_marche': agg_wrapper('code_sous_marche', priority_orders),\n",
    "    'CCOTABNP': agg_wrapper('CCOTABNP', priority_orders),\n",
    "    'anc_mois_crea': 'max',\n",
    "    'MACMREP': 'sum',\n",
    "    'MFTCREP': 'sum',\n",
    "    'k_eq_restant_du': 'sum'\n",
    "}\n",
    "\n",
    "# Group and aggregate data for 'ER' segment\n",
    "grouped_data_er = df_pro_unique_er.groupby('CCLIKPI').agg(agg_dict).reset_index()\n",
    "\n",
    "# Group and aggregate data for the rest\n",
    "grouped_data_rest = df_pro_unique_rest.groupby('CCLIKPI').agg(agg_dict).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Target Variable\n",
    "\n",
    "We read additional data files from 2018 to 2023 to prepare the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data files from 2018 to 2023\n",
    "additional_files = [\n",
    "    'data/STOCK_PROFILPRO_CLIENTS_122018.csv',\n",
    "    '../domino/datasets/local/sp_2019_to_2023/STOCK_PROFILPRO_CLIENTS_122019.csv',\n",
    "    '../domino/datasets/local/sp_2019_to_2023/STOCK_PROFILPRO_CLIENTS_122020.csv',\n",
    "    '../domino/datasets/local/sp_2019_to_2023/STOCK_PROFILPRO_CLIENTS_122021.csv',\n",
    "    '../domino/datasets/local/sp_2019_to_2023/STOCK_PROFILPRO_CLIENTS_122022.csv',\n",
    "    '../domino/datasets/local/sp_2019_to_2023/STOCK_PROFILPRO_CLIENTS_062023.csv'\n",
    "]\n",
    "\n",
    "dataframes_additional = [pd.read_csv(file, sep=';', encoding='latin-1') for file in additional_files]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Total PNB for Each ID\n",
    "\n",
    "We calculate the total `pnb_annuel` (presumably a financial metric) for each `CCLIKPI` across the additional dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate total pnb for each id\n",
    "def calculate_pnb_for_each_id(og_df, dataframes, key='CCLIKPI', target_col='pnb_annuel'):\n",
    "    # Get the unique ids from the original dataframe\n",
    "    og_ids = set(og_df[key].unique())\n",
    "    \n",
    "    # Initialize a dictionary to store the total pnb for each id\n",
    "    total_pnb_dict = {id: 0 for id in og_ids}\n",
    "    \n",
    "    # Iterate through each dataframe\n",
    "    for df in dataframes:\n",
    "        # Filter the dataframe to only include rows where the id is in the original dataframe\n",
    "        filtered_df = df[df[key].isin(og_ids)]\n",
    "        \n",
    "        # Sum the pnb column for the filtered dataframe by id and add it to the total_pnb_dict\n",
    "        for id, pnb_sum in filtered_df.groupby(key)[target_col].sum().items():\n",
    "            total_pnb_dict[id] += pnb_sum\n",
    "    \n",
    "    return total_pnb_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For 'ER' Segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total pnb for each id in grouped_data_er\n",
    "og = grouped_data_er\n",
    "total_pnb_dict = calculate_pnb_for_each_id(og, dataframes_additional)\n",
    "\n",
    "# Create a dataframe with the total_pnb\n",
    "result_df = pd.DataFrame({\n",
    "    'CCLIKPI': list(total_pnb_dict.keys()),\n",
    "    'total_pnb': list(total_pnb_dict.values())\n",
    "})\n",
    "\n",
    "# Merge total_pnb with grouped_data_er\n",
    "df_er = pd.merge(grouped_data_er, result_df, on='CCLIKPI', how='inner')\n",
    "\n",
    "# Save the dataframe\n",
    "df_er.to_csv('df_er.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the Rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total pnb for each id in grouped_data_rest\n",
    "og = grouped_data_rest\n",
    "total_pnb_dict = calculate_pnb_for_each_id(og, dataframes_additional)\n",
    "\n",
    "# Create a dataframe with the total_pnb\n",
    "result_df = pd.DataFrame({\n",
    "    'CCLIKPI': list(total_pnb_dict.keys()),\n",
    "    'total_pnb': list(total_pnb_dict.values())\n",
    "})\n",
    "\n",
    "# Merge total_pnb with grouped_data_rest\n",
    "df_rest = pd.merge(grouped_data_rest, result_df, on='CCLIKPI', how='inner')\n",
    "\n",
    "# Exclude rows where CENSEIGNE == 2\n",
    "df_rest = df_rest[df_rest['CENSEIGNE'] != 2]\n",
    "\n",
    "# Save the dataframe\n",
    "df_rest.to_csv('df_rest.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Final Dataframes\n",
    "\n",
    "We save the final dataframes `df_er.csv` and `df_rest.csv` for further modeling.\n",
    "\n",
    "---\n",
    "\n",
    "**Note**: This notebook has been structured to provide a clear understanding of each step involved in the data preparation process. Each section includes explanations and code snippets to make the notebook easy to follow and aesthetically pleasing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
