from sklearn.linear_model import LinearRegression
import pandas as pd

# Sample DataFrame
data = {
    'Feature_1': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],
    'Feature_2': [1.1, 2.2, 3.3, 4.4, 5.5, 6.6, 7.7, 8.8, 9.9, 10.1],
    'Target': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]
}
df = pd.DataFrame(data)

# Separate features and target
X = df.drop(columns=['Target'])
y = df['Target']

# Train a linear regression model
model = LinearRegression()
model.fit(X, y)

# Coefficients as feature importance
importance = model.coef_
for i, v in enumerate(importance):
    print(f'Feature: {X.columns[i]}, Score: {v:.5f}')



from sklearn.ensemble import RandomForestRegressor
import pandas as pd

# Sample DataFrame
data = {
    'Feature_1': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],
    'Feature_2': [1.1, 2.2, 3.3, 4.4, 5.5, 6.6, 7.7, 8.8, 9.9, 10.1],
    'Target': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]
}
df = pd.DataFrame(data)

# Separate features and target
X = df.drop(columns=['Target'])
y = df['Target']

# Train a random forest model
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X, y)

# Feature importances
importances = model.feature_importances_
for i, v in enumerate(importances):
    print(f'Feature: {X.columns[i]}, Score: {v:.5f}')


from sklearn.ensemble import RandomForestRegressor
from sklearn.inspection import permutation_importance
import pandas as pd

# Sample DataFrame
data = {
    'Feature_1': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],
    'Feature_2': [1.1, 2.2, 3.3, 4.4, 5.5, 6.6, 7.7, 8.8, 9.9, 10.1],
    'Target': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]
}
df = pd.DataFrame(data)

# Separate features and target
X = df.drop(columns=['Target'])
y = df['Target']

# Train a random forest model
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X, y)

# Permutation importance
results = permutation_importance(model, X, y, scoring='neg_mean_squared_error')
importances = results.importances_mean
for i, v in enumerate(importances):
    print(f'Feature: {X.columns[i]}, Score: {v:.5f}')








import shap
from sklearn.ensemble import RandomForestRegressor
import pandas as pd

# Sample DataFrame
data = {
    'Feature_1': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],
    'Feature_2': [1.1, 2.2, 3.3, 4.4, 5.5, 6.6, 7.7, 8.8, 9.9, 10.1],
    'Target': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]
}
df = pd.DataFrame(data)

# Separate features and target
X = df.drop(columns=['Target'])
y = df['Target']

# Train a random forest model
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X, y)

# Explain the model predictions using SHAP values
explainer = shap.Explainer(model, X)
shap_values = explainer(X)

# Plot SHAP values
shap.summary_plot(shap_values, X)
