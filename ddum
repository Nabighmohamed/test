import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split

# Sample DataFrame creation for demonstration
np.random.seed(0)
df = pd.DataFrame({
    'Age': np.random.randint(18, 70, size=100),
    'Income': np.random.uniform(30000, 100000, size=100),
    'Category1': np.random.choice(['A', 'B', 'C', np.nan], size=100),
    'Category2': np.random.choice(['X', 'Y', 'Z', np.nan], size=100),
    'Target': np.random.uniform(0, 100, size=100)
})

# Replace missing values with a new category "missing" and convert all to strings
df.fillna('missing', inplace=True)
df['Category1'] = df['Category1'].astype(str)
df['Category2'] = df['Category2'].astype(str)

# Encode categorical variables
label_encoders = {}
for col in df.select_dtypes(include=['object']).columns:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col])
    label_encoders[col] = le

# Combine the columns for stratification
df['Stratify'] = df['Age'].astype(str) + '_' + df['Income'].round(0).astype(str) + '_' + df['Category1'].astype(str) + '_' + df['Category2'].astype(str)

# Perform the train-test split with stratification
train_df, test_df = train_test_split(df, test_size=0.2, random_state=0, stratify=df['Stratify'])

# Drop the stratification column from the train and test sets
train_df = train_df.drop(columns=['Stratify']).reset_index(drop=True)
test_df = test_df.drop(columns=['Stratify']).reset_index(drop=True)

# Check the distribution
print("Training set distribution:\n", train_df['Stratify'].value_counts(normalize=True))
print("\nTesting set distribution:\n", test_df['Stratify'].value_counts(normalize=True))

# Proceed with your further code (clustering, modeling, etc.)





import pandas as pd
import numpy as np
from sklearn.cluster import KMeans
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import r2_score
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression, Ridge, Lasso, HuberRegressor
import matplotlib.pyplot as plt
from sklearn.mixture import GaussianMixture
from sklearn.metrics import silhouette_score

# Sample DataFrame creation for demonstration
np.random.seed(0)
df = pd.DataFrame({
    'Age': np.random.randint(18, 70, size=100),
    'Income': np.random.uniform(30000, 100000, size=100),
    'Category1': np.random.choice(['A', 'B', 'C', np.nan], size=100),
    'Category2': np.random.choice(['X', 'Y', 'Z', np.nan], size=100),
    'Target': np.random.uniform(0, 100, size=100)
})

# Replace missing values with a new category "missing" and convert all to strings
df.fillna('missing', inplace=True)
df['Category1'] = df['Category1'].astype(str)
df['Category2'] = df['Category2'].astype(str)

# Encode categorical variables
label_encoders = {}
for col in df.select_dtypes(include=['object']).columns:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col])
    label_encoders[col] = le

# Plot AIC and BIC for different number of clusters
n_clusters = range(1, 11)
aic_values = []
bic_values = []
silhouette_scores = []

for n in n_clusters:
    gmm = GaussianMixture(n_components=n, random_state=0)
    gmm.fit(df[['Target']])
    aic_values.append(gmm.aic(df[['Target']]))
    bic_values.append(gmm.bic(df[['Target']]))
    if n > 1:
        silhouette_scores.append(silhouette_score(df[['Target']], gmm.predict(df[['Target']])))

plt.figure(figsize=(12, 6))
plt.plot(n_clusters, aic_values, label='AIC')
plt.plot(n_clusters, bic_values, label='BIC')
plt.xlabel('Number of clusters')
plt.ylabel('Score')
plt.title('AIC and BIC for different number of clusters')
plt.legend()
plt.show()

plt.figure(figsize=(12, 6))
plt.plot(n_clusters[1:], silhouette_scores, label='Silhouette Score')
plt.xlabel('Number of clusters')
plt.ylabel('Score')
plt.title('Silhouette Score for different number of clusters')
plt.legend()
plt.show()

# Choose the optimal number of clusters based on BIC (you can also choose based on AIC or silhouette score)
optimal_clusters = np.argmin(bic_values) + 1
print(f'Optimal number of clusters: {optimal_clusters}')

# Apply k-means clustering to segment the target variable
kmeans = KMeans(n_clusters=optimal_clusters, random_state=0)
df['Cluster'] = kmeans.fit_predict(df[['Target']])

# Separate data into clusters based on k-means clustering
clusters = [df[df['Cluster'] == i] for i in range(optimal_clusters)]

# Calculate and display intervals for each cluster
intervals = []
for cluster_id, cluster in enumerate(clusters):
    min_value = cluster['Target'].min()
    max_value = cluster['Target'].max()
    intervals.append((min_value, max_value))

# Sort intervals to ensure they are in order
intervals.sort()

# Adjust intervals to ensure no gaps
adjusted_intervals = []
for i, (min_value, max_value) in enumerate(intervals):
    if i == 0:
        adjusted_intervals.append((min_value, max_value))
    else:
        previous_max = adjusted_intervals[-1][1]
        adjusted_intervals.append((previous_max, max_value))

# Print adjusted intervals
for i, (min_value, max_value) in enumerate(adjusted_intervals):
    print(f'Cluster {i}: {min_value:.2f} to {max_value:.2f}')

# Define models to train
models = {
    'RandomForest': RandomForestRegressor(random_state=0),
    'LinearRegression': LinearRegression(),
    'Ridge': Ridge(),
    'Lasso': Lasso(),
    'Huber': HuberRegressor()
}

param_grid = {
    'RandomForest': {'n_estimators': [50, 100], 'max_depth': [3, 5]},
    'Ridge': {'alpha': [0.01, 0.1, 1]},
    'Lasso': {'alpha': [0.01, 0.1, 1]},
    'Huber': {'epsilon': [1.35, 1.5]}
}

# Function to train and evaluate models
def train_evaluate_models(X_train, X_test, y_train, y_test, model, param_grid):
    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='r2', n_jobs=-1)
    grid_search.fit(X_train, y_train)
    best_model = grid_search.best_estimator_
    y_pred = best_model.predict(X_test)
    r2 = r2_score(y_test, y_pred)
    return r2

# Train and evaluate models for each cluster
results = {}
for cluster_id, cluster in enumerate(clusters):
    X = cluster.drop(columns=['Target', 'Cluster'])
    y = cluster['Target']
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)
    cluster_results = {}
    for model_name, model in models.items():
        r2 = train_evaluate_models(X_train, X_test, y_train, y_test, model, param_grid.get(model_name, {}))
        cluster_results[model_name] = r2
    results[f'Cluster {cluster_id}'] = cluster_results

# Display results
results_df = pd.DataFrame(results).T
print(results_df)

# Plot RÂ² scores for each model across different clusters
results_df.plot(kind='bar', figsize=(12, 6))
plt.xlabel('Cluster')
plt.ylabel('RÂ² Score')
plt.title('RÂ² Scores for Different Models across Clusters')
plt.legend()
plt.show()











import xgboost as xgb
from sklearn.metrics import r2_score
import itertools

# Define the parameter grid
etas = [0.01, 0.1, 0.3]
max_depths = [2, 4, 6]
subsamples = [0.8, 1.0]
colsample_bytree = [1.0, 0.8]

# List to store results
results = []

# Iterate over all parameter combinations
for eta, max_depth, subsample, colsample in itertools.product(etas, max_depths, subsamples, colsample_bytree):
    xgb_params = {
        'eta': eta,
        'max_depth': max_depth,
        'subsample': subsample,
        'colsample_bytree': colsample,
        'objective': 'reg:squarederror',
        'seed': 1989
    }
    
    xgb_cv = xgb.cv(
        params=xgb_params,
        dtrain=train_xgb,
        num_boost_round=10000,
        nfold=5,
        early_stopping_rounds=10,
        verbose_eval=0
    )
    
    # Extract the best number of boosting rounds
    best_num_boost_rounds = len(xgb_cv['train-rmse-mean'])
    
    # Train the model with the best number of boosting rounds
    model = xgb.train(
        params=xgb_params,
        dtrain=train_xgb,
        num_boost_round=best_num_boost_rounds
    )
    
    # Make predictions
    y_pred = model.predict(test_xgb)
    
    # Evaluate using R2 score
    r2 = r2_score(y_test, y_pred)
    
    # Store the results
    results.append({
        'eta': eta,
        'max_depth': max_depth,
        'subsample': subsample,
        'colsample_bytree': colsample,
        'best_num_boost_rounds': best_num_boost_rounds,
        'r2': r2
    })

# Find the best result
best_result = max(results, key=lambda x: x['r2'])

# Print the best parameters and corresponding R2 score
print("Best parameters found: ", best_result)
print("Best R2 score: ", best_result['r2'])











import pandas as pd
import numpy as np
from sklearn.cluster import KMeans
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import r2_score
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression, Ridge, Lasso, HuberRegressor
import matplotlib.pyplot as plt
from sklearn.mixture import GaussianMixture
from sklearn.metrics import silhouette_score

# Sample DataFrame creation for demonstration
np.random.seed(0)
df = pd.DataFrame({
    'Age': np.random.randint(18, 70, size=100),
    'Income': np.random.uniform(30000, 100000, size=100),
    'Category1': np.random.choice(['A', 'B', 'C', np.nan], size=100),
    'Category2': np.random.choice(['X', 'Y', 'Z', np.nan], size=100),
    'Target': np.random.uniform(0, 100, size=100)
})

# Replace missing values with a new category "missing" and convert all to strings
df.fillna('missing', inplace=True)
df['Category1'] = df['Category1'].astype(str)
df['Category2'] = df['Category2'].astype(str)

# Encode categorical variables
label_encoders = {}
for col in df.select_dtypes(include=['object']).columns:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col])
    label_encoders[col] = le

# Plot AIC and BIC for different number of clusters
n_clusters = range(1, 11)
aic_values = []
bic_values = []
silhouette_scores = []

for n in n_clusters:
    gmm = GaussianMixture(n_components=n, random_state=0)
    gmm.fit(df[['Target']])
    aic_values.append(gmm.aic(df[['Target']]))
    bic_values.append(gmm.bic(df[['Target']]))
    if n > 1:
        silhouette_scores.append(silhouette_score(df[['Target']], gmm.predict(df[['Target']])))

plt.figure(figsize=(12, 6))
plt.plot(n_clusters, aic_values, label='AIC')
plt.plot(n_clusters, bic_values, label='BIC')
plt.xlabel('Number of clusters')
plt.ylabel('Score')
plt.title('AIC and BIC for different number of clusters')
plt.legend()
plt.show()

plt.figure(figsize=(12, 6))
plt.plot(n_clusters[1:], silhouette_scores, label='Silhouette Score')
plt.xlabel('Number of clusters')
plt.ylabel('Score')
plt.title('Silhouette Score for different number of clusters')
plt.legend()
plt.show()

# Choose the optimal number of clusters based on BIC (you can also choose based on AIC or silhouette score)
optimal_clusters = np.argmin(bic_values) + 1
print(f'Optimal number of clusters: {optimal_clusters}')

# Apply k-means clustering to segment the target variable
kmeans = KMeans(n_clusters=optimal_clusters, random_state=0)
df['Cluster'] = kmeans.fit_predict(df[['Target']])

# Separate data into clusters based on k-means clustering
clusters = [df[df['Cluster'] == i] for i in range(optimal_clusters)]

# Calculate and display intervals for each cluster
intervals = {}
for cluster_id, cluster in enumerate(clusters):
    min_value = cluster['Target'].min()
    max_value = cluster['Target'].max()
    intervals[f'Cluster {cluster_id}'] = (min_value, max_value)
    print(f'Cluster {cluster_id}: {min_value:.2f} to {max_value:.2f}')

# Define models to train
models = {
    'RandomForest': RandomForestRegressor(random_state=0),
    'LinearRegression': LinearRegression(),
    'Ridge': Ridge(),
    'Lasso': Lasso(),
    'Huber': HuberRegressor()
}

param_grid = {
    'RandomForest': {'n_estimators': [50, 100], 'max_depth': [3, 5]},
    'Ridge': {'alpha': [0.01, 0.1, 1]},
    'Lasso': {'alpha': [0.01, 0.1, 1]},
    'Huber': {'epsilon': [1.35, 1.5]}
}

# Function to train and evaluate models
def train_evaluate_models(X_train, X_test, y_train, y_test, model, param_grid):
    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='r2', n_jobs=-1)
    grid_search.fit(X_train, y_train)
    best_model = grid_search.best_estimator_
    y_pred = best_model.predict(X_test)
    r2 = r2_score(y_test, y_pred)
    return r2

# Train and evaluate models for each cluster
results = {}
for cluster_id, cluster in enumerate(clusters):
    X = cluster.drop(columns=['Target', 'Cluster'])
    y = cluster['Target']
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)
    cluster_results = {}
    for model_name, model in models.items():
        r2 = train_evaluate_models(X_train, X_test, y_train, y_test, model, param_grid.get(model_name, {}))
        cluster_results[model_name] = r2
    results[f'Cluster {cluster_id}'] = cluster_results

# Display results
results_df = pd.DataFrame(results).T
print(results_df)

# Plot RÂ² scores for each model across different clusters
results_df.plot(kind='bar', figsize=(12, 6))
plt.xlabel('Cluster')
plt.ylabel('RÂ² Score')
plt.title('RÂ² Scores for Different Models across Clusters')
plt.legend()
plt.show()














import pandas as pd
import numpy as np

# Load your dataset
# Replace 'your_dataset.csv' with the path to your dataset and 'target' with the target variable name
df = pd.read_csv('your_dataset.csv')

# Define the target variable
target = 'your_target_variable'

# Calculate the IQR (Interquartile Range) to identify outliers
Q1 = df[target].quantile(0.25)
Q3 = df[target].quantile(0.75)
IQR = Q3 - Q1

# Define the bounds for identifying outliers
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# Create the first dataset with outliers and negative target values
outliers_negative = df[(df[target] < lower_bound) | (df[target] > upper_bound) | (df[target] < 0)]

# Create the second dataset with the rest
non_outliers = df[~((df[target] < lower_bound) | (df[target] > upper_bound) | (df[target] < 0))]

# Save the datasets to CSV files (optional)
outliers_negative.to_csv('outliers_negative.csv', index=False)
non_outliers.to_csv('non_outliers.csv', index=False)

# Display the datasets
print("Outliers and Negative Target Values Dataset")
print(outliers_negative.head())

print("\nNon-Outliers Dataset")
print(non_outliers.head())



import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import mean_squared_error, r2_score
import xgboost as xgb

# Sample DataFrame creation for demonstration
np.random.seed(0)
df = pd.DataFrame({
    'Feature': np.random.randn(100) * 20,
    'Target': np.random.uniform(0, 100, size=100)
})

# Split the data into features and target
X = df[['Feature']]
y = df['Target']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# Define parameter grid for XGBoost
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [3, 5, 7],
    'learning_rate': [0.01, 0.1, 0.3],
    'min_child_weight': [1, 5, 10]
}

# Initialize and train XGBoost model with GridSearchCV
xgb_reg = xgb.XGBRegressor(objective='reg:squarederror', random_state=0)
grid_search = GridSearchCV(estimator=xgb_reg, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1, return_train_score=True)
grid_search.fit(X_train, y_train)

# Get the best model
best_model = grid_search.best_estimator_

# Predict and evaluate the best model
y_train_pred = best_model.predict(X_train)
y_test_pred = best_model.predict(X_test)

mse_train = mean_squared_error(y_train, y_train_pred)
mse_test = mean_squared_error(y_test, y_test_pred)
r2_train = r2_score(y_train, y_train_pred)
r2_test = r2_score(y_test, y_test_pred)

print(f'Best Parameters: {grid_search.best_params_}')
print(f'XGBoost - MSE Train: {mse_train}, MSE Test: {mse_test}, R^2 Train: {r2_train}, R^2 Test: {r2_test}')

# Plotting train vs test results
plt.figure(figsize=(14, 6))

plt.subplot(1, 2, 1)
plt.scatter(y_train, y_train_pred, alpha=0.5)
plt.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], '--r')
plt.xlabel('Actual Values (Train)')
plt.ylabel('Predicted Values (Train)')
plt.title('XGBoost - Train')

plt.subplot(1, 2, 2)
plt.scatter(y_test, y_test_pred, alpha=0.5)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], '--r')
plt.xlabel('Actual Values (Test)')
plt.ylabel('Predicted Values (Test)')
plt.title('XGBoost - Test')

plt.suptitle('Actual vs Predicted Values (XGBoost)')
plt.show()

# Display results in a dataframe
results = {
    'MSE Train': mse_train,
    'MSE Test': mse_test,
    'R^2 Train': r2_train,
    'R^2 Test': r2_test
}
results_df = pd.DataFrame([results])
print(results_df)














import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import mean_squared_error, r2_score
import xgboost as xgb

# Sample DataFrame creation for demonstration
np.random.seed(0)
df = pd.DataFrame({
    'Feature': np.random.randn(100) * 20,
    'Target': np.random.uniform(0, 100, size=100)
})

# Split the data into features and target
X = df[['Feature']]
y = df['Target']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# Define parameter grid for XGBoost
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [3, 5, 7],
    'learning_rate': [0.01, 0.1, 0.3],
    'min_child_weight': [1, 5, 10]
}

# Initialize and train XGBoost model with GridSearchCV
xgb_reg = xgb.XGBRegressor(objective='reg:squarederror', random_state=0)
grid_search = GridSearchCV(estimator=xgb_reg, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1, return_train_score=True)
grid_search.fit(X_train, y_train)

# Get the results in a DataFrame
results = pd.DataFrame(grid_search.cv_results_)

# Calculate RMSE for train and test sets
results['mean_train_rmse'] = np.sqrt(-results['mean_train_score'])
results['mean_test_rmse'] = np.sqrt(-results['mean_test_score'])

# Plot RÂ² scores
plt.figure(figsize=(14, 6))

plt.subplot(1, 2, 1)
for learning_rate in param_grid['learning_rate']:
    subset = results[results.param_learning_rate == learning_rate]
    plt.plot(subset['param_n_estimators'], subset['mean_train_score'], label=f'Train - lr={learning_rate}')
    plt.plot(subset['param_n_estimators'], subset['mean_test_score'], linestyle='--', label=f'Test - lr={learning_rate}')
plt.xlabel('Number of Estimators')
plt.ylabel('Neg MSE')
plt.title('Neg MSE vs Number of Estimators')
plt.legend()

# Plot RMSE scores
plt.subplot(1, 2, 2)
for learning_rate in param_grid['learning_rate']:
    subset = results[results.param_learning_rate == learning_rate]
    plt.plot(subset['param_n_estimators'], subset['mean_train_rmse'], label=f'Train - lr={learning_rate}')
    plt.plot(subset['param_n_estimators'], subset['mean_test_rmse'], linestyle='--', label=f'Test - lr={learning_rate}')
plt.xlabel('Number of Estimators')
plt.ylabel('RMSE')
plt.title('RMSE vs Number of Estimators')
plt.legend()

plt.tight_layout()
plt.show()

# Print the best parameters
print("Best Parameters:", grid_search.best_params_)
print("Best RÂ² Score:", grid_search.best_score_)








import xgboost as xgb
from sklearn.model_selection import GridSearchCV, train_test_split
from sklearn.metrics import r2_score, make_scorer
import pandas as pd
import matplotlib.pyplot as plt

# Sample data preparation (assuming you have your dataset as X and y)
# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Define XGBoost regressor
xgb_reg = xgb.XGBRegressor()

# Define parameter grid
param_grid = {
    'eta': [0.01, 0.02, 0.03],
    'max_depth': [3, 5, 7],
    'n_estimators': [100, 200, 300]
}

# Define R^2 scorer
r2_scorer = make_scorer(r2_score)

# Perform GridSearchCV
grid_search = GridSearchCV(estimator=xgb_reg, param_grid=param_grid, scoring=r2_scorer, cv=5, return_train_score=True)
grid_search.fit(X_train, y_train)

# Extract results
results = pd.DataFrame(grid_search.cv_results_)

# Plotting the evolution of R^2
plt.figure(figsize=(14, 7))

plt.plot(results['param_eta'], results['mean_train_score'], label='Train R^2')
plt.plot(results['param_eta'], results['mean_test_score'], label='Test R^2')

plt.xlabel('Learning Rate (eta)')
plt.ylabel('R^2 Score')
plt.title('Evolution of R^2 for different Learning Rates')
plt.legend()
plt.grid(True)
plt.show()






import xgboost as xgb
import pandas as pd
from sklearn.metrics import r2_score

# Define XGBoost parameters
xgb_para = {
    'eta': 0.02,
    'booster': 'gbtree',
    'max_depth': 10
}

# Perform cross-validation
xgb_cv = xgb.cv(
    params=xgb_para,
    dtrain=train_xgb,
    num_boost_round=500,
    nfold=5,
    metrics={'rmse'},  # RMSE is used for early stopping
    as_pandas=True,
    seed=42
)

# Extract the train and test predictions from the cross-validation
train_predictions = xgb_cv['train-rmse-mean']
test_predictions = xgb_cv['test-rmse-mean']

# Calculate R^2 for train and test
train_r2 = [r2_score(train_xgb.get_label(), train_predictions)]
test_r2 = [r2_score(test_xgb.get_label(), test_predictions)]

# Convert R^2 scores to a DataFrame for plotting
r2_df = pd.DataFrame({
    'train-r2': train_r2,
    'test-r2': test_r2
})

# Plot R^2 scores
r2_df.plot()










import xgboost as xgb
from sklearn.model_selection import GridSearchCV
import pandas as pd

# Define the parameter grid
param_grid = {
    'eta': [0.01, 0.02, 0.1],
    'booster': ['gbtree', 'gblinear'],
    'max_depth': [6, 10, 15]
}

# Convert your training data to DMatrix format
dtrain = xgb.DMatrix(data=train_data, label=train_labels)

# Define the model
xgb_model = xgb.XGBRegressor()

# Perform the grid search
grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=3, scoring='neg_mean_squared_error', verbose=1)

# Fit the grid search
grid_search.fit(train_data, train_labels)

# Get the results
cv_results = pd.DataFrame(grid_search.cv_results_)

# Print the best parameters
print("Best parameters:", grid_search.best_params_)

# Plot the results
cv_results[['mean_test_score', 'std_test_score']].plot()
















Rapport sur la Valeur de RÂ² et son InterprÃ©tation Statistique
Introduction
La valeur de RÂ², ou coefficient de dÃ©termination, est souvent mal comprise. En particulier, beaucoup de gens pensent que RÂ² ne peut Ãªtre qu'entre 0 et 1. Cependant, il peut Ãªtre nÃ©gatif dans certains cas. Ce rapport explique pourquoi et comment cela peut se produire, avec une explication dÃ©taillÃ©e des calculs de RÂ² et une illustration pratique.

Calcul de RÂ²
Pour comprendre pourquoi RÂ² peut Ãªtre nÃ©gatif, nous devons examiner comment il est calculÃ©. Nous utilisons trois variables clÃ©s dans ce calcul : RSS (Residual Sum of Squares), TSS (Total Sum of Squares), et ESS (Explained Sum of Squares).

Calcul de RSS :
Pour chaque variable indÃ©pendante 
ð‘¥
x, nous avons une variable dÃ©pendante 
ð‘¦
y. Nous traÃ§ons une ligne de rÃ©gression linÃ©aire qui prÃ©dit les valeurs de 
ð‘¦
y pour chaque valeur de 
ð‘¥
x. Appelons les valeurs prÃ©dites 
ð‘¦
^
y
^
â€‹
 . L'erreur entre ce que la ligne prÃ©dit et les valeurs rÃ©elles de 
ð‘¦
y est calculÃ©e par soustraction. Toutes ces diffÃ©rences sont mises au carrÃ© et additionnÃ©es, ce qui donne la somme des carrÃ©s des rÃ©sidus, RSS.

ð‘…
ð‘†
ð‘†
=
âˆ‘
(
ð‘¦
âˆ’
ð‘¦
^
)
2
RSS=âˆ‘(yâˆ’ 
y
^
â€‹
 ) 
2
 
Calcul de TSS :
Nous pouvons calculer la valeur moyenne de 
ð‘¦
y, appelÃ©e 
ð‘¦
Ë‰
y
Ë‰
â€‹
 . Si nous traÃ§ons 
ð‘¦
Ë‰
y
Ë‰
â€‹
 , c'est simplement une ligne horizontale Ã  travers les donnÃ©es. En soustrayant 
ð‘¦
Ë‰
y
Ë‰
â€‹
  de chaque valeur rÃ©elle de 
ð‘¦
y, nous obtenons la somme totale des carrÃ©s, TSS.

ð‘‡
ð‘†
ð‘†
=
âˆ‘
(
ð‘¦
âˆ’
ð‘¦
Ë‰
)
2
TSS=âˆ‘(yâˆ’ 
y
Ë‰
â€‹
 ) 
2
 
Calcul de ESS :
Les diffÃ©rences entre les valeurs prÃ©dites 
ð‘¦
^
y
^
â€‹
  et la valeur moyenne 
ð‘¦
Ë‰
y
Ë‰
â€‹
  sont mises au carrÃ© et additionnÃ©es. Ceci est la somme expliquÃ©e des carrÃ©s, ESS.

ð¸
ð‘†
ð‘†
=
âˆ‘
(
ð‘¦
^
âˆ’
ð‘¦
Ë‰
)
2
ESS=âˆ‘( 
y
^
â€‹
 âˆ’ 
y
Ë‰
â€‹
 ) 
2
 
Relation entre TSS, RSS et ESS
Lorsque nous avons une ligne de rÃ©gression avec une interception, la relation suivante est toujours vraie :

ð‘‡
ð‘†
ð‘†
=
ð‘…
ð‘†
ð‘†
+
ð¸
ð‘†
ð‘†
TSS=RSS+ESS
En divisant tous les termes par TSS et en rÃ©arrangeant, nous obtenons :

ð‘…
2
=
1
âˆ’
ð‘…
ð‘†
ð‘†
ð‘‡
ð‘†
ð‘†
R 
2
 =1âˆ’ 
TSS
RSS
â€‹
 
Dans ce cas, RÂ² est toujours positif.

Cas oÃ¹ RÂ² peut Ãªtre nÃ©gatif
Cependant, sans interception, la relation ci-dessus change. La formule devient :

ð‘‡
ð‘†
ð‘†
=
ð‘…
ð‘†
ð‘†
+
ð¸
ð‘†
ð‘†
+
2
âˆ‘
(
ð‘¦
âˆ’
ð‘¦
^
)
(
ð‘¦
^
âˆ’
ð‘¦
Ë‰
)
TSS=RSS+ESS+2âˆ‘(yâˆ’ 
y
^
â€‹
 )( 
y
^
â€‹
 âˆ’ 
y
Ë‰
â€‹
 )
En divisant tous les termes par TSS, nous obtenons :

ð‘…
2
=
ð¸
ð‘†
ð‘†
+
2
âˆ‘
(
ð‘¦
âˆ’
ð‘¦
^
)
(
ð‘¦
^
âˆ’
ð‘¦
Ë‰
)
ð‘‡
ð‘†
ð‘†
R 
2
 = 
TSS
ESS+2âˆ‘(yâˆ’ 
y
^
â€‹
 )( 
y
^
â€‹
 âˆ’ 
y
Ë‰
â€‹
 )
â€‹
 
Le terme supplÃ©mentaire peut rendre le numÃ©rateur nÃ©gatif, ce qui fait que RÂ² peut Ãªtre nÃ©gatif. Cela se produit lorsque la ligne horizontale 
ð‘¦
Ë‰
y
Ë‰
â€‹
  explique mieux les donnÃ©es que la ligne de rÃ©gression.

Quand le terme 
2
âˆ‘
(
ð‘¦
âˆ’
ð‘¦
^
)
(
ð‘¦
^
âˆ’
ð‘¦
Ë‰
)
2âˆ‘(yâˆ’ 
y
^
â€‹
 )( 
y
^
â€‹
 âˆ’ 
y
Ë‰
â€‹
 ) est nul ou non nul
Nul : Ce terme est nul lorsque la ligne de rÃ©gression passe par le point moyen des donnÃ©es 
(
ð‘¥
Ë‰
,
ð‘¦
Ë‰
)
( 
x
Ë‰
 , 
y
Ë‰
â€‹
 ), ce qui se produit lorsque le modÃ¨le inclut une interception. Dans ce cas, les erreurs 
(
ð‘¦
âˆ’
ð‘¦
^
)
(yâˆ’ 
y
^
â€‹
 ) et les diffÃ©rences 
(
ð‘¦
^
âˆ’
ð‘¦
Ë‰
)
( 
y
^
â€‹
 âˆ’ 
y
Ë‰
â€‹
 ) sont orthogonales, ce qui signifie que leur produit est en moyenne nul.
Non nul : Ce terme n'est pas nÃ©cessairement nul lorsque la rÃ©gression ne comprend pas d'interception. Dans ce cas, la ligne de rÃ©gression peut ne pas passer par le point moyen des donnÃ©es, et les erreurs et les diffÃ©rences peuvent avoir une covariance non nulle, conduisant ainsi Ã  un terme supplÃ©mentaire qui peut Ãªtre positif ou nÃ©gatif.
Exemple Simple
ConsidÃ©rons un exemple simple pour illustrer ce concept. Supposons que nous ayons les donnÃ©es suivantes :

x	y
1	1
2	2
3	1.3
4	3.75
5	2.25
Calculons la rÃ©gression linÃ©aire avec et sans interception :

RÃ©gression avec interception :
La ligne de rÃ©gression a une interception et la formule obtenue est :

ð‘¦
^
=
0.425
+
0.475
ð‘¥
y
^
â€‹
 =0.425+0.475x
RÃ©gression sans interception :
La ligne de rÃ©gression passe par l'origine (sans interception) et la formule obtenue est :

ð‘¦
^
=
0.63
ð‘¥
y
^
â€‹
 =0.63x
La moyenne des 
ð‘¦
y est 
ð‘¦
Ë‰
=
2.06
y
Ë‰
â€‹
 =2.06.

En traÃ§ant les lignes de rÃ©gression et la moyenne de 
ð‘¦
y sur un graphique, nous observons que la ligne de rÃ©gression sans interception ne passe pas par la moyenne des donnÃ©es, ce qui peut rendre le terme 
2
âˆ‘
(
ð‘¦
âˆ’
ð‘¦
^
)
(
ð‘¦
^
âˆ’
ð‘¦
Ë‰
)
2âˆ‘(yâˆ’ 
y
^
â€‹
 )( 
y
^
â€‹
 âˆ’ 
y
Ë‰
â€‹
 ) non nul et potentiellement nÃ©gatif, rendant ainsi 
ð‘…
2
R 
2
  nÃ©gatif.

Conclusion
La valeur de RÂ² peut Ãªtre nÃ©gative si le modÃ¨le de rÃ©gression n'a pas d'interception et s'adapte trÃ¨s mal aux donnÃ©es. Dans ce cas, une ligne horizontale pourrait fournir une meilleure explication des variations dans les donnÃ©es que le modÃ¨le lui-mÃªme. Comprendre cette nuance est crucial pour une interprÃ©tation correcte des rÃ©sultats de rÃ©gression linÃ©aire.

Visualisation avec Matplotlib
Voici un code Python qui illustre cet exemple :

python
Copy code
import matplotlib.pyplot as plt
import numpy as np

# DonnÃ©es simples
x = np.array([1, 2, 3, 4, 5])
y = np.array([1, 2, 1.3, 3.75, 2.25])

# Calcul de la rÃ©gression linÃ©aire avec interception
coeffs_with_intercept = np.polyfit(x, y, 1)
y_hat_with_intercept = np.polyval(coeffs_with_intercept, x)

# Calcul de la rÃ©gression linÃ©aire sans interception
coeffs_without_intercept = np.polyfit(x, y, 1, full=True)[0]
y_hat_without_intercept = np.polyval([coeffs_without_intercept[0]], x)

# Calcul de la moyenne de y
y_bar = np.mean(y)

# Visualisation des donnÃ©es et des lignes de rÃ©gression
plt.scatter(x, y, label='DonnÃ©es')
plt.plot(x, y_hat_with_intercept, label='RÃ©gression avec interception', color='green')
plt.plot(x, y_hat_without_intercept, label='RÃ©gression sans interception', color='red')
plt.axhline(y=y_bar, color='blue', linestyle='--', label='Moyenne de y')

plt.xlabel('x')
plt.ylabel('y')
plt.legend()
plt.title('RÃ©gression LinÃ©aire avec et sans Interception')
plt.show()
Ce graphique montre les donnÃ©es avec deux lignes de rÃ©gression : une avec interception (en vert) et une sans interception (en rouge), ainsi qu'une ligne horizontale reprÃ©sentant la moyenne de 
ð‘¦
y (en bleu). La ligne rouge ne passe pas par le point moyen des donnÃ©es, ce qui explique pourquoi 
ð‘…
2
R 
2
  peut Ãªtre nÃ©gatif dans ce cas.





import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score

# Generate data that follows the line y = x
np.random.seed(0)
X = np.linspace(-10, 10, 100).reshape(-1, 1)
y = X.flatten()  # y = x

# Fit a linear regression model with the equation y = -x
model = LinearRegression()
model.fit(X, -X)  # The model is trained with y = -x

# Predict using the fitted model
y_pred = model.predict(X)

# Compute R^2 value
r2 = r2_score(y, y_pred)

# Plot the results
plt.figure(figsize=(10, 6))
plt.scatter(X, y, color='black', label='Data: y = x')
plt.plot(X, y_pred, color='red', linewidth=2, label='Model: y = -x')
plt.xlabel('X')
plt.ylabel('Y')
plt.title(f'Linear Regression with y = -x\nRÂ² = {r2:.2f}')
plt.legend()
plt.grid(True)
plt.show()

print(f"RÂ²: {r2:.2f}")












import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score

# Generate non-linear data
np.random.seed(0)
X = np.sort(5 * np.random.rand(80, 1), axis=0)
y = np.sin(X).ravel() + np.random.randn(80) * 0.5

# Fit linear model
model = LinearRegression()
model.fit(X, y)
y_pred = model.predict(X)

# Calculate R^2
r2 = r2_score(y, y_pred)
print(f"R^2: {r2}")

# Plot
plt.scatter(X, y, color='black')
plt.plot(X, y_pred, color='blue', linewidth=3)
plt.title(f'Linear Regression on Non-linear Data\nR^2 = {r2:.2f}')
plt.show()


from sklearn.model_selection import train_test_split

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# Fit model on training data
model.fit(X_train, y_train)
y_test_pred = model.predict(X_test)

# Calculate R^2 on test data
r2_test = r2_score(y_test, y_test_pred)
print(f"R^2 on test data: {r2_test}")
















import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.ensemble import IsolationForest
from sklearn.model_selection import train_test_split, GridSearchCV
import xgboost as xgb
from sklearn.metrics import mean_squared_error, r2_score

# Sample DataFrame creation for demonstration
np.random.seed(0)
df = pd.DataFrame({
    'Value': np.random.randn(100) * 20  # Generating a dataset with potential outliers
})

# Introduce extreme outliers
df.loc[::10, 'Value'] = df['Value'] * 100

# Function to apply Isolation Forest and adjust outliers
def apply_isolation_forest(df, contamination, n_estimators):
    iso_forest = IsolationForest(contamination=contamination, n_estimators=n_estimators, random_state=0)
    df['Outlier'] = iso_forest.fit_predict(df[['Value']])
    df['Outlier'] = df['Outlier'].apply(lambda x: 'Outlier' if x == -1 else 'Inlier')
    return df

# Apply Isolation Forest
contamination = 0.1
n_estimators = 100
df = apply_isolation_forest(df, contamination, n_estimators)

# Calculate the replacement values
quantiles = df[df['Outlier'] == 'Inlier']['Value'].quantile([0.05, 0.1, 0.6, 0.7, 0.8, 0.9])
mean_value = df[df['Outlier'] == 'Inlier']['Value'].mean()

# Replace outliers based on specified rules
def replace_outliers(row, quantiles, mean_value):
    noise = np.random.normal(0, 1)
    if row['Outlier'] == 'Outlier':
        if row['Value'] > mean_value:
            if row['Value'] > quantiles[0.9]:
                return quantiles[0.7] + noise
            elif row['Value'] > quantiles[0.8]:
                return quantiles[0.6] + noise
        else:
            return quantiles[0.1] + noise if row['Value'] < quantiles[0.05] else quantiles[0.05] + noise
    else:
        return row['Value']

df['Adjusted'] = df.apply(lambda row: replace_outliers(row, quantiles, mean_value), axis=1)

# Plot original data with outliers highlighted
plt.figure(figsize=(12, 8))
sns.scatterplot(data=df, x=range(len(df)), y='Value', hue='Outlier', palette='tab10', legend='full')
plt.title('Isolation Forest Outlier Detection')
plt.xlabel('Index')
plt.ylabel('Value')
plt.show()

# Plot original and adjusted data distributions
plt.figure(figsize=(12, 8))
sns.displot(df, x='Value', hue='Outlier', kind='kde', fill=True, height=5, aspect=2)
plt.title('Original Data with Outliers Highlighted')

sns.displot(df, x='Adjusted', kind='kde', fill=True, height=5, aspect=2)
plt.title('Data after Outlier Adjustment')

plt.show()

# Show the impact of adjusting outliers
print("Original Data:")
print(df['Value'].describe())
print("\nAdjusted Data:")
print(df['Adjusted'].describe())

# Split the data into features and target
X = df[['Value']]
y = df['Adjusted']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# Define parameter grid for XGBoost
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [3, 5, 7],
    'learning_rate': [0.01, 0.1, 0.3],
    'min_child_weight': [1, 5, 10]
}

# Initialize and train XGBoost model with GridSearchCV
xgb_reg = xgb.XGBRegressor(objective='reg:squarederror', random_state=0)
grid_search = GridSearchCV(estimator=xgb_reg, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)
grid_search.fit(X_train, y_train)

# Get the best model
best_model = grid_search.best_estimator_

# Predict and evaluate the best model
y_train_pred = best_model.predict(X_train)
y_test_pred = best_model.predict(X_test)

mse_train = mean_squared_error(y_train, y_train_pred)
mse_test = mean_squared_error(y_test, y_test_pred)
r2_train = r2_score(y_train, y_train_pred)
r2_test = r2_score(y_test, y_test_pred)

print(f'Best Parameters: {grid_search.best_params_}')
print(f'XGBoost - MSE Train: {mse_train}, MSE Test: {mse_test}, R^2 Train: {r2_train}, R^2 Test: {r2_test}')

# Plotting train vs test results
plt.figure(figsize=(14, 6))

plt.subplot(1, 2, 1)
plt.scatter(y_train, y_train_pred, alpha=0.5)
plt.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], '--r')
plt.xlabel('Actual Values (Train)')
plt.ylabel('Predicted Values (Train)')
plt.title('XGBoost - Train')

plt.subplot(1, 2, 2)
plt.scatter(y_test, y_test_pred, alpha=0.5)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], '--r')
plt.xlabel('Actual Values (Test)')
plt.ylabel('Predicted Values (Test)')
plt.title('XGBoost - Test')

plt.suptitle('Actual vs Predicted Values (XGBoost)')
plt.show()









import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.ensemble import IsolationForest
from sklearn.model_selection import train_test_split, GridSearchCV
import xgboost as xgb
from sklearn.metrics import mean_squared_error, r2_score

# Sample DataFrame creation for demonstration
np.random.seed(0)
df = pd.DataFrame({
    'Value': np.random.randn(100) * 20  # Generating a dataset with potential outliers
})

# Introduce extreme outliers
df.loc[::10, 'Value'] = df['Value'] * 100

# Function to apply Isolation Forest and adjust outliers
def apply_isolation_forest(df, contamination, n_estimators):
    iso_forest = IsolationForest(contamination=contamination, n_estimators=n_estimators, random_state=0)
    df['Outlier'] = iso_forest.fit_predict(df[['Value']])
    df['Outlier'] = df['Outlier'].apply(lambda x: 'Outlier' if x == -1 else 'Inlier')
    return df

# Apply Isolation Forest
contamination = 0.1
n_estimators = 100
df = apply_isolation_forest(df, contamination, n_estimators)

# Calculate the replacement values
mean_value = df[df['Outlier'] == 'Inlier']['Value'].mean()
max_value = df[df['Outlier'] == 'Inlier']['Value'].max()
quantile_5th = df[df['Outlier'] == 'Inlier']['Value'].quantile(0.05)

# Replace outliers based on specified rules
def replace_outliers(row, mean_value, max_value, quantile_5th):
    if row['Outlier'] == 'Outlier':
        noise = np.random.normal(0, 1)
        if row['Value'] > mean_value:
            return 0.1 * max_value + noise
        else:
            return quantile_5th + noise
    else:
        return row['Value']

df['Adjusted'] = df.apply(lambda row: replace_outliers(row, mean_value, max_value, quantile_5th), axis=1)

# Plot original data with outliers highlighted
plt.figure(figsize=(12, 8))
sns.scatterplot(data=df, x=range(len(df)), y='Value', hue='Outlier', palette='tab10', legend='full')
plt.title('Isolation Forest Outlier Detection')
plt.xlabel('Index')
plt.ylabel('Value')
plt.show()

# Plot original and adjusted data distributions
plt.figure(figsize=(12, 8))
sns.displot(df, x='Value', hue='Outlier', kind='kde', fill=True, height=5, aspect=2)
plt.title('Original Data with Outliers Highlighted')

sns.displot(df, x='Adjusted', kind='kde', fill=True, height=5, aspect=2)
plt.title('Data after Outlier Adjustment')

plt.show()

# Show the impact of adjusting outliers
print("Original Data:")
print(df['Value'].describe())
print("\nAdjusted Data:")
print(df['Adjusted'].describe())

# Split the data into features and target
X = df[['Value']]
y = df['Adjusted']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# Define parameter grid for XGBoost
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [3, 5, 7],
    'learning_rate': [0.01, 0.1, 0.3],
    'min_child_weight': [1, 5, 10]
}

# Initialize and train XGBoost model with GridSearchCV
xgb_reg = xgb.XGBRegressor(objective='reg:squarederror', random_state=0)
grid_search = GridSearchCV(estimator=xgb_reg, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)
grid_search.fit(X_train, y_train)

# Get the best model
best_model = grid_search.best_estimator_

# Predict and evaluate the best model
y_train_pred = best_model.predict(X_train)
y_test_pred = best_model.predict(X_test)

mse_train = mean_squared_error(y_train, y_train_pred)
mse_test = mean_squared_error(y_test, y_test_pred)
r2_train = r2_score(y_train, y_train_pred)
r2_test = r2_score(y_test, y_test_pred)

print(f'Best Parameters: {grid_search.best_params_}')
print(f'XGBoost - MSE Train: {mse_train}, MSE Test: {mse_test}, R^2 Train: {r2_train}, R^2 Test: {r2_test}')

# Plotting train vs test results
plt.figure(figsize=(14, 6))

plt.subplot(1, 2, 1)
plt.scatter(y_train, y_train_pred, alpha=0.5)
plt.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], '--r')
plt.xlabel('Actual Values (Train)')
plt.ylabel('Predicted Values (Train)')
plt.title('XGBoost - Train')

plt.subplot(1, 2, 2)
plt.scatter(y_test, y_test_pred, alpha=0.5)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], '--r')
plt.xlabel('Actual Values (Test)')
plt.ylabel('Predicted Values (Test)')
plt.title('XGBoost - Test')

plt.suptitle('Actual vs Predicted Values (XGBoost)')
plt.show()









import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.ensemble import IsolationForest
from sklearn.model_selection import train_test_split
import xgboost as xgb
from sklearn.metrics import mean_squared_error, r2_score

# Sample DataFrame creation for demonstration
np.random.seed(0)
df = pd.DataFrame({
    'Value': np.random.randn(100) * 20  # Generating a dataset with potential outliers
})

# Introduce extreme outliers
df.loc[::10, 'Value'] = df['Value'] * 100

# Function to apply Isolation Forest and adjust outliers
def apply_isolation_forest(df, contamination, n_estimators):
    iso_forest = IsolationForest(contamination=contamination, n_estimators=n_estimators, random_state=0)
    df['Outlier'] = iso_forest.fit_predict(df[['Value']])
    df['Outlier'] = df['Outlier'].apply(lambda x: 'Outlier' if x == -1 else 'Inlier')
    return df

# Apply Isolation Forest
contamination = 0.1
n_estimators = 100
df = apply_isolation_forest(df, contamination, n_estimators)

# Calculate the replacement values
mean_value = df[df['Outlier'] == 'Inlier']['Value'].mean()
max_value = df[df['Outlier'] == 'Inlier']['Value'].max()
quantile_5th = df[df['Outlier'] == 'Inlier']['Value'].quantile(0.05)

# Replace outliers based on specified rules
def replace_outliers(row, mean_value, max_value, quantile_5th):
    if row['Outlier'] == 'Outlier':
        noise = np.random.normal(0, 1)
        if row['Value'] > mean_value:
            return 0.1 * max_value + noise
        else:
            return quantile_5th + noise
    else:
        return row['Value']

df['Adjusted'] = df.apply(lambda row: replace_outliers(row, mean_value, max_value, quantile_5th), axis=1)

# Plot original data with outliers highlighted
plt.figure(figsize=(12, 8))
sns.scatterplot(data=df, x=range(len(df)), y='Value', hue='Outlier', palette='tab10', legend='full')
plt.title('Isolation Forest Outlier Detection')
plt.xlabel('Index')
plt.ylabel('Value')
plt.show()

# Plot original and adjusted data distributions
plt.figure(figsize=(12, 8))
sns.displot(df, x='Value', hue='Outlier', kind='kde', fill=True, height=5, aspect=2)
plt.title('Original Data with Outliers Highlighted')

sns.displot(df, x='Adjusted', kind='kde', fill=True, height=5, aspect=2)
plt.title('Data after Outlier Adjustment')

plt.show()

# Show the impact of adjusting outliers
print("Original Data:")
print(df['Value'].describe())
print("\nAdjusted Data:")
print(df['Adjusted'].describe())

# Split the data into features and target
X = df[['Value']]
y = df['Adjusted']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# Initialize and train XGBoost model with enable_categorical set to True
xgb_reg = xgb.XGBRegressor(objective='reg:squarederror', random_state=0, enable_categorical=False)
xgb_reg.fit(X_train, y_train)

# Predict and evaluate the model
y_train_pred = xgb_reg.predict(X_train)
y_test_pred = xgb_reg.predict(X_test)

mse_train = mean_squared_error(y_train, y_train_pred)
mse_test = mean_squared_error(y_test, y_test_pred)
r2_train = r2_score(y_train, y_train_pred)
r2_test = r2_score(y_test, y_test_pred)

print(f'XGBoost - MSE Train: {mse_train}, MSE Test: {mse_test}, R^2 Train: {r2_train}, R^2 Test: {r2_test}')

# Plotting train vs test results
plt.figure(figsize=(14, 6))

plt.subplot(1, 2, 1)
plt.scatter(y_train, y_train_pred, alpha=0.5)
plt.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], '--r')
plt.xlabel('Actual Values (Train)')
plt.ylabel('Predicted Values (Train)')
plt.title('XGBoost - Train')

plt.subplot(1, 2, 2)
plt.scatter(y_test, y_test_pred, alpha=0.5)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], '--r')
plt.xlabel('Actual Values (Test)')
plt.ylabel('Predicted Values (Test)')
plt.title('XGBoost - Test')

plt.suptitle('Actual vs Predicted Values (XGBoost)')
plt.show()









import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.ensemble import IsolationForest
from sklearn.model_selection import train_test_split, GridSearchCV
import xgboost as xgb
from sklearn.metrics import mean_squared_error, r2_score

# Sample DataFrame creation for demonstration
np.random.seed(0)
df = pd.DataFrame({
    'Value': np.random.randn(100) * 20  # Generating a dataset with potential outliers
})

# Introduce extreme outliers
df.loc[::10, 'Value'] = df['Value'] * 100

# Function to apply Isolation Forest and adjust outliers
def apply_isolation_forest(df, contamination, n_estimators):
    iso_forest = IsolationForest(contamination=contamination, n_estimators=n_estimators, random_state=0)
    df['Outlier'] = iso_forest.fit_predict(df[['Value']])
    df['Outlier'] = df['Outlier'].apply(lambda x: 'Outlier' if x == -1 else 'Inlier')
    return df

# Apply Isolation Forest
contamination = 0.1
n_estimators = 100
df = apply_isolation_forest(df, contamination, n_estimators)

# Calculate the replacement values
mean_value = df[df['Outlier'] == 'Inlier']['Value'].mean()
max_value = df[df['Outlier'] == 'Inlier']['Value'].max()
quantile_5th = df[df['Outlier'] == 'Inlier']['Value'].quantile(0.05)

# Replace outliers based on specified rules
def replace_outliers(row, mean_value, max_value, quantile_5th):
    if row['Outlier'] == 'Outlier':
        noise = np.random.normal(0, 1)
        if row['Value'] > mean_value:
            return 0.1 * max_value + noise
        else:
            return quantile_5th + noise
    else:
        return row['Value']

df['Adjusted'] = df.apply(lambda row: replace_outliers(row, mean_value, max_value, quantile_5th), axis=1)

# Plot original data with outliers highlighted
plt.figure(figsize=(12, 8))
sns.scatterplot(data=df, x=range(len(df)), y='Value', hue='Outlier', palette='tab10', legend='full')
plt.title('Isolation Forest Outlier Detection')
plt.xlabel('Index')
plt.ylabel('Value')
plt.show()

# Plot original and adjusted data distributions
plt.figure(figsize=(12, 8))
sns.displot(df, x='Value', hue='Outlier', kind='kde', fill=True, height=5, aspect=2)
plt.title('Original Data with Outliers Highlighted')

sns.displot(df, x='Adjusted', kind='kde', fill=True, height=5, aspect=2)
plt.title('Data after Outlier Adjustment')

plt.show()

# Show the impact of adjusting outliers
print("Original Data:")
print(df['Value'].describe())
print("\nAdjusted Data:")
print(df['Adjusted'].describe())

# Split the data into features and target
X = df[['Value']]
y = df['Adjusted']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# Initialize and train XGBoost model
xgb_reg = xgb.XGBRegressor(objective='reg:squarederror', random_state=0)
xgb_reg.fit(X_train, y_train)

# Predict and evaluate the model
y_train_pred = xgb_reg.predict(X_train)
y_test_pred = xgb_reg.predict(X_test)

mse_train = mean_squared_error(y_train, y_train_pred)
mse_test = mean_squared_error(y_test, y_test_pred)
r2_train = r2_score(y_train, y_train_pred)
r2_test = r2_score(y_test, y_test_pred)

print(f'XGBoost - MSE Train: {mse_train}, MSE Test: {mse_test}, R^2 Train: {r2_train}, R^2 Test: {r2_test}')

# Plotting train vs test results
plt.figure(figsize=(14, 6))

plt.subplot(1, 2, 1)
plt.scatter(y_train, y_train_pred, alpha=0.5)
plt.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], '--r')
plt.xlabel('Actual Values (Train)')
plt.ylabel('Predicted Values (Train)')
plt.title('XGBoost - Train')

plt.subplot(1, 2, 2)
plt.scatter(y_test, y_test_pred, alpha=0.5)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], '--r')
plt.xlabel('Actual Values (Test)')
plt.ylabel('Predicted Values (Test)')
plt.title('XGBoost - Test')

plt.suptitle('Actual vs Predicted Values (XGBoost)')
plt.show()








import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.ensemble import IsolationForest
from sklearn.model_selection import train_test_split
import xgboost as xgb
from sklearn.metrics import mean_squared_error, r2_score

# Sample DataFrame creation for demonstration
np.random.seed(0)
df = pd.DataFrame({
    'Value': np.random.randn(100) * 20  # Generating a dataset with potential outliers
})

# Introduce extreme outliers
df.loc[::10, 'Value'] = df['Value'] * 100

# Function to apply Isolation Forest and adjust outliers
def apply_isolation_forest(df, contamination, n_estimators):
    iso_forest = IsolationForest(contamination=contamination, n_estimators=n_estimators, random_state=0)
    df['Outlier'] = iso_forest.fit_predict(df[['Value']])
    df['Outlier'] = df['Outlier'].apply(lambda x: 'Outlier' if x == -1 else 'Inlier')
    return df

# Apply Isolation Forest
contamination = 0.1
n_estimators = 100
df = apply_isolation_forest(df, contamination, n_estimators)

# Calculate the replacement values
mean_value = df[df['Outlier'] == 'Inlier']['Value'].mean()
max_value = df[df['Outlier'] == 'Inlier']['Value'].max()
quantile_5th = df[df['Outlier'] == 'Inlier']['Value'].quantile(0.05)

# Replace outliers based on specified rules
def replace_outliers(row, mean_value, max_value, quantile_5th):
    if row['Outlier'] == 'Outlier':
        noise = np.random.normal(0, 1)
        if row['Value'] > mean_value:
            return 0.1 * max_value + noise
        else:
            return quantile_5th + noise
    else:
        return row['Value']

df['Adjusted'] = df.apply(lambda row: replace_outliers(row, mean_value, max_value, quantile_5th), axis=1)

# Plot original data with outliers highlighted
plt.figure(figsize=(12, 8))
sns.scatterplot(data=df, x=range(len(df)), y='Value', hue='Outlier', palette='tab10', legend='full')
plt.title('Isolation Forest Outlier Detection')
plt.xlabel('Index')
plt.ylabel('Value')
plt.show()

# Plot original and adjusted data distributions
plt.figure(figsize=(12, 8))
sns.displot(df, x='Value', hue='Outlier', kind='kde', fill=True, height=5, aspect=2)
plt.title('Original Data with Outliers Highlighted')

sns.displot(df, x='Adjusted', kind='kde', fill=True, height=5, aspect=2)
plt.title('Data after Outlier Adjustment')

plt.show()

# Show the impact of adjusting outliers
print("Original Data:")
print(df['Value'].describe())
print("\nAdjusted Data:")
print(df['Adjusted'].describe())












import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder
from sklearn.tree import DecisionTreeRegressor, plot_tree
import seaborn as sns
import matplotlib.pyplot as plt

# Sample DataFrame creation for demonstration
np.random.seed(0)
df = pd.DataFrame({
    'CatVar1': np.random.choice(['A', 'B', 'C', np.nan], size=100),
    'CatVar2': np.random.choice(['X', 'Y', 'Z', np.nan], size=100),
    'Target': np.random.uniform(0, 100, size=100)
})

# Replace missing values with a new category "missing" and convert all to strings
df.fillna('missing', inplace=True)
df['CatVar1'] = df['CatVar1'].astype(str)
df['CatVar2'] = df['CatVar2'].astype(str)

# Function to group using Decision Tree and plot the tree
def group_classes_with_decision_tree(df, cat_vars, target_var):
    group_mappings = {}
    for cat_var in cat_vars:
        le = LabelEncoder()
        df[f'{cat_var}_encoded'] = le.fit_transform(df[cat_var])
        X = df[[f'{cat_var}_encoded']]
        y = df[target_var]
        
        dt_reg = DecisionTreeRegressor(max_depth=3, random_state=0)
        dt_reg.fit(X, y)
        
        # Predict the leaves for each sample
        leaf_ids = dt_reg.apply(X).reshape(-1)  # Flatten to 1D array
        unique_leaf_ids = np.unique(leaf_ids)
        leaf_id_to_group = {leaf_id: idx for idx, leaf_id in enumerate(unique_leaf_ids)}
        
        df[f'Grouped_{cat_var}'] = pd.Series(leaf_ids).map(leaf_id_to_group)
        
        # Create a mapping from original categories to new groups
        original_to_group = {}
        for category in le.classes_:
            category_encoded = le.transform([category])[0]
            group = df[df[f'{cat_var}_encoded'] == category_encoded][f'Grouped_{cat_var}'].mode()[0]
            original_to_group[category] = group
        
        group_mappings[cat_var] = original_to_group

        # Plot the Decision Tree
        plt.figure(figsize=(12, 8))
        plot_tree(dt_reg, feature_names=[cat_var], filled=True, rounded=True, fontsize=10)
        plt.title(f'Decision Tree for {cat_var}')
        plt.show()
        
    return df, group_mappings

# Apply Decision Tree grouping
cat_vars = ['CatVar1', 'CatVar2']
df_grouped, group_mappings = group_classes_with_decision_tree(df, cat_vars, 'Target')

# Display the grouped DataFrame
print(df_grouped.head())

# Display the mappings from original to new groups
for cat_var, mapping in group_mappings.items():
    print(f'\nMapping for {cat_var}:')
    groups = {}
    for original, group in mapping.items():
        if group not in groups:
            groups[group] = []
        groups[group].append(original)
    for group, categories in groups.items():
        print(f'  Group {group + 1}: {categories}')

# Plot the distribution of the target variable by the grouped categories
for cat_var in cat_vars:
    plt.figure(figsize=(12, 6))
    sns.boxplot(x=f'Grouped_{cat_var}', y='Target', data=df_grouped)
    plt.title(f'Distribution of Target by Grouped {cat_var}')
    plt.show()









import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder
from sklearn.tree import DecisionTreeRegressor
import seaborn as sns
import matplotlib.pyplot as plt

# Sample DataFrame creation for demonstration
np.random.seed(0)
df = pd.DataFrame({
    'CatVar1': np.random.choice(['A', 'B', 'C', np.nan], size=100),
    'CatVar2': np.random.choice(['X', 'Y', 'Z', np.nan], size=100),
    'Target': np.random.uniform(0, 100, size=100)
})

# Replace missing values with a new category "missing" and convert all to strings
df.fillna('missing', inplace=True)
df['CatVar1'] = df['CatVar1'].astype(str)
df['CatVar2'] = df['CatVar2'].astype(str)

# Function to group using Decision Tree
def group_classes_with_decision_tree(df, cat_vars, target_var):
    group_mappings = {}
    for cat_var in cat_vars:
        le = LabelEncoder()
        df[f'{cat_var}_encoded'] = le.fit_transform(df[cat_var])
        X = df[[f'{cat_var}_encoded']]
        y = df[target_var]
        
        dt_reg = DecisionTreeRegressor(max_depth=3, random_state=0)
        dt_reg.fit(X, y)
        
        # Predict the leaves for each sample
        leaf_ids = dt_reg.apply(X).reshape(-1)  # Flatten to 1D array
        unique_leaf_ids = np.unique(leaf_ids)
        leaf_id_to_group = {leaf_id: idx for idx, leaf_id in enumerate(unique_leaf_ids)}
        
        df[f'Grouped_{cat_var}'] = pd.Series(leaf_ids).map(leaf_id_to_group)
        
        # Create a mapping from original categories to new groups
        original_to_group = {}
        for category in le.classes_:
            category_encoded = le.transform([category])[0]
            group = df[df[f'{cat_var}_encoded'] == category_encoded][f'Grouped_{cat_var}'].mode()[0]
            original_to_group[category] = group
        
        group_mappings[cat_var] = original_to_group
        
    return df, group_mappings

# Apply Decision Tree grouping
cat_vars = ['CatVar1', 'CatVar2']
df_grouped, group_mappings = group_classes_with_decision_tree(df, cat_vars, 'Target')

# Display the grouped DataFrame
print(df_grouped.head())

# Display the mappings from original to new groups
for cat_var, mapping in group_mappings.items():
    print(f'\nMapping for {cat_var}:')
    groups = {}
    for original, group in mapping.items():
        if group not in groups:
            groups[group] = []
        groups[group].append(original)
    for group, categories in groups.items():
        print(f'  Group {group + 1}: {categories}')

# Plot the distribution of the target variable by the grouped categories
for cat_var in cat_vars:
    plt.figure(figsize=(12, 6))
    sns.boxplot(x=f'Grouped_{cat_var}', y='Target', data=df_grouped)
    plt.title(f'Distribution of Target by Grouped {cat_var}')
    plt.show()
